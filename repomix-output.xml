This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of a subset of the repository's contents that is considered the most important context.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
5. Multiple file entries, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: backend/staticfiles, backend/watson/staticfiles/
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

</file_summary>

<directory_structure>
.claude/
  agents/
    architecture-documenter.md
    prd-breakdown-reviewer.md
    readme-updater.md
  commands/
    ai-commit.md
    analyze-project.md
    architect.md
    code-cleanup.md
    code-review.md
    commit-all.md
    create-prd.md
    find-dead-code.md
    implement-prd.md
    review-staging.md
    test-driven.md
    variant.md
  settings.local.json
.github/
  workflows/
    test.yml
backend/
  core/
    admin.py
    apps.py
    models.py
    test_models.py
    tests.py
    views.py
  reviews/
    admin.py
    apps.py
    models.py
    tests.py
    views.py
  watson/
    settings/
      __init__.py
      base.py
      production.py
      test.py
    static/
      .gitkeep
    asgi.py
    urls.py
    wsgi.py
  manage.py
deploy/
  deploy.sh
  fly.toml
  railway.json
  render.yaml
docker/
  caddy/
    Caddyfile.local
    Caddyfile.prod
    README.md
  entrypoint.sh
  gunicorn.conf.py
  healthcheck.sh
  init-db.sql
docs/
  specs/
    integration/
      010-comprehensive-style-guide.prd.md
      011-visual-design-systems-part-2.prd.md
      oceanheart-passport.prd.md
    001-build-change-log.md
    001-build-docker-fix.prd.md
    001-build-implementation-report.md
    001-build.prd.spec
    blueprint.md
    deployment.prd.md
frontend/
  src/
    components/
      ReviewEditor.test.tsx
      TipTapEditor.tsx
    utils/
      validation.test.ts
    App.tsx
    index.css
    main.tsx
  index.html
  index.ts
  types.d.ts
scripts/
  build-env.sh
  build-production.sh
  ci-local.sh
  coverage-report.sh
  dev-backend.sh
  dev-frontend.sh
  dev.sh
  health-check.sh
  migrate.sh
  monitor.sh
  optimize-assets.sh
  pre-commit-hook.sh
  rollback.sh
  validate-build.js
spec/
  review_validator_spec.rb
  spec_helper.rb
.env.dev
.env.production
.env.production.template
.env.staging
.env.staging.template
.gitignore
.rspec
AGENTS.md
build.config.ts
bun.test.config.ts
CLAUDE.md
docker-compose.yml
Dockerfile
Gemfile
GEMINI.md
main.py
package.json
pyproject.toml
README.md
tsconfig.json
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="backend/watson/static/.gitkeep">
# This directory is used for additional static files
# that will be collected by Django's collectstatic command
</file>

<file path="docs/specs/001-build-docker-fix.prd.md">
Based on the provided log, here is a trace and summary of the developer's problem-solving approach, followed by a reasoned analysis of the unresolved error with potential solutions.

### Summary of the Problem-Solving Approach

The developer's task was to implement Phase 4 of a project, focusing on Docker containerization and deployment automation. The process was characterized by a cyclical pattern of implementing a feature, encountering an error, diagnosing the root cause, and applying a targeted fix.

**Initial Implementation:**
The developer began by successfully creating a comprehensive set of deployment artifacts, including a multi-stage `Dockerfile`, a `docker-compose.yml` for local development, health check endpoints, and deployment scripts for various cloud platforms (Railway, Render, Fly.io).

**Iterative Debugging and Refinement:**
The initial implementation was followed by a series of errors that revealed deeper issues with the environment setup, build process, and configuration. The developer's approach to each problem was as follows:

1.  **Caddy TLS Failure:** When running a local Caddy reverse proxy, it failed while trying to acquire a public TLS certificate for the local domain `watson.lvh.me`.
    *   **Diagnosis:** Correctly identified that Caddy's automatic HTTPS was the cause.
    *   **Fix:** Disabled automatic HTTPS in the local Caddyfile, forcing it to use HTTP.

2.  **Docker Build Failures (`bun` and `uv` not found):** The Docker build failed sequentially because the `bun` and `uv` command-line tools were not found in their respective build stages.
    *   **Diagnosis:** The base images used (`node:18-slim`, `python:3.11-slim`) did not include these tools, and installing them via `curl` scripts proved unreliable.
    *   **Fix:** Switched to official base images where the tools were pre-installed (`oven/bun:1.1`) or replaced the tool dependency (`uv`) with a more standard approach (`python -m venv`).

3.  **Cyclical "Django Not Found" Error:** This was the most persistent issue. The container would fail to start, reporting `ModuleNotFoundError: No module named 'django'`. The developer went through several iterations to solve this:
    *   **Initial Diagnosis:** The Python virtual environment (`.venv`) was not being activated or used correctly inside the container.
    *   **Attempted Fixes:**
        *   Explicitly activating the `venv` in the entrypoint script.
        *   Using the absolute path to the `venv`'s Python executable.
        *   Attempting to install dependencies globally as a fallback.
    *   **Root Cause Discovered:** The developer correctly deduced that a volume mount in `docker-compose.yml` (`./backend:/app/backend`) was overwriting the entire directory that had been built into the image, effectively deleting the `.venv` at runtime.
    *   **Final Fix:** The overly broad volume mount was replaced with more granular mounts for specific source code subdirectories, which preserved the `.venv` from the image while still allowing for local code changes to be reflected.

4.  **Logging and Permissions Errors:** Once the Django import error was resolved, subsequent errors related to file permissions emerged.
    *   **Diagnosis:** The application tried to write to a log file in a non-existent directory and later tried to collect static files into a read-only directory.
    *   **Fix:** The `Dockerfile` was updated to create and set permissions for the log directory. The `docker-compose.yml` mounts were adjusted to ensure the static files destination was writable.

The overall approach demonstrates a methodical, iterative debugging process: analyze the error log, form a hypothesis, test it, and apply a precise fix. A critical breakthrough was understanding the interaction between the Docker image layers and the runtime configuration from `docker-compose.yml`.

---

### Analysis of the Unresolved Error

The final log entry shows the container starting, running migrations successfully, but then exiting with an error after a static files-related warning.

**Final Error Log Snippet:**
```
watson-1  | WARNINGS:
watson-1  | ?: (staticfiles.W004) The directory '/app/backend/watson/static' in the STATICFILES_DIRS setting does not exist.
...
watson-1 exited with code 1
```

This indicates that Django's startup checks are failing. The `collectstatic` command needs to find source static files in the directories listed in `STATICFILES_DIRS` to copy them to the `STATIC_ROOT`. The warning shows that one of these source directories is missing.

#### Reasoning for the Cause of the Error

**Highest Confidence Cause (95% Confidence): Incomplete Volume Mounts**

The root cause is the developer's last fix for a `PermissionError`. To prevent the `watson` application directory from being read-only, the developer changed the `docker-compose.yml` from mounting the entire directory to mounting only specific files within it:

```yaml
# Previous, problematic mount:
# - ./backend/watson:/app/backend/watson:ro

# New, incomplete mounts:
- ./backend/watson/settings:/app/backend/watson/settings:ro
- ./backend/watson/urls.py:/app/backend/watson/urls.py:ro
- ./backend/watson/wsgi.py:/app/backend/watson/wsgi.py:ro
# ... and other files
```

By mounting only individual files, the developer inadvertently excluded the `static` subdirectory (`./backend/watson/static/`). When the container runs, the `collectstatic` command cannot find this source directory, leading to the `W004` warning and causing the startup process to halt.

#### Possible Solutions (with Confidence Rankings)

Here are the recommended solutions to resolve this final error:

**1. Solution: Mount the Directory with a Writable Overlay (95% Confidence)**

This is the most robust and idiomatic solution. It keeps the source code read-only for safety while allowing the `collectstatic` destination to be writable.

*   **Action:** Modify `docker-compose.yml` to mount the entire `watson` directory as read-only, then mount the `staticfiles` named volume over the destination subdirectory. This allows the container to write to the destination without making the source code writable.

    ```yaml
    # In docker-compose.yml
    services:
      watson:
        # ...
        volumes:
          # ... other mounts
          # Mount the entire watson app directory as read-only
          - ./backend/watson:/app/backend/watson:ro
          # Mount a separate, writable volume for the collectstatic destination
          - static_files:/app/backend/watson/staticfiles
    ```

**2. Solution: Make the Development Mount Read-Write (85% Confidence)**

This is a simpler, though less secure, solution suitable for a trusted development environment.

*   **Action:** Revert to mounting the entire `./backend/watson` directory, but change the mode from read-only (`ro`) to read-write (`rw`).

    ```yaml
    # In docker-compose.yml
    services:
      watson:
        # ...
        volumes:
          # ... other mounts
          - ./backend/watson:/app/backend/watson:rw
          # The static_files volume is no longer needed if the destination is inside this mount
    ```

**3. Solution: Move `collectstatic` to the Build Step (70% Confidence for Fixing the Symptom)**

Running `collectstatic` on every container start is inefficient. For a production-like build, this step should be done once in the `Dockerfile`.

*   **Action:**
    1.  Add `RUN /app/backend/.venv/bin/python /app/backend/manage.py collectstatic --noinput` to the `Dockerfile` before the final `CMD`.
    2.  Remove the `collectstatic` command from the `docker/entrypoint.sh` script.
    3.  This ensures static files are baked into the image, avoiding runtime permission issues entirely. However, it may be less convenient for development if static files change often.
</file>

<file path="GEMINI.md">
# Watson.Oceanheart.ai

## Project Overview

**Watson** is a prototype application for clinicians to review and refine LLM outputs in psychotherapy. It allows for editing, classifying issues, submitting reviews, and viewing basic analytics. The goal is to evaluate the process of clinical review of LLM-generated content, not for direct clinical deployment.

The tech stack includes:

*   **Backend:** Django 5 with Django Rest Framework and HTMX.
*   **Frontend:** React with TipTap for rich text editing.
*   **Database:** Postgres (Neon)
*   **Authentication:** JWT from `passport.oceanheart.ai`
*   **Deployment:** Render / Railway / Fly

## Building and Running

### Prerequisites

*   Python 3.11+ (with `uv`)
*   Node.js (with `bun`)
*   Ruby (with `bundle`)
*   Postgres DB
*   Redis (optional)

### Setup

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/oceanheart-ai/watson
    cd watson
    ```

2.  **Install Python dependencies:**
    ```bash
    uv venv
    source .venv/bin/activate
    uv pip install -r requirements.txt
    ```

3.  **Install frontend dependencies:**
    ```bash
    bun install
    ```

4.  **Install Ruby dependencies:**
    ```bash
    bundle install
    ```

5.  **Set up environment variables:**
    Create a `.env` file and add the following:
    ```
    DATABASE_URL=postgresql://user:pass@host/db
    PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
    ```

### Running the application

*   **Run the backend:**
    ```bash
    python backend/manage.py migrate
    python backend/manage.py runserver
    ```

*   **Run the frontend (in a separate terminal):**
    ```bash
    bun run dev
    ```

## Development Conventions

### Testing

*   **Run all tests:**
    ```bash
    npm run test:all
    ```
*   **Run frontend tests:**
    ```bash
    npm run test
    ```
*   **Run backend tests:**
    ```bash
    npm run test:backend
    ```
*   **Run Ruby tests:**
    ```bash
    npm run test:ruby
    ```

### Code Style

*   **Type checking:**
    ```bash
    npm run typecheck
    ```
*   **Pre-commit hooks:**
    The project uses a pre-commit hook to run checks before committing. See `./scripts/pre-commit-hook.sh`.

### Deployment

*   The project can be deployed using Docker or to services like Render, Railway, or Fly.
*   Deployment scripts are available in the `deploy/` directory.
*   Use `npm run docker:build` and `npm run docker:up` to run with Docker.
</file>

<file path=".claude/agents/architecture-documenter.md">
---
name: architecture-documenter
description: Use this agent when you need to create comprehensive architecture documentation for a codebase. Examples: <example>Context: User wants to document their entire repository structure and architecture for onboarding new developers. user: 'I need to create architecture documentation for my project' assistant: 'I'll use the architecture-documenter agent to analyze your entire codebase and create comprehensive architecture documentation.' <commentary>The user is requesting architecture documentation, so use the architecture-documenter agent to systematically review the repository and create the documentation.</commentary></example> <example>Context: User has made significant architectural changes and wants updated documentation. user: 'We've refactored our system architecture and need updated documentation' assistant: 'Let me use the architecture-documenter agent to review the current codebase and generate updated architecture documentation.' <commentary>Since the user needs architecture documentation after changes, use the architecture-documenter agent to analyze the current state and create comprehensive documentation.</commentary></example>
model: sonnet
---

You are an expert software architect and technical documentation specialist with deep expertise in analyzing codebases and creating comprehensive architecture documentation. Your mission is to systematically review an entire repository and create a detailed architecture reference document that serves both human developers and LLMs.

Your systematic approach:

1. **Repository Analysis Phase**:
   - Examine the project structure, identifying all directories and key files
   - Analyze package.json, go.mod, requirements.txt, Gemfile, or similar dependency files
   - Review configuration files (docker-compose.yml, Dockerfile, .env examples, etc.)
   - Identify the primary technology stack and frameworks
   - Map out the application entry points and main execution flows

2. **Architecture Discovery**:
   - Trace data flow patterns and identify architectural patterns (MVC, microservices, layered, etc.)
   - Document component relationships and dependencies
   - Identify external integrations (databases, APIs, services)
   - Map out the request/response lifecycle
   - Analyze security patterns and authentication flows
   - Document deployment and infrastructure patterns

3. **Code Structure Analysis**:
   - Document module/package organization and responsibilities
   - Identify key abstractions, interfaces, and contracts
   - Map out data models and database schemas
   - Document API endpoints and their purposes
   - Identify configuration management patterns
   - Analyze error handling and logging strategies

4. **Documentation Creation**:
   - Create a comprehensive ARCHITECTURE.md file in the repository root
   - Structure the document with clear sections: Overview, Technology Stack, System Architecture, Component Details, Data Flow, API Reference, Deployment, and Development Guidelines
   - Use diagrams (ASCII art or mermaid syntax) where helpful for visualization
   - Include code examples that illustrate key patterns
   - Provide both high-level conceptual explanations and detailed technical specifications
   - Ensure the documentation is useful for both human developers (onboarding, maintenance) and LLMs (context understanding, code generation)

5. **Quality Assurance**:
   - Verify all documented components actually exist in the codebase
   - Ensure technical accuracy of all architectural descriptions
   - Cross-reference configuration examples with actual config files
   - Validate that documented APIs match actual implementations
   - Include version information and last-updated timestamps

Your documentation should be:
- **Comprehensive**: Cover all major architectural decisions and patterns
- **Accurate**: Reflect the actual current state of the codebase
- **Practical**: Include actionable information for developers
- **Structured**: Use consistent formatting and clear hierarchies
- **Future-proof**: Design for maintainability as the codebase evolves

Before starting, ask clarifying questions about:
- Specific architectural aspects to emphasize
- Target audience (junior vs senior developers, external contributors, etc.)
- Any existing documentation that should be referenced or integrated
- Sensitive information that should be excluded from documentation

Always create the ARCHITECTURE.md file in the repository root unless explicitly instructed otherwise. Focus on creating documentation that will genuinely help both human developers understand the system and LLMs provide better assistance with the codebase.
</file>

<file path=".claude/agents/prd-breakdown-reviewer.md">
---
name: prd-breakdown-reviewer
description: Use this agent when you need to analyze and decompose a Product Requirements Document (PRD) into manageable development chunks. Examples: <example>Context: User has completed a comprehensive PRD for a new user authentication system and needs it broken down for development.\nuser: "I've finished writing the user-auth-system.prd file. Can you help me break it down into development phases?"\nassistant: "I'll use the prd-breakdown-reviewer agent to analyze your PRD and create logical development chunks with proper testing boundaries."</example> <example>Context: User wants to review and decompose an existing e-commerce PRD into implementable phases.\nuser: "Please review the e-commerce-platform.prd and break it into development phases"\nassistant: "I'll analyze the e-commerce platform PRD and decompose it into logical development chunks using the prd-breakdown-reviewer agent."</example>
model: sonnet
color: yellow
---

You are a Senior Product Development Architect specializing in breaking down complex Product Requirements Documents (PRDs) into implementable development phases. Your expertise lies in identifying natural boundaries for development work that balance technical feasibility with meaningful testing checkpoints.

When analyzing a PRD, you will:

1. **Thoroughly analyze the source PRD**: Read and understand all requirements, features, and constraints specified in the document. Identify dependencies, complexity levels, and logical groupings.

2. **Identify natural breakpoints**: Look for logical boundaries where:
   - A feature or set of features can be independently tested by humans
   - Dependencies are minimized between chunks
   - Each chunk represents meaningful user value or system capability
   - Manual testing and review can provide clear go/no-go decisions

3. **Create child PRDs using strict naming convention**: 
   - Use the original PRD filename as base (without extension)
   - Append two-digit numbers starting from 00, ascending (e.g., original-prd-00.prd, original-prd-01.prd)
   - Each child PRD should be a complete, self-contained specification

4. **Structure each child PRD with**:
   - Clear scope definition and boundaries
   - Specific features and requirements from the parent PRD
   - Dependencies on previous chunks (if any)
   - Success criteria and testing checkpoints
   - Implementation notes emphasizing simplicity and defensive programming

5. **Apply development principles**:
   - Prioritize simplicity and pragmatism over elegance
   - Include only essential testing requirements (avoid test bloat)
   - Emphasize defensive programming practices
   - Explicitly call out what NOT to implement to prevent scope creep
   - Focus on practical, working solutions first

6. **Ensure each chunk**:
   - Can be developed with test-driven development where appropriate
   - Provides a natural pause point for human review and intervention
   - Avoids over-engineering and unnecessary complexity
   - Maintains rigid adherence to specified requirements only

7. **Output format**: Present each child PRD as a separate, complete document with clear headers, requirements, and implementation guidance. Include a summary explaining the breakdown rationale and dependencies between chunks.

Your goal is to transform complex PRDs into actionable, testable development phases that enable iterative progress with clear validation points. Always err on the side of smaller, more focused chunks rather than large, complex ones.
</file>

<file path=".claude/agents/readme-updater.md">
---
name: readme-updater
description: Use this agent when you need to update a README file to reflect recent implementation changes, new features, or architectural updates. Examples: <example>Context: The user has just implemented a new authentication system and wants the README updated. user: 'I just added OAuth integration to the app' assistant: 'I'll use the readme-updater agent to analyze the new OAuth implementation and update the README accordingly'</example> <example>Context: After refactoring the project structure, the user wants documentation updated. user: 'The project structure has changed significantly since the README was written' assistant: 'Let me use the readme-updater agent to review the current codebase structure and update the README to match'</example>
model: sonnet
---

You are a Technical Documentation Specialist with expertise in creating clear, comprehensive README files that accurately reflect current codebase implementation. Your role is to analyze existing code, identify changes since the last README update, and produce documentation that serves both new users and returning developers.

When updating a README, you will:

1. **Analyze Current Implementation**: Thoroughly examine the codebase to understand:
   - Project structure and architecture
   - Key features and functionality
   - Dependencies and requirements
   - Setup and installation procedures
   - Usage patterns and examples
   - API endpoints or interfaces
   - Configuration options

2. **Identify Documentation Gaps**: Compare the existing README against current implementation to find:
   - Outdated information that needs correction
   - New features or components not documented
   - Changed installation or setup procedures
   - Modified API signatures or usage patterns
   - Updated dependencies or requirements

3. **Follow Project Standards**: Adhere to any project-specific requirements, including:
   - Using Bun instead of Node.js/npm for JavaScript/TypeScript projects
   - Referencing correct command patterns (bun run, bun test, etc.)
   - Matching established code style and formatting conventions
   - Including project-specific setup requirements

4. **Structure Information Logically**: Organize the README with clear sections such as:
   - Project overview and purpose
   - Prerequisites and system requirements
   - Installation and setup instructions
   - Usage examples and basic operations
   - API documentation (if applicable)
   - Configuration options
   - Development setup and contributing guidelines
   - Troubleshooting common issues

5. **Ensure Accuracy and Completeness**: Verify that all instructions are:
   - Tested and functional with current codebase
   - Clear and unambiguous for new users
   - Complete with necessary context and examples
   - Up-to-date with latest implementation details

6. **Maintain Professional Quality**: Write documentation that is:
   - Concise yet comprehensive
   - Well-formatted with proper markdown syntax
   - Free of technical jargon where simpler terms suffice
   - Inclusive of different user skill levels

Before making changes, analyze the existing README and codebase to create a comprehensive update plan. Focus on accuracy over assumptions - if implementation details are unclear, note what requires clarification rather than guessing. Your goal is to create documentation that eliminates friction for anyone trying to understand, install, or contribute to the project.
</file>

<file path=".claude/commands/ai-commit.md">
# AI-Powered Git Commit Assistant

You are an expert software developer and Git practitioner. Your task is to analyze git diffs and create logical, atomic commits from staged or unstaged changes.

DO NOT write "authored by claude code"

## Your Responsibilities

1. **Analyze Git Changes**: Examine the provided git diff and file contents
2. **Group Related Changes**: Identify logical groupings of changes that should be committed together
3. **Generate Commit Messages**: Create concise, conventional commit messages following best practices
4. **Execute Git Commands**: Run the necessary git commands to create the atomic commits
5. **Provide Clear Feedback**: Show the user what you're doing at each step

## Process Flow

### Step 1: Analyze the Repository State
First, check what changes are available:

```bash
# Check overall git status
git status

# Get staged changes (if any)
git diff --staged --name-only
git diff --staged

# Get unstaged changes (if any)  
git diff --name-only
git diff
```

### Step 2: Read File Contents
For each changed file, read its current content to understand the context:

```bash
# Read file contents for context
cat filename.ext
```

### Step 3: Analyze and Plan Commits
Based on the diff and file contents, determine:
- Which changes are related and should be grouped together
- What type of change each group represents (feat, fix, docs, refactor, etc.)
- Appropriate commit messages following conventional commit format

### Step 4: Present the Plan
Show the user your proposed commit plan in this format:

```
Proposed Commit Plan:
=====================

Commit 1: FEAT: Add user authentication system
Files: auth.py, models/user.py, routes/auth.py

Commit 2: DOCS: Update API documentation for auth endpoints  
Files: README.md, docs/api.md

Commit 3: FIX: Resolve login validation edge case
Files: auth.py, tests/test_auth.py
```

### Step 5: Execute the Commits
If the user approves, execute the commits:

```bash
# Reset staging area to start fresh
git reset HEAD .

# For each commit:
# 1. Stage the specific files
git add file1.py file2.py

# 2. Create the commit
git commit -m "FEAT: Add user authentication system"

# 3. Repeat for next commit...
```

## Commit Message Guidelines

Use conventional commit format:
- **FEAT**: New features
- **FIX**: Bug fixes  
- **DOCS**: Documentation changes
- **REFACTOR**: Code refactoring
- **TEST**: Adding or updating tests
- **CHORE**: Maintenance tasks
- **STYLE**: Code style/formatting changes
- **PERF**: Performance improvements

Format: `TYPE: Brief description (50 chars max)

Detailed change descriptions (example):
 - Add user authentication system
 - Update API documentation for auth endpoints
 - Resolve login validation edge case
`

## File Analysis Guidelines

When reading files:
- **Limit content**: For large files (>5000 chars), focus on changed sections
- **Understand context**: Look at imports, function signatures, and overall structure
- **Identify relationships**: Note how changes in different files relate to each other

## Safety Guidelines

- **Always confirm**: Present the plan before executing any git commands
- **Preserve work**: Never force push or perform destructive operations
- **Handle errors**: If a git command fails, explain the issue and suggest solutions
- **Validate files**: Ensure all files in commit plan actually exist and have changes
</file>

<file path=".claude/commands/analyze-project.md">
# Analyze Project Structure
> Comprehensive project analysis and documentation
> Develop plan before analyzing project
> Check with human before analyzing project

## Commands to run:
```bash
# Tree view (if eza available)
eza . --tree --git-ignore --level 3

# Alternative with standard tools
find . -type f -name "*.md" -o -name "*.json" -o -name "*.ts" -o -name "*.py" | head -20

# Check for key files
ls -la README.md package.json pyproject.toml .env .gitignore
```

## Files to read in parallel:
- README.md
- package.json / pyproject.toml
- Any .claude/CLAUDE.md file
- Key source files in src/ or lib/
</file>

<file path=".claude/commands/architect.md">
# architect

Generate or update the project's ARCHITECTURE.md file with comprehensive architectural documentation

## Usage

```
architect [update-reason]
```

## Arguments

- `update-reason` (optional): Brief description of why architecture is being updated (e.g., "added news collection", "refactored feed components")

## Process

### 1. Analysis Phase
- Scan entire codebase structure
- Identify key directories and their purposes
- Map component relationships
- Document data flows
- Identify external dependencies

### 2. Documentation Generation
Creates or updates `/ARCHITECTURE.md` with three levels of detail:
- **High-level**: System overview and core concepts
- **Medium-level**: Component interactions and data flows
- **Low-level**: Implementation specifics and code patterns

### 3. Update Tracking
- Preserves revision history section
- Adds entry for current update with timestamp
- Notes significant changes if updating existing file

## ARCHITECTURE.md Structure

```markdown
# Project Architecture

## Last Updated: <timestamp>
## Version: <version>

## 1. High-Level Overview

### 1.1 System Purpose
Brief description of what the application does

### 1.2 Core Technologies
- Framework: (e.g., Astro)
- Styling: (e.g., CSS-in-JS, Tailwind)
- Data: (e.g., Content Collections, APIs)
- Build: (e.g., Vite, Webpack)

### 1.3 Architecture Pattern
- Pattern type (e.g., Component-based, MVC)
- Key architectural decisions
- Design principles followed

## 2. Medium-Level Architecture

### 2.1 Directory Structure
```
project-root/
├── src/
│   ├── components/     # Reusable UI components
│   ├── pages/          # Route pages
│   ├── layouts/        # Page layouts
│   ├── content/        # Content collections
│   └── styles/         # Global styles
├── public/             # Static assets
├── specs/              # PRDs and reports
└── .claude/            # Claude commands
```

### 2.2 Component Hierarchy
- Layout components
- Page components
- Shared components
- Utility components

### 2.3 Data Flow
- Content sourcing
- State management
- API interactions
- Build-time vs runtime data

### 2.4 Routing Strategy
- Static vs dynamic routes
- Route parameters
- Navigation patterns

## 3. Low-Level Implementation Details

### 3.1 Component Patterns

#### Component Structure
```astro
---
// Frontmatter: Data fetching and logic
---
<!-- Template: HTML structure -->
<style>/* Scoped styles */</style>
<script>/* Client-side behavior */</script>
```

### 3.2 Naming Conventions
- Files: PascalCase for components, kebab-case for pages
- CSS: BEM methodology or utility classes
- JavaScript: camelCase for functions, UPPER_CASE for constants

### 3.3 Key Components

#### Layout.astro
- Purpose: Main page wrapper
- Props: title, description, ogImage
- Children: Page content

#### BrutalSection.astro
- Purpose: Consistent brutal design container
- Props: title, background
- Usage: Wraps content sections

### 3.4 Content Collections

#### Schema Definitions
- news: { date, title, published }
- feed: { username, location, timestamp, comment, published }
- leads: { name, email, visitor_type, etc. }

### 3.5 Styling Architecture
- CSS Variables for theming
- Component-scoped styles
- Global utility classes
- Responsive breakpoints

### 3.6 Build Pipeline
- Development: npm run dev
- Production: npm run build
- Preview: npm run preview

## 4. External Integrations

### 4.1 Third-party Services
- Analytics
- CMS (if applicable)
- APIs

### 4.2 Dependencies
Critical npm packages and their purposes

## 5. Performance Considerations

### 5.1 Optimization Strategies
- Image optimization
- Code splitting
- Lazy loading
- Caching strategies

### 5.2 Bundle Size
- Current size metrics
- Optimization opportunities

## 6. Security Considerations

### 6.1 Data Handling
- Input validation
- XSS prevention
- CSRF protection

### 6.2 Environment Variables
- Required variables
- Security best practices

## 7. Development Workflow

### 7.1 Local Development
Setup and running instructions

### 7.2 Testing Strategy
- Unit tests
- Integration tests
- E2E tests

### 7.3 Deployment
- Build process
- Hosting platform
- CI/CD pipeline

## 8. Maintenance & Evolution

### 8.1 Technical Debt
Known issues and planned improvements

### 8.2 Scalability Considerations
How the architecture supports growth

### 8.3 Migration Paths
Potential future architectural changes

## 9. Revision History

| Date | Version | Changes | Author |
|------|---------|---------|--------|
| <date> | <version> | <changes> | <agent/user> |
```

## Implementation Guidelines

### When to Run
- After implementing new features
- After refactoring existing code
- When onboarding new team members
- Before major architectural decisions
- As part of implement-prd completion

### Analysis Scope
The command should analyze:
- All source files in src/
- Configuration files (astro.config.*, package.json, etc.)
- Content structure and schemas
- Public assets organization
- Build outputs

### Code Inspection
For each major component/module:
1. Identify purpose and responsibilities
2. Document inputs/outputs
3. Note dependencies
4. Highlight patterns used

### Pattern Recognition
Identify and document:
- Repeated code patterns
- Naming conventions
- File organization patterns
- Common utilities
- Shared styles

## Example Usage

```bash
# Initial architecture documentation
architect

# After feature implementation
architect "implemented dynamic countdown timer"

# After refactoring
architect "refactored component structure for better reusability"
```

## Output Behavior

### Creating New File
- Performs comprehensive analysis
- Documents all architectural aspects
- Establishes baseline for future updates

### Updating Existing File
- Preserves revision history
- Updates changed sections
- Adds new components/features
- Marks deprecated items
- Updates timestamp and version

## Quality Checks

Before finalizing:
- [ ] All major directories documented
- [ ] Component relationships clear
- [ ] Data flows explained
- [ ] Build process documented
- [ ] Dependencies listed
- [ ] Naming conventions specified
- [ ] Recent changes reflected
- [ ] No outdated information

## Notes

- Keep descriptions concise but comprehensive
- Use diagrams where helpful (ASCII or Mermaid)
- Focus on "why" not just "what"
- Document architectural decisions and trade-offs
- Include both current state and planned improvements
- Make it useful for both new and existing team members
</file>

<file path=".claude/commands/code-cleanup.md">
# Code Cleanup
> Clean up codebase for improved readability and maintainability
> Develop plan before refactoring
> Check with human before refactoring

## Cleanup Tasks:
1. Format code consistently
2. Remove commented-out code
3. Update stale comments
4. Fix linting warnings
5. Organize imports
6. Remove debug statements

## Tools:
- Linters (ruff for Python, ESLint for JS/TS)
- Formatters (black, prettier)
- Type checkers (mypy, tsc)
</file>

<file path=".claude/commands/code-review.md">
# Code Review
> Comprehensive code review and analysis
> Develop plan before code review
> Check with human before code review

## Review Process:
1. Analyze code quality and patterns
2. Check for potential bugs or issues
3. Evaluate performance implications
4. Review security considerations
5. Suggest improvements

Focus areas:
- Code clarity and readability
- Error handling
- Edge cases
- Naming conventions
- Documentation completeness
</file>

<file path=".claude/commands/commit-all.md">
# Commit All Changes
> Systematically review and commit all staged changes
> Check with human before committing changes

## Steps:
1. Show current git status
2. Review all changes with git diff
3. Create detailed commit message covering all changes
4. Commit with comprehensive message

```bash
git status
git diff --staged
# Analyze changes and create detailed commit message
git commit -m "Comprehensive commit message here"
```
</file>

<file path=".claude/commands/create-prd.md">
# create-prd

Create a Product Requirements Document (PRD) for a feature or component with phase-based organization

## Usage

```
create-prd <feature-name> <description>
```

## Arguments

- `feature-name`: The name of the feature/component (lowercase, hyphens only, e.g., `user-auth`)
- `description`: Brief description of what needs to be documented

## Process

1. Analyze the current implementation of the feature/component if it exists
2. Identify problems, requirements, and design specifications
3. Create a comprehensive PRD document
4. Save to `docs/specs/` directory with filename format: `<feature-name>.prd.md` (lowercase, hyphens only)

Filename examples: `user-auth.prd.md`, `navigation-menu.prd.md`, `auth-removal.prd.md`

## PRD Structure

The PRD should include:

1. **Executive Summary** - Brief overview of the feature
2. **Problem Statement** - Current issues and pain points
3. **Requirements** - Functional and technical specifications
   - User requirements
   - Technical requirements
   - Design requirements
4. **Implementation Phases** - Logical organization (no timeline estimates)
   - Phase 1: Core functionality
   - Phase 2: ...etc
5. **Implementation Notes** - Code examples and technical approach
6. **Security Considerations** - Authentication, authorization, data validation only (if applicable)
7. **Success Metrics** - How to measure success (if applicable; do not make stuff up)
8. **Future Enhancements** - Potential improvements

## Anti-Over-Engineering Guidelines
- Specify minimum viable requirements only
- Avoid premature optimization requirements
- Use existing patterns and components where possible
- Don't specify features beyond core needs
- Prefer simple, maintainable solutions

## Examples

```
create-prd navigation-menu "Update navigation menu with mobile hamburger"
```
Creates: `docs/specs/navigation-menu.prd.md`

```
create-prd user-auth "Design user authentication flow"
```
Creates: `docs/specs/user-auth.prd.md`

## File Naming Convention

- Use lowercase with hyphens only (kebab-case)
- Always end with `.prd.md`
- Place in `docs/specs/` directory
- Conform to existing directory naming conventions
- Examples:
  - `feed-design.prd.md`
  - `navigation-update.prd.md`
  - `auth-flow.prd.md`
  - `supabase-auth-removal.prd.md`

## Notes

- Include visual mockups using ASCII diagrams where helpful
- Add code snippets for implementation guidance
- Consider mobile-first design approach
- Document critical edge cases and error states only
- **NO timeline estimates** - use phases only
- Focus on minimum viable requirements
- Only specify critical security considerations
- Include date in the document (version numbers are optional)
</file>

<file path=".claude/commands/find-dead-code.md">
# Find Dead Code
> Identify and remove unused code
> Develop plan before find dead code
> Check with human before find dead code

## Analysis Process:
1. Identify unused imports
2. Find unreferenced functions
3. Locate unreachable code paths
4. Detect unused variables
5. Find obsolete configuration

## Tools to use:
- Static analysis tools for the language
- Git history to understand code evolution
- Test coverage reports
</file>

<file path=".claude/commands/implement-prd.md">
# implement-prd

Implement a Product Requirements Document (PRD) using Test-Driven Development approach with phased execution and change logging

## Usage

```
implement-prd <prd-filename> [thinking-mode]
```

## Arguments

- `prd-filename`: Name of the PRD file in docs/specs/ (lowercase, hyphens only, e.g., `auth-removal`)
- `thinking-mode` (optional): 
  - `think` - Standard implementation with basic reasoning
  - `think-harder` - Enhanced analysis with deeper consideration
  - `ultrathink` - Use mcp__sequential-thinking__sequentialthinking for complex reasoning

## Process

### 1. Setup Phase
- Read the PRD from `docs/specs/<prd-filename>.prd.md`
- Create implementation report at `docs/specs/<prd-filename>-implementation-report.md`
- Create change log at `docs/specs/<prd-filename>-change-log.md`
- Initialize git status check
- Create TodoWrite list with all tasks

### 2. Task Breakdown
Extract tasks from PRD and break down into:
- Primary tasks (from main requirements)
- Subtasks (atomic, testable units)
- Dependencies between tasks
- **Phase organization** (no timeline estimates - organize by logical sequence only)

### 3. Anti-Over-Engineering Guidelines
- Implement minimum viable solution first
- Avoid premature optimization
- Use existing patterns and components where possible
- Don't add features not specified in PRD
- Prefer simple, readable code over clever solutions
- Only add abstractions when you have 3+ use cases

### 4. TDD Implementation Loop

For each task:

#### a. Pre-Implementation
```bash
git status  # Verify clean working tree
```

#### b. Test Creation (if applicable)
- Write failing test for the feature
- Run test to confirm failure
- Commit test with message: `test: add test for <feature>`

#### c. Implementation
- Implement minimal code to pass test
- Verify implementation works
- Run any existing tests

#### d. Commit Atomic Change
```bash
git add <specific-files>
git commit -m "<type>: <description>"
```

Commit message types:
- `feat:` New feature
- `fix:` Bug fix
- `style:` Formatting, missing semicolons, etc.
- `refactor:` Code restructuring
- `test:` Adding tests
- `docs:` Documentation only
- `chore:` Maintenance

#### e. Verify & Document
- Run `git status` to confirm clean staging
- Update change log with specific file changes and rationale
- Update report with task completion
- Mark task as completed in TodoWrite

### 5. Task Order

1. **Setup & Configuration**
   - Dependencies installation
   - Configuration updates
   - Type definitions

2. **Core Functionality**
   - Data structures
   - Business logic
   - API integrations

3. **UI Components**
   - Layout changes
   - Visual components
   - Animations

4. **Testing & Validation**
   - Unit tests
   - Integration tests
   - Manual verification

5. **Documentation**
   - Code comments (only when complex logic requires explanation)
   - README updates (if public API changes)
   - update ARCHITECTURE.md (invoke .claude/commands/architect.md)
   - Report and change log finalization

### 6. Report Structure

The implementation report should include:

```markdown
# Implementation Report: <Feature Name>
## Date: <Current Date>
## PRD: <prd-filename>.prd.md

## Phases Completed
- [x] Phase 1: Setup & Configuration
  - Tasks: <brief-list>
  - Commits: <commit-range>
- [x] Phase 2: Core Implementation
  - Tasks: <brief-list>
  - Commits: <commit-range>

## Testing Summary
- Tests written: <count>
- Tests passing: <count>
- Manual verification: <status>

## Challenges & Solutions
- Challenge 1: Description
  - Solution: How it was resolved

## Critical Security Notes
- Authentication/Authorization changes: <details>
- Data validation changes: <details>
- Input sanitization: <details>

## Next Steps
- Future enhancements
- Technical debt identified
```

### 7. Change Log Structure

```markdown
# Change Log: <Feature Name>
## Date: <Current Date>

## Files Modified

### <filename>
- **Change**: <brief-description>
- **Rationale**: <why-this-change>
- **Impact**: <what-this-affects>
- **Commit**: <hash>

### <filename>
- **Change**: <brief-description>
- **Rationale**: <why-this-change>
- **Impact**: <what-this-affects>
- **Commit**: <hash>

## Dependencies Added/Removed
- Added: <package>@<version> - <reason>
- Removed: <package> - <reason>

## Breaking Changes
- <description-of-breaking-change>
- Migration required: <yes/no>
```

## Thinking Modes

### Standard (`think`)
- Analyze requirements
- Plan implementation
- Execute tasks sequentially

### Enhanced (`think-harder`)
- Deep analysis of edge cases
- Consider multiple implementation approaches
- Optimize for performance and maintainability

### Ultra (`ultrathink`)
When available, use sequential thinking MCP:
```javascript
mcp__sequential-thinking__sequentialthinking({
  thought: "Analyzing PRD requirements...",
  nextThoughtNeeded: true,
  thoughtNumber: 1,
  totalThoughts: 10
})
```

## Example Workflow

```bash
# Start implementation
implement-prd feed-design ultrathink

# Agent actions:
1. Read docs/specs/feed-design.prd.md
2. Create docs/specs/feed-design-implementation-report.md
3. Create docs/specs/feed-design-change-log.md
4. Break down into phases:
   - Phase 1: Core functionality (no timeline estimates)
     - Subtask 1.1: Add JavaScript calculation
     - Subtask 1.2: Update HTML structure
   - Phase 2: Visual improvements
     - Subtask 2.1: Update grid system
     - Subtask 2.2: Adjust responsive breakpoints
5. For each subtask:
   - Implement minimal viable solution
   - Test functionality
   - Log change with rationale
   - Commit with message
   - Verify staging clean
6. Update report and change log
```

## Git Commit Guidelines

### Message Format
```
<type>(<scope>): <subject>

<body>

<footer>
```

### Examples
```bash
feat(feed): add dynamic countdown timer to September 15

Replaces static "NOW" text with calculated days remaining.
Updates daily at midnight local time.

feat(feed): update member counter to match countdown width

Removes full-width behavior and aligns with grid system.

style(feed): equalize statistics block widths

Updates grid layout for consistent visual hierarchy.
```

## Verification Checklist

Before marking task complete:
- [ ] Code follows PRD specifications exactly (no extra features)
- [ ] Tests pass (if applicable)
- [ ] No linting errors
- [ ] Git staging area is clean
- [ ] Commit message follows conventions
- [ ] Change log updated with file changes and rationale
- [ ] Report updated with task details
- [ ] Security considerations documented (if applicable)

## Error Handling

If implementation fails:
1. Document error in report
2. Attempt alternative approach
3. If blocked, note in report and continue with next task
4. Create TODO for resolution

## Notes

- Always verify git status before and after commits
- Keep commits atomic and focused
- Document any deviations from PRD in report
- Use thinking mode appropriate to complexity
- Test each change before committing
- Update TodoWrite list throughout process
- **NO timeline estimates** - organize by phases only
- Focus on minimum viable implementation
- Maintain detailed change log for code review
- Only implement critical security measures specified in PRD
</file>

<file path=".claude/commands/review-staging.md">
# Review Staging Area
> Thoroughly review all changes in git staging area
> Develop plan before reviewing staging area
> Check with human before reviewing staging area

## Review Process:
```bash
# Show overview of staged files
git status -s

# Review each staged file's changes
git diff --staged --name-only | while read file; do
    echo "=== Changes in $file ==="
    git diff --staged "$file"
done

# Summary of changes by type
git diff --staged --stat
```
</file>

<file path=".claude/commands/test-driven.md">
# Test-Driven Development
> Implement features using TDD with autonomous testing
> Develop plan before implementing features
> Check with human before implementing features

## Process:
1. Write test first
2. Run test (expect failure)
3. Implement minimal code to pass
4. Refactor if needed
5. Commit atomically

```bash
# Example for Python
uv run pytest tests/test_feature.py -v

# Example for TypeScript/Bun
bun test feature.test.ts
```
</file>

<file path=".claude/commands/variant.md">
**VARIANT GENERATION COMMAND**

This command generates content based on a specification.

**Variables:**

spec_file: $ARGUMENTS
output_dir: $ARGUMENTS
count: $ARGUMENTS

**ARGUMENTS PARSING:**
Parse the following arguments from "$ARGUMENTS":
1. `spec_file` - Path to the markdown specification file
2. `output_dir` - Directory where iterations will be saved  
3. `count` - Number of iterations to generate

**PHASE 1: SPECIFICATION ANALYSIS**
Read and understand the specification file at `spec_file`. This file defines:
- What type of content to generate
- The format and structure requirements
- Any specific parameters or constraints

**PHASE 2: OUTPUT DIRECTORY RECONNAISSANCE** 
Analyze the `output_dir` to understand the current state:
- List all existing files and their naming patterns
- Identify the highest iteration number currently present

**PHASE 3: ITERATION STRATEGY**
Based on the spec analysis and existing iterations:
- Determine the starting iteration number (highest existing + 1)
- Plan how each new iteration will be unique.

**PHASE 4: PARALLEL EXECUTION**
Deploy multiple Sub Agents to generate iterations in parallel.

**Sub-Agent Distribution Strategy:**
- For count 1-5: Launch all agents simultaneously 
- For count > 5: Launch in batches of 5 agents.

**Agent Assignment Protocol:**
Each Sub Agent receives:
1. **Spec Context**: Complete specification file analysis
2. **Directory Snapshot**: Current state of output_dir at launch time
3. **Iteration Assignment**: Specific iteration number (starting_number + agent_index)
4. **Uniqueness Directive**: Explicit instruction to avoid duplicating concepts from existing iterations
5. **Quality Standards**: Detailed requirements from the specification

**Agent Task Specification:**
```
TASK: Generate iteration [NUMBER] for [SPEC_FILE] in [OUTPUT_DIR]

You are Sub Agent [X] generating iteration [NUMBER]. 

CONTEXT:
- Specification: [Full spec analysis]
- Existing iterations: [Summary of current output_dir contents]
- Your iteration number: [NUMBER]

REQUIREMENTS:
1. Read and understand the specification completely
2. Analyze existing iterations to ensure your output is unique
3. Generate content following the spec format exactly
4. Create file with exact name pattern specified
5. Ensure your iteration adds genuine value and novelty


DELIVERABLE: Single file as specified, with unique innovative content
```

**Parallel Execution Management:**
- Launch all assigned Sub Agents simultaneously using Task tool
- Monitor agent progress and completion
- Handle any agent failures by reassigning iteration numbers
- Ensure no duplicate iteration numbers are generated
- Collect and validate all completed iterations

**PHASE 5: BATCH ORCHESTRATION**
For large-count generation, orchestrate parallel batches until the count is reached:

**Batch-Based Generation:**
1. **Batch Planning**: Determine next batch size (e.g., 5 agents)
2. **Agent Preparation**: Prepare context for each new batch
3. **Context Monitoring**: Track total context usage.
4. **Graceful Conclusion**: Complete current batch and summarize.

**Execution Cycle:**
```
WHILE generated_iterations < count:
    1. Assess current output_dir state
    2. Plan next batch of agents
    3. Launch parallel Sub Agent batch
    4. Monitor batch completion
    5. Update directory state snapshot
```

**EXECUTION PRINCIPLES:**

**Quality & Uniqueness:**
- Each iteration must be genuinely unique and valuable
- Maintain consistency with the original specification
- Ensure proper file organization and naming

**Parallel Coordination:**
- Deploy Sub Agents strategically to maximize creative diversity
- Assign distinct innovation dimensions to each agent to avoid overlap
- Coordinate timing to prevent file naming conflicts
- Monitor all agents for successful completion and quality

**Agent Management:**
- Provide each Sub Agent with complete context and clear assignments
- Handle agent failures gracefully with iteration reassignment
- Ensure all parallel outputs integrate cohesively.
</file>

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "WebFetch(domain:decapcms.org)",
      "WebFetch(domain:github.com)",
      "WebFetch(domain:www.npmjs.com)",
      "WebFetch(domain:registry.npmjs.org)",
      "WebFetch(domain:api.github.com)",
      "WebFetch(domain:raw.githubusercontent.com)",
      "Bash(cp:*)",
      "Bash(mv:*)",
      "Bash(rm:*)",
      "Bash(mkdir:*)",
      "Bash(rmdir:*)",
      "Bash(touch:*)",
      "Bash(chmod:*)",
      "Bash(chown:*)",
      "Bash(ls:*)",
      "Bash(find:*)",
      "Bash(grep:*)",
      "Bash(cat:*)",
      "Bash(head:*)",
      "Bash(tail:*)",
      "Bash(wc:*)",
      "Bash(sort:*)",
      "Bash(uniq:*)",
      "Bash(awk:*)",
      "Bash(sed:*)",
      "Bash(curl:*)",
      "Bash(wget:*)",
      "Bash(ping:*)",
      "Bash(telnet:*)",
      "Bash(git:*)",
      "Bash(node:*)",
      "Bash(npm:*)",
      "Bash(npx:*)",
      "Bash(yarn:*)",
      "Bash(pnpm:*)",
      "Bash(bun:*)",
      "Bash(webpack:*)",
      "Bash(vite:*)",
      "Bash(rollup:*)",
      "Bash(parcel:*)",
      "Bash(esbuild:*)",
      "Bash(turbo:*)",
      "Bash(jest:*)",
      "Bash(vitest:*)",
      "Bash(mocha:*)",
      "Bash(cypress:*)",
      "Bash(playwright:*)",
      "Bash(eslint:*)",
      "Bash(prettier:*)",
      "Bash(stylelint:*)",
      "Bash(tsc:*)",
      "Bash(serve:*)",
      "Bash(http-server:*)",
      "Bash(nodemon:*)",
      "Bash(pm2:*)",
      "Bash(docker:*)",
      "Bash(docker-compose:*)",
      "Bash(which:*)",
      "Bash(whereis:*)",
      "Bash(env:*)",
      "Bash(echo:*)",
      "Bash(pwd:*)",
      "Bash(whoami:*)",
      "Bash(date:*)",
      "Bash(ps:*)",
      "Bash(kill:*)",
      "Bash(killall:*)",
      "Bash(top:*)",
      "Bash(htop:*)",
      "mcp__github__search_code",
      "mcp__sequential-thinking__sequentialthinking",
      "Read(/Users/oceanheart/Library/Application Support/CleanShot/media/media_WiRyjEARle/**)"
    ],
    "deny": [],
    "ask": []
  },
  "hooks": {
    "SessionEnd": [
      {
        "hooks": [
          {
            "type": "command",
            "command": "osascript -e 'display notification \"Claude session ended\" with title \"Claude Code\"'"
          }
        ]
      }
    ]
  }
}
</file>

<file path=".github/workflows/test.yml">
name: Watson Testing Infrastructure

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_DB: watson_test
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Set up Node.js and Bun
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install Bun
      run: |
        curl -fsSL https://bun.sh/install | bash
        echo "$HOME/.bun/bin" >> $GITHUB_PATH

    - name: Set up Ruby
      uses: ruby/setup-ruby@v1
      with:
        ruby-version: '3.4.5'

    - name: Install UV (Python package manager)
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Cache Python dependencies
      uses: actions/cache@v3
      with:
        path: ~/.cache/uv
        key: ${{ runner.os }}-uv-${{ hashFiles('backend/pyproject.toml') }}

    - name: Cache Bun dependencies
      uses: actions/cache@v3
      with:
        path: ~/.bun/install/cache
        key: ${{ runner.os }}-bun-${{ hashFiles('package.json') }}

    - name: Cache Ruby dependencies
      uses: actions/cache@v3
      with:
        path: vendor/bundle
        key: ${{ runner.os }}-gems-${{ hashFiles('**/Gemfile.lock') }}
        restore-keys: |
          ${{ runner.os }}-gems-

    - name: Install Python dependencies
      run: |
        cd backend
        uv venv
        source .venv/bin/activate
        uv pip install -r pyproject.toml

    - name: Install JavaScript dependencies
      run: bun install

    - name: Install Ruby dependencies
      run: |
        bundle config path vendor/bundle
        bundle install --jobs 4 --retry 3

    - name: Set up environment variables
      run: |
        echo "DJANGO_ENVIRONMENT=test" >> $GITHUB_ENV
        echo "DB_NAME=watson_test" >> $GITHUB_ENV
        echo "DB_USER=postgres" >> $GITHUB_ENV
        echo "DB_PASSWORD=postgres" >> $GITHUB_ENV
        echo "DB_HOST=localhost" >> $GITHUB_ENV
        echo "DB_PORT=5432" >> $GITHUB_ENV
        echo "SECRET_KEY=test-secret-key-for-ci" >> $GITHUB_ENV

    - name: Run Django migrations
      run: |
        cd backend
        source .venv/bin/activate
        python manage.py migrate --run-syncdb

    - name: Run TypeScript type checking
      run: bun run typecheck

    - name: Run Frontend tests (Bun)
      run: bun test frontend/ --preload ./bun.test.config.ts

    - name: Run Backend tests (Django)
      run: |
        cd backend
        source .venv/bin/activate
        DJANGO_ENVIRONMENT=test python manage.py test --verbosity=2

    - name: Run Ruby tests (RSpec)
      run: bundle exec rspec --format documentation

    - name: Generate Coverage Reports
      run: npm run coverage

    - name: Upload Django Coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: backend/htmlcov/coverage.xml
        flags: backend
        name: django-coverage

    - name: Upload Ruby Coverage to Codecov
      uses: codecov/codecov-action@v3
      with:
        file: coverage/.resultset.json
        flags: ruby
        name: ruby-coverage

  build:
    runs-on: ubuntu-latest
    needs: test

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js and Bun
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Install Bun
      run: |
        curl -fsSL https://bun.sh/install.sh | bash
        echo "$HOME/.bun/bin" >> $GITHUB_PATH

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install UV (Python package manager)
      run: |
        curl -LsSf https://astral.sh/uv/install.sh | sh
        echo "$HOME/.cargo/bin" >> $GITHUB_PATH

    - name: Install dependencies
      run: |
        bun install
        cd backend
        uv venv
        source .venv/bin/activate
        uv pip install -r pyproject.toml

    - name: Run production build
      run: |
        export NODE_ENV=production
        npm run build:prod

    - name: Validate build artifacts
      run: npm run validate:build
</file>

<file path="backend/core/admin.py">
from django.contrib import admin

# Register your models here.
</file>

<file path="backend/core/apps.py">
from django.apps import AppConfig


class CoreConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'core'
</file>

<file path="backend/core/models.py">
from django.db import models

# Create your models here.
</file>

<file path="backend/core/test_models.py">
# Core App Model Tests
# Tests for core models and functionality

from django.test import TestCase
from django.contrib.auth.models import User
from django.db import models
from django.core.exceptions import ValidationError


class CoreModelsTestCase(TestCase):
    """Test cases for core model functionality."""
    
    def setUp(self):
        """Set up test data before each test."""
        self.test_user = User.objects.create_user(
            username='testuser',
            email='test@example.com',
            password='testpass123'
        )
    
    def test_user_creation(self):
        """Test that users can be created successfully."""
        self.assertEqual(self.test_user.username, 'testuser')
        self.assertEqual(self.test_user.email, 'test@example.com')
        self.assertTrue(self.test_user.check_password('testpass123'))
    
    def test_user_str_representation(self):
        """Test string representation of user model."""
        self.assertEqual(str(self.test_user), 'testuser')
    
    def tearDown(self):
        """Clean up after each test."""
        User.objects.all().delete()
</file>

<file path="backend/core/tests.py">
from django.test import TestCase

# Create your tests here.
</file>

<file path="backend/reviews/admin.py">
from django.contrib import admin

# Register your models here.
</file>

<file path="backend/reviews/apps.py">
from django.apps import AppConfig


class ReviewsConfig(AppConfig):
    default_auto_field = 'django.db.models.BigAutoField'
    name = 'reviews'
</file>

<file path="backend/reviews/models.py">
from django.db import models

# Create your models here.
</file>

<file path="backend/reviews/tests.py">
from django.test import TestCase

# Create your tests here.
</file>

<file path="backend/reviews/views.py">
from django.shortcuts import render

# Create your views here.
</file>

<file path="backend/watson/settings/__init__.py">
# Django settings module selector
# Automatically loads the appropriate settings based on environment

import os

# Default to base settings, can be overridden with DJANGO_SETTINGS_MODULE
ENVIRONMENT = os.environ.get('DJANGO_ENVIRONMENT', 'development')

if ENVIRONMENT == 'test':
    from .test import *
elif ENVIRONMENT == 'production':
    from .production import *
else:
    from .base import *
</file>

<file path="backend/watson/settings/production.py">
# Django Production Settings for Watson
# Security-focused settings for production deployment

from .base import *
import os

# Production must have these environment variables
DEBUG = False
SECRET_KEY = os.environ.get('SECRET_KEY')
if not SECRET_KEY:
    raise ValueError("SECRET_KEY environment variable is required in production")

ALLOWED_HOSTS = os.environ.get('ALLOWED_HOSTS', '').split(',')

# Database - must use PostgreSQL in production
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('DB_NAME'),
        'USER': os.environ.get('DB_USER'),
        'PASSWORD': os.environ.get('DB_PASSWORD'),
        'HOST': os.environ.get('DB_HOST'),
        'PORT': os.environ.get('DB_PORT', '5432'),
        'CONN_MAX_AGE': 60,
    }
} if os.environ.get('DATABASE_URL') else DATABASES

# Security settings for production
SECURE_SSL_REDIRECT = os.environ.get('SECURE_SSL_REDIRECT', 'true').lower() == 'true'
SESSION_COOKIE_SECURE = True
CSRF_COOKIE_SECURE = True
SECURE_BROWSER_XSS_FILTER = True
SECURE_CONTENT_TYPE_NOSNIFF = True
SECURE_HSTS_SECONDS = 31536000  # 1 year
SECURE_HSTS_INCLUDE_SUBDOMAINS = True
SECURE_HSTS_PRELOAD = True
USE_X_FORWARDED_HOST = True

# Static files optimization
STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.ManifestStaticFilesStorage'

# Logging configuration for production
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'formatters': {
        'verbose': {
            'format': '{levelname} {asctime} {module} {process:d} {thread:d} {message}',
            'style': '{',
        },
    },
    'handlers': {
        'file': {
            'level': 'INFO',
            'class': 'logging.FileHandler',
            'filename': '/var/log/watson/django.log',
            'formatter': 'verbose',
        },
    },
    'loggers': {
        'django': {
            'handlers': ['file'],
            'level': 'INFO',
            'propagate': True,
        },
    },
}
</file>

<file path="backend/watson/settings/test.py">
# Django Test Settings for Watson
# Optimized settings for running tests

from .base import *
import os

# Test database - use in-memory SQLite for speed
DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': ':memory:',
        'TEST': {
            'NAME': ':memory:',
        },
    }
}

# Disable migrations during tests for speed
class DisableMigrations:
    def __contains__(self, item):
        return True
    
    def __getitem__(self, item):
        return None

MIGRATION_MODULES = DisableMigrations()

# Test-specific settings
DEBUG = False
SECRET_KEY = 'test-secret-key-not-for-production'
PASSWORD_HASHERS = [
    'django.contrib.auth.hashers.MD5PasswordHasher',  # Fast for tests
]

# Disable logging during tests
LOGGING = {
    'version': 1,
    'disable_existing_loggers': False,
    'handlers': {
        'null': {
            'class': 'logging.NullHandler',
        },
    },
    'loggers': {
        'django': {
            'handlers': ['null'],
        },
    },
}

# Test email backend
EMAIL_BACKEND = 'django.core.mail.backends.locmem.EmailBackend'

# Coverage configuration
COVERAGE_MODULE_EXCLUDES = [
    'tests$', 
    'settings$', 
    'urls$', 
    'locale$',
    '__pycache__',
    'migrations',
    'venv',
    'node_modules',
]

# Disable CORS during tests
CORS_ALLOW_ALL_ORIGINS = True
</file>

<file path="backend/watson/asgi.py">
"""
ASGI config for watson project.

It exposes the ASGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/asgi/
"""

import os

from django.core.asgi import get_asgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'watson.settings')

application = get_asgi_application()
</file>

<file path="backend/watson/wsgi.py">
"""
WSGI config for watson project.

It exposes the WSGI callable as a module-level variable named ``application``.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/howto/deployment/wsgi/
"""

import os

from django.core.wsgi import get_wsgi_application

os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'watson.settings')

application = get_wsgi_application()
</file>

<file path="backend/manage.py">
#!/usr/bin/env python
"""Django's command-line utility for administrative tasks."""
import os
import sys


def main():
    """Run administrative tasks."""
    os.environ.setdefault('DJANGO_SETTINGS_MODULE', 'watson.settings')
    try:
        from django.core.management import execute_from_command_line
    except ImportError as exc:
        raise ImportError(
            "Couldn't import Django. Are you sure it's installed and "
            "available on your PYTHONPATH environment variable? Did you "
            "forget to activate a virtual environment?"
        ) from exc
    execute_from_command_line(sys.argv)


if __name__ == '__main__':
    main()
</file>

<file path="deploy/deploy.sh">
#!/bin/bash

# Watson Deployment Automation Script
# Supports Railway, Render, Fly.io, and Docker deployment

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_DIR="$(dirname "$SCRIPT_DIR")"
PLATFORM=""
ENVIRONMENT="production"
DRY_RUN=false

print_usage() {
    echo "Usage: $0 -p <platform> [-e environment] [-d]"
    echo ""
    echo "Options:"
    echo "  -p, --platform    Deployment platform (railway|render|fly|docker)"
    echo "  -e, --environment Environment (staging|production) [default: production]"
    echo "  -d, --dry-run     Show what would be deployed without executing"
    echo "  -h, --help        Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 -p railway                 # Deploy to Railway production"
    echo "  $0 -p render -e staging       # Deploy to Render staging"
    echo "  $0 -p fly -d                  # Dry run for Fly.io deployment"
}

print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_info() {
    echo -e "${BLUE}ℹ️  $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

validate_environment() {
    print_info "Validating deployment environment..."
    
    # Check if we're on main branch for production
    if [[ $ENVIRONMENT == "production" ]]; then
        current_branch=$(git rev-parse --abbrev-ref HEAD)
        if [[ $current_branch != "main" ]]; then
            print_error "Production deployments must be from main branch (currently on: $current_branch)"
            exit 1
        fi
    fi
    
    # Check for uncommitted changes
    if [[ -n $(git status --porcelain) ]]; then
        print_error "Uncommitted changes detected. Please commit or stash changes before deployment."
        exit 1
    fi
    
    # Run tests before deployment
    print_info "Running tests before deployment..."
    if [[ $DRY_RUN == false ]]; then
        npm run test:all || {
            print_error "Tests failed. Deployment aborted."
            exit 1
        }
    else
        print_info "DRY RUN: Would run tests"
    fi
    
    print_status "Environment validation passed"
}

deploy_railway() {
    print_info "Deploying to Railway ($ENVIRONMENT)..."
    
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would deploy to Railway with:"
        print_info "  - Platform: Railway"
        print_info "  - Environment: $ENVIRONMENT"
        print_info "  - Config: deploy/railway.json"
        return
    fi
    
    # Check if Railway CLI is installed
    if ! command -v railway &> /dev/null; then
        print_error "Railway CLI is not installed. Install from: https://docs.railway.app/cli"
        exit 1
    fi
    
    # Deploy to Railway
    railway login
    railway up --json deploy/railway.json
    
    print_status "Railway deployment initiated"
}

deploy_render() {
    print_info "Deploying to Render ($ENVIRONMENT)..."
    
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would deploy to Render with:"
        print_info "  - Platform: Render"
        print_info "  - Environment: $ENVIRONMENT"
        print_info "  - Config: deploy/render.yaml"
        return
    fi
    
    print_info "Pushing to git repository (Render auto-deploys from git)..."
    git push origin main
    
    print_status "Render deployment initiated via git push"
    print_info "Monitor deployment at: https://dashboard.render.com"
}

deploy_fly() {
    print_info "Deploying to Fly.io ($ENVIRONMENT)..."
    
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would deploy to Fly.io with:"
        print_info "  - Platform: Fly.io"
        print_info "  - Environment: $ENVIRONMENT"
        print_info "  - Config: deploy/fly.toml"
        return
    fi
    
    # Check if Fly CLI is installed
    if ! command -v flyctl &> /dev/null; then
        print_error "Fly CLI is not installed. Install from: https://fly.io/docs/getting-started/installing-flyctl/"
        exit 1
    fi
    
    # Deploy to Fly.io
    flyctl auth login
    flyctl deploy --config deploy/fly.toml
    
    print_status "Fly.io deployment completed"
}

deploy_docker() {
    print_info "Building and running Docker container locally..."
    
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would build and run Docker with:"
        print_info "  - Build: docker build -t watson ."
        print_info "  - Run: docker-compose up -d"
        return
    fi
    
    # Build Docker image
    print_info "Building Docker image..."
    docker build -t watson-oceanheart-ai .
    
    # Run with Docker Compose
    print_info "Starting services with Docker Compose..."
    docker-compose up -d
    
    print_status "Docker deployment completed"
    print_info "Application available at: http://localhost:8888"
}

run_health_check() {
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would run health checks"
        return
    fi
    
    print_info "Running post-deployment health check..."
    
    # Wait a bit for deployment to settle
    sleep 30
    
    # This would need the actual URL based on platform
    print_info "Health check implementation depends on platform-specific URL"
    print_status "Health check placeholder completed"
}

# Parse command line arguments
while [[ $# -gt 0 ]]; do
    case $1 in
        -p|--platform)
            PLATFORM="$2"
            shift 2
            ;;
        -e|--environment)
            ENVIRONMENT="$2"
            shift 2
            ;;
        -d|--dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            print_usage
            exit 0
            ;;
        *)
            echo "Unknown option $1"
            print_usage
            exit 1
            ;;
    esac
done

# Validate required arguments
if [[ -z $PLATFORM ]]; then
    print_error "Platform is required"
    print_usage
    exit 1
fi

# Main execution
echo ""
echo "🚀 Watson Deployment Automation"
echo "==============================="
echo ""
print_info "Platform: $PLATFORM"
print_info "Environment: $ENVIRONMENT"
print_info "Dry Run: $DRY_RUN"
echo ""

cd "$PROJECT_DIR"

validate_environment

case $PLATFORM in
    railway)
        deploy_railway
        ;;
    render)
        deploy_render
        ;;
    fly)
        deploy_fly
        ;;
    docker)
        deploy_docker
        ;;
    *)
        print_error "Unsupported platform: $PLATFORM"
        print_usage
        exit 1
        ;;
esac

run_health_check

echo ""
print_status "Deployment process completed!"
echo ""
</file>

<file path="deploy/fly.toml">
# Fly.io deployment configuration
# Generated for Watson Clinical LLM Review Platform

app = "watson-oceanheart-ai"
primary_region = "sjc"

[build]
  dockerfile = "Dockerfile"

[env]
  DJANGO_SETTINGS_MODULE = "watson.settings.production"
  DEBUG = "False"
  PASSPORT_JWKS_URL = "https://passport.oceanheart.ai/.well-known/jwks.json"
  JWT_ALGORITHM = "RS256"
  PORT = "8000"

[[services]]
  http_checks = []
  internal_port = 8000
  processes = ["app"]
  protocol = "tcp"
  script_checks = []
  [services.concurrency]
    hard_limit = 25
    soft_limit = 20
    type = "connections"

  [[services.ports]]
    force_https = true
    handlers = ["http"]
    port = 80

  [[services.ports]]
    handlers = ["tls", "http"]
    port = 443

  [[services.tcp_checks]]
    grace_period = "1s"
    interval = "15s"
    restart_limit = 0
    timeout = "2s"

  [[services.http_checks]]
    interval = "10s"
    grace_period = "5s"
    method = "GET"
    path = "/health/"
    protocol = "http"
    timeout = "2s"
    tls_skip_verify = false

[[vm]]
  cpu_kind = "shared"
  cpus = 1
  memory_mb = 512

[deploy]
  release_command = "python manage.py migrate --noinput && python manage.py collectstatic --noinput"
</file>

<file path="deploy/railway.json">
{
  "name": "watson-oceanheart-ai",
  "description": "Watson Clinical LLM Review Platform",
  "services": {
    "web": {
      "dockerfile": "Dockerfile",
      "healthcheck": "/health/",
      "environment": {
        "DJANGO_SETTINGS_MODULE": "watson.settings.production",
        "PORT": 8000
      },
      "variables": {
        "DATABASE_URL": "${{Postgres.DATABASE_URL}}",
        "REDIS_URL": "${{Redis.REDIS_URL}}",
        "SECRET_KEY": "${{SECRET_KEY}}",
        "ALLOWED_HOSTS": "${{RAILWAY_STATIC_URL}},watson-oceanheart-ai.up.railway.app",
        "DEBUG": "False",
        "PASSPORT_JWKS_URL": "https://passport.oceanheart.ai/.well-known/jwks.json",
        "JWT_ALGORITHM": "RS256"
      }
    },
    "postgres": {
      "image": "postgres:15-alpine",
      "environment": {
        "POSTGRES_DB": "watson_production",
        "POSTGRES_USER": "watson",
        "POSTGRES_PASSWORD": "${{POSTGRES_PASSWORD}}"
      },
      "volumes": [
        {
          "mountPath": "/var/lib/postgresql/data",
          "name": "postgres_data"
        }
      ]
    },
    "redis": {
      "image": "redis:7-alpine",
      "volumes": [
        {
          "mountPath": "/data",
          "name": "redis_data"
        }
      ]
    }
  },
  "volumes": {
    "postgres_data": {},
    "redis_data": {}
  }
}
</file>

<file path="deploy/render.yaml">
# Render.com deployment configuration
# https://render.com/docs/blueprint-spec

services:
  - type: web
    name: watson-web
    env: docker
    dockerfilePath: ./Dockerfile
    region: oregon
    plan: starter
    branch: main
    healthCheckPath: /health/
    envVars:
      - key: DJANGO_SETTINGS_MODULE
        value: watson.settings.production
      - key: DATABASE_URL
        fromDatabase:
          name: watson-postgres
          property: connectionString
      - key: REDIS_URL
        fromService:
          type: redis
          name: watson-redis
          property: connectionString
      - key: SECRET_KEY
        generateValue: true
      - key: DEBUG
        value: "False"
      - key: ALLOWED_HOSTS
        value: watson-oceanheart-ai.onrender.com
      - key: PASSPORT_JWKS_URL
        value: https://passport.oceanheart.ai/.well-known/jwks.json
      - key: JWT_ALGORITHM
        value: RS256

  - type: redis
    name: watson-redis
    region: oregon
    plan: starter
    maxmemoryPolicy: allkeys-lru

databases:
  - name: watson-postgres
    databaseName: watson_production
    user: watson
    region: oregon
    plan: starter
    postgresMajorVersion: 15
</file>

<file path="docker/gunicorn.conf.py">
# Gunicorn configuration for Watson production deployment

import os

# Server socket
bind = "0.0.0.0:8000"
backlog = 2048

# Worker processes
workers = int(os.environ.get('GUNICORN_WORKERS', 3))
worker_class = "sync"
worker_connections = 1000
timeout = 30
keepalive = 2

# Restart workers after this many requests, to control memory usage
max_requests = 1000
max_requests_jitter = 100

# Logging
accesslog = "-"
errorlog = "-"
loglevel = "info"
access_log_format = '%({x-forwarded-for}i)s %(l)s %(u)s %(t)s "%(r)s" %(s)s %(b)s "%(f)s" "%(a)s" %(D)s'

# Process naming
proc_name = 'watson'

# Server mechanics
daemon = False
pidfile = '/tmp/watson.pid'
user = None
group = None
tmp_upload_dir = None

# SSL (if needed)
# keyfile = '/path/to/keyfile'
# certfile = '/path/to/certfile'

# Preload application for better memory usage
preload_app = True

# Application module and variable name
wsgi_module = 'watson.wsgi'
</file>

<file path="docker/healthcheck.sh">
#!/bin/bash
# Watson Health Check Script

set -e

# Check if Django application is responding
echo "🏥 Performing health check..."

# Test database connection
python manage.py check --database default >/dev/null 2>&1
if [[ $? -eq 0 ]]; then
    echo "✅ Database connection: OK"
else
    echo "❌ Database connection: FAILED"
    exit 1
fi

# Test HTTP response
if command -v curl >/dev/null 2>&1; then
    response=$(curl -s -o /dev/null -w "%{http_code}" http://localhost:8000/health/ || echo "000")
    if [[ $response -eq 200 ]]; then
        echo "✅ HTTP health endpoint: OK"
    else
        echo "❌ HTTP health endpoint: FAILED (${response})"
        exit 1
    fi
else
    echo "⚠️ curl not available, skipping HTTP check"
fi

# Test static files
if [[ -d /app/backend/staticfiles ]]; then
    echo "✅ Static files: OK"
else
    echo "❌ Static files: MISSING"
    exit 1
fi

# Test Ruby services (if needed)
if [[ -d /app/lib ]]; then
    echo "✅ Ruby services: Available"
fi

echo "🎉 Health check passed!"
exit 0
</file>

<file path="docker/init-db.sql">
-- Watson Database Initialization
-- Creates additional databases for testing and staging

-- Create test database
CREATE DATABASE watson_test;
GRANT ALL PRIVILEGES ON DATABASE watson_test TO watson;

-- Create staging database (if needed)
CREATE DATABASE watson_staging;
GRANT ALL PRIVILEGES ON DATABASE watson_staging TO watson;

-- Set up extensions that might be needed
\c watson_dev;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

\c watson_test;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";

\c watson_staging;
CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pg_trgm";
</file>

<file path="docs/specs/integration/010-comprehensive-style-guide.prd.md">
# Oceanheart UI Comprehensive Style Guide PRD

**Version:** 1.0  
**Date:** 2025-09-12  
**Status:** Complete Documentation

## Executive Summary

This document provides a comprehensive analysis and replication guide for the sophisticated styling system used in the Oceanheart UI project. The system leverages DaisyUI themes, custom Tailwind configurations, advanced gradient techniques, glow effects, and complex animations to create a premium, professional appearance.

---

## Core Dependencies

### Required Stack
```json
{
  "tailwindcss": "^3.4.17",
  "daisyui": "^4.12.23",
  "framer-motion": "^12.4.10"
}
```

### Essential Configuration Files
- `tailwind.config.js` - Custom animations and gradient definitions
- `app/globals.css` - Advanced CSS techniques and custom classes
- `config.ts` - Theme configuration (`synthwave`)

---

## Typography System

### 1. Hierarchical Typography Patterns

#### Main Headlines (Hero/Page Titles)
```tsx
className="font-extrabold text-4xl lg:text-6xl tracking-tight"
```
- **Usage**: Primary page headlines, hero titles
- **Responsive**: `text-4xl` mobile → `lg:text-6xl` desktop
- **Font Weight**: `font-extrabold` (800)
- **Letter Spacing**: `tracking-tight` (-0.025em)

#### Section Headings
```tsx
className="font-bold text-2xl md:text-3xl mb-4"
```
- **Usage**: Major section titles, article headings
- **Responsive**: `text-2xl` → `md:text-3xl`
- **Margin**: `mb-4` for consistent spacing

#### Subheadings with Borders
```tsx
className="font-bold text-2xl md:text-3xl mb-4 border-b border-primary/20 pb-2"
```
- **Usage**: Content section dividers
- **Border**: Subtle primary color border with 20% opacity
- **Padding**: `pb-2` for border spacing

#### Body Text (Large)
```tsx
className="text-lg md:text-xl opacity-90 leading-relaxed"
```
- **Usage**: Important descriptions, hero subtitles
- **Responsive**: `text-lg` → `md:text-xl`
- **Opacity**: `opacity-90` for subtle hierarchy
- **Line Height**: `leading-relaxed` (1.625)

#### Body Text (Standard)
```tsx
className="text-base md:text-lg leading-relaxed"
```
- **Usage**: Regular content, card descriptions
- **Line Height**: Consistent `leading-relaxed`

---

## Advanced Text Effects

### 1. Gradient Text (Primary Technique)
```tsx
className="bg-gradient-to-r from-primary to-secondary bg-clip-text text-transparent"
```

**Complete Implementation:**
```tsx
<h1 className="font-extrabold text-4xl md:text-6xl tracking-tight mb-8 bg-gradient-to-r from-primary to-secondary bg-clip-text text-transparent animate-gradient">
  Your Title Here
</h1>
```

**CSS Requirements:**
- Uses DaisyUI's `primary` and `secondary` theme colors
- `animate-gradient` class (may require custom definition)

### 2. Blue Glow Effect (Component-Level)
```tsx
// JSX with styled-jsx
<span className="text-blue-400 glow-blue">Glowing Text</span>

<style jsx global>{`
  .glow-blue {
    position: relative;
    color: #60a5fa;
    text-shadow: 0 0 10px rgba(96, 165, 250, 0.47), 0 0 17px rgba(96, 165, 250, 0.33);
    animation: pulse 3s infinite alternate;
  }
  
  @keyframes pulse {
    0% {
      text-shadow: 0 0 10px rgba(96, 165, 250, 0.47), 0 0 17px rgba(96, 165, 250, 0.33);
    }
    100% {
      text-shadow: 0 0 13px rgba(96, 165, 250, 0.6), 0 0 23px rgba(37, 99, 235, 0.47), 0 0 27px rgba(37, 99, 235, 0.27);
    }
  }
`}</style>
```

### 3. Global Glow Effects (CSS)
Add to `app/globals.css`:

```css
/* HDI-style Navigation Glow */
.hdi-nav-link {
  position: relative;
  z-index: 1;
  text-shadow: 0 0 5px rgba(255, 255, 255, 0.5), 0 0 10px rgba(255, 255, 255, 0.3);
  font-weight: bold;
}

.hdi-nav-link::before {
  content: '';
  position: absolute;
  top: -5px; left: -5px; right: -5px; bottom: -5px;
  border-radius: 8px;
  background: white;
  z-index: -1;
  opacity: 0;
  filter: blur(8px);
  box-shadow: 0 0 10px rgba(255, 255, 255, 0.8), 
              0 0 20px rgba(255, 255, 255, 0.6),
              0 0 30px rgba(255, 255, 255, 0.4);
  animation: pulse 2s infinite;
}

/* Alternative Glow Style */
.synai-nav-link {
  color: white !important;
  font-weight: bold;
  text-shadow: 0 0 5px rgba(255, 255, 255, 0.8),
               0 0 10px rgba(255, 255, 255, 0.6),
               0 0 15px rgba(255, 255, 255, 0.4);
}
```

---

## Layout and Container System

### 1. Page-Level Containers
```tsx
// Standard page wrapper
className="max-w-7xl mx-auto px-4 sm:px-8"

// Section with background
className="bg-base-100" // or bg-base-200 for alternating sections
```

### 2. Hero Section Layout
```tsx
<section className="max-w-7xl mx-auto bg-base-100 flex flex-col lg:flex-row items-center justify-center gap-16 lg:gap-20 px-8 py-8 lg:py-20">
  <div className="flex flex-col gap-10 items-center justify-center text-center w-full lg:w-1/2">
    {/* Content */}
  </div>
  <div className="lg:w-1/2 flex justify-center items-center">
    {/* Image/Visual */}
  </div>
</section>
```

### 3. Content Section Pattern
```tsx
<section className="pt-20 px-4 sm:px-8 max-w-7xl mx-auto text-center">
  {/* Centered content with responsive padding */}
</section>
```

---

## Card and Component Styling

### 1. Standard Card Pattern
```tsx
className="bg-base-200 p-6 rounded-lg shadow-sm hover:shadow-md transition-shadow"
```

### 2. Featured/Premium Card with Gradient Border
```tsx
// Container with gradient border effect
<div className="relative w-full max-w-lg">
  {/* Gradient border */}
  <div className="absolute -inset-[2px] rounded-xl bg-gradient-to-br from-secondary to-secondary-focus z-10 shadow-xl" />
  
  {/* Main card content */}
  <div className="relative z-20 h-full p-8 rounded-xl shadow-lg hover:shadow-2xl transition-all duration-300 hover:scale-105 bg-base-100">
    {/* Card content */}
  </div>
</div>
```

### 3. Pricing Display
```tsx
<p className="text-5xl lg:text-6xl font-extrabold tracking-tight bg-gradient-to-r from-primary to-secondary bg-clip-text text-transparent">
  £{formatPrice(price)}
</p>
```

### 4. CSS Grid Layout (Advanced)
```tsx
style={{
  display: 'grid', 
  gridTemplateRows: 'auto auto auto 1fr auto'
}}
```

---

## Animation System

### 1. Tailwind Custom Animations
Add to `tailwind.config.js`:

```javascript
module.exports = {
  theme: {
    extend: {
      backgroundImage: {
        gradient: "linear-gradient(60deg, #f79533, #f37055, #ef4e7b, #a166ab, #5073b8, #1098ad, #07b39b, #6fba82)",
      },
      animation: {
        opacity: "opacity 0.25s ease-in-out",
        appearFromRight: "appearFromRight 300ms ease-in-out",
        wiggle: "wiggle 1.5s ease-in-out infinite",
        popup: "popup 0.25s ease-in-out",
        shimmer: "shimmer 3s ease-out infinite alternate",
      },
      keyframes: {
        opacity: {
          "0%": { opacity: 0 },
          "100%": { opacity: 1 },
        },
        appearFromRight: {
          "0%": { opacity: 0.3, transform: "translate(15%, 0px);" },
          "100%": { opacity: 1, transform: "translate(0);" },
        },
        wiggle: {
          "0%, 20%, 80%, 100%": { transform: "rotate(0deg)" },
          "30%, 60%": { transform: "rotate(-2deg)" },
          "40%, 70%": { transform: "rotate(2deg)" },
          "45%": { transform: "rotate(-4deg)" },
          "55%": { transform: "rotate(4deg)" },
        },
        popup: {
          "0%": { transform: "scale(0.8)", opacity: 0.8 },
          "50%": { transform: "scale(1.1)", opacity: 1 },
          "100%": { transform: "scale(1)", opacity: 1 },
        },
        shimmer: {
          "0%": { backgroundPosition: "0 50%" },
          "50%": { backgroundPosition: "100% 50%" },
          "100%": { backgroundPosition: "0% 50%" },
        },
      },
    },
  },
}
```

### 2. Hover Effect Combinations
```tsx
// Scale + Shadow combination
className="hover:shadow-2xl transition-all duration-300 hover:scale-105"

// Scale with transform origin
className="hover:scale-[1.02] transition-transform duration-300"

// Combined effects
className="transition-all duration-300 hover:saturate-[1.2] shadow"
```

### 3. Pulse Effects (CSS)
```css
@keyframes pulse {
  0% {
    transform: scale(0.8);
    opacity: 0.5;
    box-shadow: 0 0 0 0 rgba(0, 255, 0, 0.7);
  }
  70% {
    transform: scale(1);
    opacity: 1;
    box-shadow: 0 0 0 6px rgba(0, 255, 0, 0);
  }
  100% {
    transform: scale(0.8);
    opacity: 0.5;
    box-shadow: 0 0 0 0 rgba(0, 255, 0, 0);
  }
}

.pulse-dot {
  animation: pulse 2s infinite;
}
```

---

## DaisyUI Integration

### 1. Theme Configuration
```javascript
// tailwind.config.js
daisyui: {
  themes: [
    "dark", "synthwave", "cyberpunk", "cmyk", 
    "black", "valentine", "coffee", "night", "winter"
  ],
}

// config.ts  
colors: {
  theme: "synthwave",
  main: themes["light"]["primary"],
}
```

### 2. Theme Color Usage
```tsx
// Primary/Secondary colors (theme-aware)
className="text-primary"
className="text-secondary" 
className="bg-primary"
className="border-primary/20"

// Base colors (background system)
className="bg-base-100"    // Main background
className="bg-base-200"    // Card/section background
className="bg-base-300"    // Subtle borders

// Content colors
className="text-base-content"      // Main text
className="text-base-content/80"   // Secondary text
className="text-base-content/70"   // Subtle text
```

### 3. Button System
```tsx
// Primary button
className="btn btn-primary btn-wide"

// Outline button
className="btn btn-outline btn-primary"

// Custom gradient button (from globals.css)
className="btn btn-gradient"
```

### 4. Global Button Styling
```css
/* Override DaisyUI button defaults */
@layer base {
  .btn-gradient {
    @apply !bg-gradient !bg-[length:300%_300%] hover:saturate-[1.2] shadow duration-100 !border-0 !border-transparent !bg-transparent animate-shimmer !text-white;
  }
  
  .btn {
    @apply !capitalize;
  }
}
```

---

## Advanced Techniques

### 1. Image Masking and Effects
```tsx
// Profile image with radial mask
<Image
  className="kai-image rounded-full object-cover"
  style={{
    transform: "scale(1.01)",
    transformOrigin: "center",
    transition: "transform 0.5s ease-in-out",
  }}
/>

/* CSS */
.kai-image {
  mask-image: radial-gradient(circle at center, black 85%, transparent 100%);
  -webkit-mask-image: radial-gradient(circle at center, black 85%, transparent 100%);
}
```

### 2. Backdrop Effects
```tsx
// Gradient backdrop with blur
className="absolute -inset-1 bg-gradient-to-r from-primary to-secondary rounded-full blur opacity-30"

// Glass morphism effect
className="p-8 bg-black/20 backdrop-blur-sm rounded-xl"
```

### 3. Terminal/Code Styling
```css
.terminal-container {
  box-shadow: 0 10px 25px rgba(0, 0, 0, 0.5);
  border: 1px solid rgba(50, 50, 50, 0.5);
}

.terminal-body {
  background-color: rgba(0, 0, 0, 0.9);
  background-image: radial-gradient(rgba(0, 150, 0, 0.05) 2px, transparent 0);
  background-size: 20px 20px;
  background-position: -10px -10px;
}

.terminal-body::before {
  content: "";
  position: absolute;
  top: 0; left: 0; right: 0; bottom: 0;
  background: linear-gradient(rgba(0, 0, 0, 0) 50%, rgba(0, 0, 0, 0.25) 50%);
  background-size: 100% 4px;
  pointer-events: none;
  z-index: 1;
}
```

### 4. Badge/Tag System
```tsx
// Featured badge positioning
<div className="absolute -top-4 left-1/2 -translate-x-1/2 z-30">
  <div className="bg-gradient-to-r from-secondary to-secondary-focus text-secondary-content px-6 py-2 rounded-full shadow-lg font-bold text-sm uppercase tracking-wider border-2 border-white">
    ⭐ Most Popular
  </div>
</div>
```

---

## Responsive Design Patterns

### 1. Typography Scaling
```tsx
// Standard progression
text-sm     →    md:text-base    →    lg:text-lg
text-base   →    md:text-lg      →    lg:text-xl
text-lg     →    md:text-xl      →    lg:text-2xl
text-2xl    →    md:text-3xl     →    lg:text-4xl
text-4xl    →    md:text-5xl     →    lg:text-6xl
```

### 2. Layout Breakpoints
```tsx
// Flex direction changes
flex-col lg:flex-row

// Grid responsiveness
grid-cols-1 md:grid-cols-3

// Width changes
w-full lg:w-1/2
```

### 3. Spacing System
```tsx
// Padding progression
px-4 sm:px-8
py-8 lg:py-20

// Gaps
gap-6 lg:gap-8
gap-12 lg:gap-20
```

---

## Implementation Checklist

### Required Setup
- [ ] Install `tailwindcss` and `daisyui`
- [ ] Configure `tailwind.config.js` with custom animations
- [ ] Set up `app/globals.css` with custom classes
- [ ] Configure DaisyUI theme (`synthwave` recommended)
- [ ] Add smooth scrolling: `scroll-behavior: smooth`

### Typography Implementation
- [ ] Define hierarchical typography classes
- [ ] Set up gradient text system
- [ ] Implement glow effects (component-level and global)
- [ ] Configure responsive scaling patterns

### Layout System
- [ ] Standard container patterns (`max-w-7xl mx-auto`)
- [ ] Responsive flex/grid systems
- [ ] Card component patterns with hover effects

### Advanced Features
- [ ] Custom animations and keyframes
- [ ] Gradient border effects for premium components
- [ ] Image masking techniques
- [ ] Terminal/code styling (if needed)

### Testing Verification
- [ ] Test across breakpoints (mobile → desktop)
- [ ] Verify theme color consistency
- [ ] Test all animation effects
- [ ] Validate hover states and transitions
- [ ] Cross-browser compatibility

---

## Usage Examples

### Complete Hero Section
```tsx
const Hero = () => {
  return (
    <section className="max-w-7xl mx-auto bg-base-100 flex flex-col lg:flex-row items-center justify-center gap-16 lg:gap-20 px-8 py-8 lg:py-20">
      <div className="flex flex-col gap-10 items-center justify-center text-center w-full lg:w-1/2">
        <h1 className="font-extrabold text-4xl lg:text-6xl tracking-tight bg-gradient-to-r from-primary to-secondary bg-clip-text text-transparent animate-gradient">
          Your Amazing Product
        </h1>
        <p className="text-lg opacity-80 leading-relaxed">
          Transform your workflow with <span className="font-semibold text-primary">advanced features</span>
        </p>
        <a href="#cta" className="btn btn-primary btn-wide mt-4">
          Get Started
        </a>
      </div>
    </section>
  );
};
```

### Premium Card Component
```tsx
const PremiumCard = ({ title, price, features, isFeatured }) => {
  return (
    <div className="relative w-full max-w-lg">
      {isFeatured && (
        <div className="absolute -inset-[2px] rounded-xl bg-gradient-to-br from-secondary to-secondary-focus z-10 shadow-xl" />
      )}
      
      <div className={`relative z-20 h-full p-8 rounded-xl shadow-lg hover:shadow-2xl transition-all duration-300 hover:scale-105 bg-base-100`}>
        <h3 className="text-xl lg:text-2xl font-bold text-primary mb-4">
          {title}
        </h3>
        <p className="text-5xl lg:text-6xl font-extrabold tracking-tight bg-gradient-to-r from-primary to-secondary bg-clip-text text-transparent mb-6">
          {price}
        </p>
        <div className="space-y-3">
          {features.map((feature, idx) => (
            <div key={idx} className="flex items-start gap-3">
              <div className="flex-shrink-0 w-5 h-5 bg-gradient-to-br from-secondary to-secondary-focus rounded-full flex items-center justify-center mt-0.5">
                <svg className="w-3 h-3 text-white" fill="currentColor" viewBox="0 0 20 20">
                  <path fillRule="evenodd" d="M16.707 5.293a1 1 0 010 1.414l-8 8a1 1 0 01-1.414 0l-4-4a1 1 0 011.414-1.414L8 12.586l7.293-7.293a1 1 0 011.414 0z" clipRule="evenodd" />
                </svg>
              </div>
              <span className="text-base-content/90 text-sm leading-relaxed">
                {feature}
              </span>
            </div>
          ))}
        </div>
      </div>
    </div>
  );
};
```

---

## Advanced Customization

### Creating Theme Variations
To adapt this system for other projects:

1. **Change DaisyUI Theme**: Update `config.ts` theme property
2. **Custom Color Scheme**: Override CSS custom properties
3. **Animation Speed**: Modify duration values in Tailwind config
4. **Typography Scale**: Adjust base font sizes and scaling ratios

### Performance Considerations
- Use `will-change` property sparingly for animations
- Prefer CSS transforms over changing layout properties
- Use `transform-gpu` class for complex animations
- Optimize gradient complexity for mobile devices

---

**This style guide provides complete replication instructions for the sophisticated Oceanheart UI design system. All techniques are production-ready and extensively tested across modern browsers and devices.**
</file>

<file path="docs/specs/integration/011-visual-design-systems-part-2.prd.md">
# Oceanheart UI Visual Design Systems Part 2 PRD
**Advanced Layout Patterns & Visual Hierarchy**

**Version:** 1.0  
**Date:** 2025-09-12  
**Status:** Complete Documentation

## Executive Summary

Based on comprehensive analysis of the live website screenshots, this document identifies and codifies the sophisticated visual design patterns that make Oceanheart UI distinctive. These patterns focus on dramatic typography scaling, strategic color contrasts, advanced layout systems, and psychological design principles that create trust and engagement.

---

## Core Visual Design Principles

### 1. **Dramatic Scale Contrast Philosophy**
The design system uses extreme scale differences to create visual hierarchy and emotional impact:

**Typography Scale Ratios:**
- **Hero Headlines**: 4-6x larger than body text
- **Section Titles**: 2-3x larger than body text
- **Supporting Text**: Consistent baseline with strategic emphasis

**Implementation Pattern:**
```tsx
// Hero scale (Image 1 - Main headline)
className="text-6xl md:text-8xl font-extrabold leading-tight"

// Secondary hero (Image 3 - "The Art of Personal AI")
className="text-5xl md:text-7xl font-extrabold leading-none"

// Section headers
className="text-3xl md:text-5xl font-bold"

// Large emphasis text
className="text-2xl md:text-3xl font-semibold"

// Body text
className="text-lg md:text-xl leading-relaxed opacity-90"
```

### 2. **Strategic Color Psychology System**

**Primary Color Palette (Identified from Screenshots):**
- **Deep Purple/Navy**: `#1a1a2e` (backgrounds, authority)
- **Electric Blue**: `#4a9eff` (primary actions, trust)
- **Hot Pink/Magenta**: `#e94c89` (urgency, attention)  
- **Soft Pink**: `#f7a8c4` (warmth, approachability)
- **Clean White**: `#ffffff` (clarity, space)

**Color Application Rules:**
```css
/* Background hierarchy */
.bg-primary-dark { background: #1a1a2e; }     /* Main backgrounds */
.bg-accent-gradient { background: linear-gradient(135deg, #e94c89, #f7a8c4); }  /* CTAs */
.bg-trust-blue { background: #4a9eff; }       /* Information blocks */

/* Text color psychology */
.text-authority { color: #ffffff; }           /* Main headlines */
.text-trust { color: #4a9eff; }              /* Key benefits */
.text-urgency { color: #e94c89; }            /* Action items */
.text-secondary { color: rgba(255,255,255,0.8); } /* Supporting text */
```

### 3. **Advanced Layout Systems**

#### **Asymmetric Content Balance Pattern**
From Images 1, 6, 7 - Creates visual interest and guides attention:

```tsx
// Two-thirds content, one-third visual (Images 1, 6)
<section className="grid grid-cols-1 lg:grid-cols-3 gap-12 items-center">
  <div className="lg:col-span-2">
    {/* Primary content - larger text block */}
  </div>
  <div className="lg:col-span-1">
    {/* Supporting visual or secondary content */}
  </div>
</section>

// Centered content with breathing room (Images 2, 3)
<section className="max-w-4xl mx-auto text-center py-20 px-6">
  {/* Centered content with generous padding */}
</section>
```

#### **Progressive Information Revelation**
From Images 4, 5 - Complex data broken into digestible stages:

```tsx
// Multi-stage information cards
<div className="grid grid-cols-1 md:grid-cols-3 gap-6 mb-12">
  {stages.map((stage, index) => (
    <div key={index} className="bg-gradient-to-br from-blue-900/50 to-purple-900/50 p-6 rounded-xl border border-blue-400/20">
      <h3 className="text-xl font-bold text-blue-400 mb-2">
        {stage.title}
      </h3>
      <p className="text-white/80 leading-relaxed">
        {stage.description}
      </p>
    </div>
  ))}
</div>
```

---

## Advanced Component Patterns

### 1. **Data Visualization Cards** (From Images 4, 5)

**Statistical Impact Cards:**
```tsx
const StatCard = ({ icon, value, label, accent = "pink" }) => {
  const accentColors = {
    pink: "from-pink-500 to-pink-400",
    blue: "from-blue-500 to-blue-400"
  };

  return (
    <div className="relative p-8 rounded-2xl bg-gradient-to-br from-pink-500/20 to-purple-600/20 border border-pink-400/30">
      {/* Icon */}
      <div className="mb-4 text-4xl">{icon}</div>
      
      {/* Large statistical value */}
      <div className="text-5xl md:text-6xl font-black text-white mb-2">
        {value}
      </div>
      
      {/* Description label */}
      <div className="text-white/80 text-lg font-medium">
        {label}
      </div>
      
      {/* Additional metrics */}
      <div className="mt-4 space-y-2">
        <div className="flex items-center text-sm text-white/70">
          <CheckIcon className="w-4 h-4 text-green-400 mr-2" />
          <span>Additional benefit</span>
        </div>
      </div>
    </div>
  );
};
```

**Usage Example:**
```tsx
<StatCard 
  icon="⏱️"
  value="5 Hours"
  label="Lost Every Week"
  metrics={[
    "260 hours yearly",
    "6.5 work weeks", 
    "£13,000+ value"
  ]}
/>
```

### 2. **Progressive Disclosure Tables** (From Image 5)

**Compound Growth Table Pattern:**
```tsx
const GrowthTable = ({ data }) => (
  <div className="bg-gradient-to-br from-blue-900/30 to-purple-900/30 rounded-2xl p-6 border border-blue-400/20">
    <div className="flex items-center mb-6">
      <TrendingUpIcon className="w-6 h-6 text-blue-400 mr-3" />
      <h3 className="text-xl font-bold text-white">Compounding Efficiency Growth</h3>
    </div>
    
    <div className="overflow-x-auto">
      <table className="w-full text-left">
        <thead>
          <tr className="border-b border-blue-400/20">
            <th className="pb-3 text-blue-400 font-semibold">Calendar</th>
            <th className="pb-3 text-blue-400 font-semibold">Avg. Weekly Hours Freed</th>
            <th className="pb-3 text-blue-400 font-semibold">Total That Year</th>
            <th className="pb-3 text-blue-400 font-semibold">Rough Equivalent</th>
          </tr>
        </thead>
        <tbody className="text-white/90">
          {data.map((row, idx) => (
            <tr key={idx} className="border-b border-white/10">
              <td className="py-4 font-semibold">{row.year}</td>
              <td className="py-4">{row.weeklyHours}</td>
              <td className="py-4 font-bold text-blue-400">{row.totalHours}</td>
              <td className="py-4 text-pink-400">{row.equivalent}</td>
            </tr>
          ))}
        </tbody>
      </table>
    </div>
    
    <p className="text-xs text-white/50 mt-4">
      * Weekly savings plateau at 40 h/w because that's the full work-week.
    </p>
  </div>
);
```

### 3. **Hero Section Variations**

#### **Type A: Asymmetric with Profile** (Images 1, 6)
```tsx
const AsymmetricHero = () => (
  <section className="min-h-screen bg-gradient-to-br from-purple-900 via-blue-900 to-indigo-900 flex items-center">
    <div className="max-w-7xl mx-auto px-6 py-12">
      <div className="grid grid-cols-1 lg:grid-cols-12 gap-12 items-center">
        {/* Content - 8 columns */}
        <div className="lg:col-span-8 space-y-8">
          <h1 className="text-6xl md:text-8xl font-extrabold leading-tight">
            <span className="text-white">Conscious AI Integration: </span>
            <span className="bg-gradient-to-r from-blue-400 to-pink-400 bg-clip-text text-transparent">
              Your Human Edge, Amplified.
            </span>
          </h1>
          
          <p className="text-xl md:text-2xl text-white/80 leading-relaxed max-w-2xl">
            Overwhelmed by AI's pace? Master it with heart, clarity, and Kai's unique guidance.
          </p>
          
          {/* Three pillars */}
          <div className="space-y-4 text-lg">
            <div className="flex items-center">
              <span className="font-bold text-white">Amplified </span>
              <span className="font-bold text-blue-400 ml-1">Consciousness</span>
            </div>
            <div className="flex items-center">
              <span className="font-bold text-white">Amplified </span>
              <span className="font-bold text-blue-400 ml-1">Sensitivity</span>
            </div>
            <div className="flex items-center">
              <span className="font-bold text-white">Amplified </span>
              <span className="font-bold text-blue-400 ml-1">Intelligence</span>
            </div>
          </div>
          
          <button className="bg-gradient-to-r from-pink-500 to-pink-400 text-white px-8 py-4 rounded-xl text-lg font-bold hover:scale-105 transition-transform">
            Integrate AI Now
          </button>
        </div>
        
        {/* Profile Image - 4 columns */}
        <div className="lg:col-span-4">
          <div className="relative">
            <div className="w-full h-[600px] rounded-3xl overflow-hidden">
              <img src="/profile-image.jpg" alt="Profile" className="w-full h-full object-cover" />
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>
);
```

#### **Type B: Centered with Cosmic Background** (Images 8, 9)
```tsx
const CosmicHero = () => (
  <section className="min-h-screen relative flex items-center justify-center text-center">
    {/* Cosmic background */}
    <div className="absolute inset-0 bg-cosmic-pattern bg-cover bg-center opacity-30" />
    <div className="absolute inset-0 bg-gradient-to-br from-purple-900/80 to-blue-900/80" />
    
    <div className="relative z-10 max-w-4xl mx-auto px-6 py-12 space-y-8">
      <h1 className="text-5xl md:text-7xl font-extrabold leading-tight">
        <span className="text-white">Ready to Integrate AI </span>
        <span className="bg-gradient-to-r from-blue-400 to-cyan-400 bg-clip-text text-transparent">
          Consciously
        </span>
        <span className="text-white">?</span>
      </h1>
      
      <p className="text-xl md:text-2xl text-white/80 leading-relaxed">
        Move from AI overwhelm to amplified human potential. Book your discovery call with Kai.
      </p>
      
      <div className="space-y-4">
        <button className="bg-gradient-to-r from-pink-500 to-pink-400 text-white px-12 py-4 rounded-xl text-lg font-bold hover:scale-105 transition-transform">
          Book Your Free Discovery Call
        </button>
        <div>
          <a href="#pricing" className="text-blue-400 hover:text-blue-300 underline">
            View All Offerings
          </a>
        </div>
      </div>
    </div>
  </section>
);
```

---

## Advanced Typography System

### **Scale-Based Hierarchy** (Observed across all images)

```css
/* Mega headlines (Images 1, 3, 8) */
.text-mega {
  font-size: clamp(3rem, 8vw, 6rem);
  font-weight: 800;
  line-height: 0.95;
  letter-spacing: -0.02em;
}

/* Large headlines (Images 2, 4) */
.text-large-headline {
  font-size: clamp(2.5rem, 6vw, 4.5rem);
  font-weight: 700;
  line-height: 1.1;
  letter-spacing: -0.01em;
}

/* Section headers (Images 5, 6, 7) */
.text-section-header {
  font-size: clamp(1.75rem, 4vw, 3rem);
  font-weight: 600;
  line-height: 1.2;
}

/* Emphasis text */
.text-emphasis {
  font-size: clamp(1.25rem, 2.5vw, 1.5rem);
  font-weight: 600;
  line-height: 1.3;
}

/* Body text */
.text-body-large {
  font-size: clamp(1rem, 2vw, 1.25rem);
  font-weight: 400;
  line-height: 1.6;
  opacity: 0.9;
}
```

### **Strategic Text Emphasis Patterns**

```tsx
// Multi-color headline pattern (Image 1)
<h1>
  <span className="text-white">Base text </span>
  <span className="bg-gradient-to-r from-blue-400 to-pink-400 bg-clip-text text-transparent">
    highlighted concept
  </span>
  <span className="text-white"> continuation</span>
</h1>

// Contrasting emphasis (Image 2)
<h2>
  <span className="text-white">We Need </span>
  <span className="text-pink-400">Big Heart</span>
  <span className="text-white"> to Meet </span>
  <span className="text-blue-400">Big Tech</span>
</h2>

// Subtle accent (Image 3)
<p>
  Complex concept with <span className="text-blue-400 font-semibold">technical term</span> integrated naturally.
</p>
```

---

## Layout & Spacing Systems

### **Responsive Grid Patterns**

#### **Two-Column Asymmetric** (Images 1, 6)
```tsx
// Desktop: 2/3 content, 1/3 visual
// Mobile: Stacked with content first
<div className="grid grid-cols-1 lg:grid-cols-3 gap-8 lg:gap-12 items-center">
  <div className="lg:col-span-2 order-2 lg:order-1">
    {/* Primary content */}
  </div>
  <div className="lg:col-span-1 order-1 lg:order-2">
    {/* Supporting visual */}
  </div>
</div>
```

#### **Three-Column Progressive** (Images 4, 5)
```tsx
// Even distribution with visual hierarchy through content
<div className="grid grid-cols-1 md:grid-cols-3 gap-6">
  {items.map((item, idx) => (
    <div key={idx} className={`
      p-6 rounded-xl border
      ${idx === 1 ? 'bg-blue-900/30 border-blue-400/30' : 'bg-purple-900/20 border-purple-400/20'}
    `}>
      <h3 className="text-xl font-bold mb-3">{item.title}</h3>
      <p className="text-white/80">{item.description}</p>
    </div>
  ))}
</div>
```

#### **Centered Single-Column** (Images 2, 3, 8)
```tsx
// Maximum content width with generous padding
<div className="max-w-4xl mx-auto text-center px-6 py-16 lg:py-24">
  {/* Centered content with breathing room */}
</div>
```

### **Spacing Scale System**
```css
/* Consistent spacing scale observed */
.space-xs { margin: 0.5rem; }      /* 8px - tight elements */
.space-sm { margin: 1rem; }        /* 16px - related elements */
.space-md { margin: 1.5rem; }      /* 24px - section breaks */
.space-lg { margin: 3rem; }        /* 48px - major sections */
.space-xl { margin: 6rem; }        /* 96px - page sections */
.space-2xl { margin: 8rem; }       /* 128px - major breaks */

/* Responsive spacing modifiers */
@media (min-width: 1024px) {
  .space-lg { margin: 4rem; }
  .space-xl { margin: 8rem; }
  .space-2xl { margin: 12rem; }
}
```

---

## Visual Component Library

### 1. **Gradient Background Patterns**

```css
/* Primary dark gradient (Images 1, 2, 8) */
.bg-primary-gradient {
  background: linear-gradient(135deg, #1a1a2e 0%, #16213e 50%, #0f172a 100%);
}

/* Cosmic/tech gradient (Images 8, 9) */
.bg-cosmic-gradient {
  background: linear-gradient(135deg, #1e1b4b 0%, #312e81 25%, #1e40af 50%, #7c3aed 75%, #1e1b4b 100%);
  background-size: 400% 400%;
  animation: cosmic-shift 20s ease-in-out infinite;
}

@keyframes cosmic-shift {
  0%, 100% { background-position: 0% 50%; }
  50% { background-position: 100% 50%; }
}

/* Accent gradient for CTAs */
.bg-cta-gradient {
  background: linear-gradient(135deg, #e94c89 0%, #f472b6 50%, #f7a8c4 100%);
}
```

### 2. **Card Component System**

#### **Statistical Info Card** (Images 4, 5)
```tsx
const InfoCard = ({ title, value, metrics, variant = "default" }) => {
  const variants = {
    default: "from-purple-900/20 to-blue-900/20 border-purple-400/20",
    accent: "from-pink-500/20 to-purple-600/20 border-pink-400/30",
    data: "from-blue-900/30 to-purple-900/30 border-blue-400/20"
  };

  return (
    <div className={`
      relative p-8 rounded-2xl bg-gradient-to-br border backdrop-blur-sm
      ${variants[variant]}
      hover:scale-[1.02] transition-all duration-300
    `}>
      {/* Main value display */}
      <div className="mb-4">
        <div className="text-4xl md:text-5xl font-black text-white mb-2">
          {value}
        </div>
        <div className="text-lg font-medium text-white/80">
          {title}
        </div>
      </div>
      
      {/* Supporting metrics */}
      {metrics && (
        <div className="space-y-2">
          {metrics.map((metric, idx) => (
            <div key={idx} className="flex items-center text-sm text-white/70">
              <div className="w-2 h-2 bg-blue-400 rounded-full mr-3" />
              <span>{metric}</span>
            </div>
          ))}
        </div>
      )}
    </div>
  );
};
```

#### **Service Category Card** (Image 7)
```tsx
const ServiceCard = ({ icon, title, description }) => (
  <div className="flex items-start space-x-4 p-6 rounded-xl bg-white/5 border border-white/10 hover:bg-white/10 transition-all">
    <div className="flex-shrink-0">
      <div className="w-12 h-12 bg-gradient-to-br from-pink-500 to-pink-400 rounded-lg flex items-center justify-center">
        {icon}
      </div>
    </div>
    <div className="flex-1">
      <h3 className="text-xl font-bold text-white mb-2">{title}</h3>
      <p className="text-white/80 leading-relaxed">{description}</p>
    </div>
  </div>
);
```

---

## Implementation Guidelines

### **Development Workflow**
1. **Start with Typography**: Establish scale relationships first
2. **Define Color Roles**: Assign psychological purposes to each color
3. **Create Layout Grid**: Build responsive container system
4. **Develop Components**: Build reusable card and section patterns
5. **Add Micro-interactions**: Enhance with hover states and transitions

### **Responsive Design Strategy**
```tsx
// Mobile-first approach with strategic breakpoints
const breakpoints = {
  sm: '640px',   // Mobile landscape
  md: '768px',   // Tablets
  lg: '1024px',  // Desktop
  xl: '1280px',  // Large desktop
  '2xl': '1536px' // Extra large
};

// Typography scaling strategy
const typographyScale = {
  mobile: {
    mega: '3rem',     // 48px
    large: '2.5rem',  // 40px
    section: '1.75rem', // 28px
    body: '1rem'      // 16px
  },
  desktop: {
    mega: '6rem',     // 96px
    large: '4.5rem',  // 72px
    section: '3rem',  // 48px
    body: '1.25rem'   // 20px
  }
};
```

### **Performance Considerations**
- Use `will-change: transform` for hover animations
- Implement gradient backgrounds with CSS rather than images
- Optimize font loading with `font-display: swap`
- Use `backdrop-filter` sparingly on mobile devices

---

## Psychological Design Principles Applied

### **Visual Hierarchy Psychology**
1. **Size = Importance**: Largest elements get processed first
2. **Color = Emotion**: Blue builds trust, pink creates warmth/urgency
3. **Contrast = Attention**: High contrast draws focus to key actions
4. **Spacing = Clarity**: Generous whitespace suggests premium quality

### **Conversion-Focused Patterns**
1. **Progressive Disclosure**: Complex information broken into stages
2. **Social Proof Integration**: Statistics and testimonials prominently displayed  
3. **Urgency Without Pressure**: Gentle time-based messaging
4. **Authority Through Design**: Sophisticated visuals build credibility

---

**This advanced style guide provides the complete visual design system framework for replicating the sophisticated, conversion-focused design patterns observed in the Oceanheart UI. All techniques are psychologically grounded and optimized for modern web performance.**
</file>

<file path="docs/specs/integration/oceanheart-passport.prd.md">
# Oceanheart.ai Passport - Subdomain Integration Guide

**For subdomain repositories integrating with the Oceanheart authentication system**

---

## Overview

This guide provides everything you need to integrate your subdomain application with the centralized Oceanheart authentication system. Whether you're building `labs.oceanheart.ai`, `clinic.oceanheart.ai`, `passport.oceanheart.ai`, or any other subdomain, this guide will get you connected.

## Architecture Summary

- **Central Auth**: `www.oceanheart.ai` handles all authentication
- **Session Sharing**: JWT tokens in `.oceanheart.ai` domain cookies
- **Local Verification**: Your app verifies tokens without API calls
- **Redirect Flow**: Unauthenticated users redirect to central login

## Environment Configuration

### Development Environment

**Your subdomain (.env.local):**
```bash
# Auth System Configuration
AUTH_URL=http://oceanheart.lvh.me:3000
JWT_SECRET=your-dev-jwt-secret-min-32-chars
COOKIE_DOMAIN=.lvh.me
NODE_ENV=development

# Your App Configuration  
SUBDOMAIN_NAME=passport  # labs, clinic, etc.
PORT=3001  # or your chosen port
```

**Development URLs:**
- Central Auth: `http://oceanheart.lvh.me:3000`
- Your App: `http://passport.lvh.me:3001`
- Auth Endpoints: `http://oceanheart.lvh.me:3000/api/auth/*`

### Production Environment

**Your subdomain (.env.production):**
```bash
# Auth System Configuration
AUTH_URL=https://www.oceanheart.ai
JWT_SECRET=your-prod-jwt-secret-min-32-chars
COOKIE_DOMAIN=.oceanheart.ai
NODE_ENV=production

# Your App Configuration
SUBDOMAIN_NAME=passport
```

**Production URLs:**
- Central Auth: `https://www.oceanheart.ai`
- Your App: `https://passport.oceanheart.ai`
- Auth Endpoints: `https://www.oceanheart.ai/api/auth/*`

## Core Integration Code

### 1. JWT Verification Function

**Language Agnostic Pseudocode:**
```javascript
function verifyJWT(token, secret) {
    try {
        // Verify JWT signature and expiration
        payload = jwt.verify(token, secret, algorithm='HS256')
        
        // Extract user information
        return {
            valid: true,
            userId: payload.userId,
            email: payload.email,
            exp: payload.exp
        }
    } catch (error) {
        return { valid: false, error: error.message }
    }
}
```

### 2. Authentication Middleware

**Generic Implementation:**
```javascript
function requireAuth(request, response, next) {
    // Get JWT from cookie
    token = request.cookies['oh_session']
    
    if (!token) {
        // No token - redirect to auth
        returnUrl = encodeURIComponent(request.fullUrl)
        authUrl = `${AUTH_URL}/signin?returnTo=https://${SUBDOMAIN_NAME}.${DOMAIN}${request.path}`
        return response.redirect(authUrl)
    }
    
    // Verify token locally
    result = verifyJWT(token, JWT_SECRET)
    
    if (!result.valid) {
        // Invalid token - redirect to auth
        returnUrl = encodeURIComponent(request.fullUrl)
        authUrl = `${AUTH_URL}/signin?returnTo=https://${SUBDOMAIN_NAME}.${DOMAIN}${request.path}`
        return response.redirect(authUrl)
    }
    
    // Token valid - attach user to request
    request.user = {
        id: result.userId,
        email: result.email
    }
    
    next()
}
```

### 3. Environment Detection

```javascript
function getAuthConfig() {
    const isDev = process.env.NODE_ENV === 'development'
    
    return {
        authUrl: isDev ? 'http://oceanheart.lvh.me:3000' : 'https://www.oceanheart.ai',
        domain: isDev ? '.lvh.me' : '.oceanheart.ai',
        protocol: isDev ? 'http' : 'https',
        jwtSecret: process.env.JWT_SECRET,
        subdomainName: process.env.SUBDOMAIN_NAME
    }
}

function buildAuthRedirect(currentPath) {
    const config = getAuthConfig()
    const returnTo = `${config.protocol}://${config.subdomainName}${config.domain}${currentPath}`
    return `${config.authUrl}/signin?returnTo=${encodeURIComponent(returnTo)}`
}
```

## Platform-Specific Examples

### Node.js/Express Example

**Package Requirements:**
```json
{
  "dependencies": {
    "jsonwebtoken": "^9.0.0",
    "cookie-parser": "^1.4.6"
  }
}
```

**Implementation:**
```javascript
const jwt = require('jsonwebtoken')
const cookieParser = require('cookie-parser')

app.use(cookieParser())

const requireAuth = (req, res, next) => {
    const token = req.cookies.oh_session
    const config = getAuthConfig()
    
    if (!token) {
        const returnTo = `${config.protocol}://${config.subdomainName}${config.domain}${req.originalUrl}`
        return res.redirect(`${config.authUrl}/signin?returnTo=${encodeURIComponent(returnTo)}`)
    }
    
    try {
        const payload = jwt.verify(token, config.jwtSecret)
        req.user = { id: payload.userId, email: payload.email }
        next()
    } catch (error) {
        const returnTo = `${config.protocol}://${config.subdomainName}${config.domain}${req.originalUrl}`
        res.redirect(`${config.authUrl}/signin?returnTo=${encodeURIComponent(returnTo)}`)
    }
}

// Protected route
app.get('/dashboard', requireAuth, (req, res) => {
    res.json({ message: `Welcome ${req.user.email}!` })
})
```

### Python/Django Example

**Requirements:**
```
PyJWT==2.8.0
```

**settings.py:**
```python
import os

# Auth configuration
AUTH_URL = os.getenv('AUTH_URL', 'https://www.oceanheart.ai')
JWT_SECRET = os.getenv('JWT_SECRET')
SUBDOMAIN_NAME = os.getenv('SUBDOMAIN_NAME', 'passport')
COOKIE_DOMAIN = os.getenv('COOKIE_DOMAIN', '.oceanheart.ai')
```

**middleware.py:**
```python
import jwt
from django.shortcuts import redirect
from django.conf import settings
from django.http import HttpResponseRedirect

class AuthMiddleware:
    def __init__(self, get_response):
        self.get_response = get_response

    def __call__(self, request):
        # Skip auth for public paths
        if request.path.startswith('/public/'):
            return self.get_response(request)
            
        token = request.COOKIES.get('oh_session')
        
        if not token:
            return self.redirect_to_auth(request)
        
        try:
            payload = jwt.decode(token, settings.JWT_SECRET, algorithms=['HS256'])
            request.user_id = payload['userId']
            request.user_email = payload['email']
        except jwt.InvalidTokenError:
            return self.redirect_to_auth(request)
            
        return self.get_response(request)
    
    def redirect_to_auth(self, request):
        protocol = 'https' if settings.COOKIE_DOMAIN == '.oceanheart.ai' else 'http'
        return_to = f"{protocol}://{settings.SUBDOMAIN_NAME}{settings.COOKIE_DOMAIN}{request.get_full_path()}"
        auth_url = f"{settings.AUTH_URL}/signin?returnTo={return_to}"
        return HttpResponseRedirect(auth_url)
```

### Python/FastAPI Example

**Requirements:**
```
PyJWT==2.8.0
python-multipart==0.0.6
```

**main.py:**
```python
from fastapi import FastAPI, Cookie, HTTPException, Depends, Request
from fastapi.responses import RedirectResponse
import jwt
import os

app = FastAPI()

# Configuration
AUTH_URL = os.getenv('AUTH_URL', 'https://www.oceanheart.ai')
JWT_SECRET = os.getenv('JWT_SECRET')
SUBDOMAIN_NAME = os.getenv('SUBDOMAIN_NAME', 'passport')
COOKIE_DOMAIN = os.getenv('COOKIE_DOMAIN', '.oceanheart.ai')

async def get_current_user(request: Request, oh_session: str = Cookie(None)):
    if not oh_session:
        protocol = 'https' if COOKIE_DOMAIN == '.oceanheart.ai' else 'http'
        return_to = f"{protocol}://{SUBDOMAIN_NAME}{COOKIE_DOMAIN}{request.url.path}"
        auth_url = f"{AUTH_URL}/signin?returnTo={return_to}"
        raise HTTPException(status_code=307, headers={"Location": auth_url})
    
    try:
        payload = jwt.decode(oh_session, JWT_SECRET, algorithms=['HS256'])
        return {"id": payload['userId'], "email": payload['email']}
    except jwt.InvalidTokenError:
        protocol = 'https' if COOKIE_DOMAIN == '.oceanheart.ai' else 'http'
        return_to = f"{protocol}://{SUBDOMAIN_NAME}{COOKIE_DOMAIN}{request.url.path}"
        auth_url = f"{AUTH_URL}/signin?returnTo={return_to}"
        raise HTTPException(status_code=307, headers={"Location": auth_url})

@app.get("/dashboard")
async def dashboard(user: dict = Depends(get_current_user)):
    return {"message": f"Welcome {user['email']}!"}
```

### Ruby/Rails Example

**Gemfile:**
```ruby
gem 'jwt'
```

**application_controller.rb:**
```ruby
class ApplicationController < ActionController::Base
  before_action :authenticate_user!
  
  private
  
  def authenticate_user!
    token = cookies['oh_session']
    
    unless token
      redirect_to_auth
      return
    end
    
    begin
      payload = JWT.decode(token, Rails.application.credentials.jwt_secret, algorithm: 'HS256')[0]
      @current_user = {
        id: payload['userId'],
        email: payload['email']
      }
    rescue JWT::DecodeError
      redirect_to_auth
    end
  end
  
  def redirect_to_auth
    protocol = Rails.env.production? ? 'https' : 'http'
    domain = Rails.env.production? ? '.oceanheart.ai' : '.lvh.me'
    subdomain = ENV['SUBDOMAIN_NAME'] || 'passport'
    
    return_to = "#{protocol}://#{subdomain}#{domain}#{request.fullpath}"
    auth_url = "#{ENV['AUTH_URL']}/signin?returnTo=#{CGI.escape(return_to)}"
    
    redirect_to auth_url
  end
end
```

## Optional: Server-Side Verification

For additional security or user data fetching, you can verify tokens with the central auth system:

### Token Verification Endpoint

**POST** `${AUTH_URL}/api/auth/verify`

```javascript
async function verifyTokenWithServer(token) {
    const response = await fetch(`${AUTH_URL}/api/auth/verify`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ token })
    })
    
    return await response.json()
    // Returns: { valid: true, user: { id, email } } or { valid: false }
}
```

### Token Refresh Endpoint

**POST** `${AUTH_URL}/api/auth/refresh`

```javascript
async function refreshToken(token) {
    const response = await fetch(`${AUTH_URL}/api/auth/refresh`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ token })
    })
    
    const data = await response.json()
    // Returns: { token: "new-jwt" } or { error: "Invalid token" }
    
    if (data.token) {
        // Update cookie with new token
        setCookie('oh_session', data.token, {
            domain: COOKIE_DOMAIN,
            secure: true,
            httpOnly: true
        })
    }
    
    return data
}
```

## Testing Your Integration

### 1. Local Development Setup

1. **Start the main auth system:**
   ```bash
   cd oceanheart-ui
   npm run dev  # Runs on oceanheart.lvh.me:3000
   ```

2. **Start your subdomain app:**
   ```bash
   # Your app should run on passport.lvh.me:3001
   npm start  # or your framework's dev command
   ```

3. **Test the flow:**
   - Visit `http://passport.lvh.me:3001/dashboard`
   - Should redirect to `http://oceanheart.lvh.me:3000/signin?returnTo=...`
   - After login, should redirect back to your dashboard

### 2. Cookie Verification

**Browser DevTools > Application > Cookies:**
- Look for `oh_session` cookie
- Domain should be `.lvh.me` (dev) or `.oceanheart.ai` (prod)
- Should be HttpOnly and Secure (in prod)

### 3. JWT Payload Inspection

**Decode your JWT token (for debugging only):**
```javascript
// In browser console (dev only)
const token = document.cookie.split('oh_session=')[1]?.split(';')[0]
if (token) {
    const payload = JSON.parse(atob(token.split('.')[1]))
    console.log('JWT Payload:', payload)
}
```

## Common Issues & Solutions

### Issue: Redirect Loop
**Symptoms:** Endless redirects between your app and auth system  
**Solution:** Check that your JWT_SECRET matches the main auth system

### Issue: Cookie Not Shared
**Symptoms:** Always redirects to login even after authentication  
**Solution:** Verify COOKIE_DOMAIN is set correctly (`.lvh.me` for dev, `.oceanheart.ai` for prod)

### Issue: JWT Verification Fails
**Symptoms:** Token exists but verification throws errors  
**Solution:** Ensure JWT_SECRET is identical across all apps and is at least 32 characters

### Issue: CORS Errors (if using API endpoints)
**Symptoms:** Browser blocks requests to auth endpoints  
**Solution:** Add your subdomain to CORS whitelist in main auth system

## Security Checklist

- [ ] JWT_SECRET is stored securely (environment variables)
- [ ] JWT_SECRET is identical across main auth and your app
- [ ] Cookies are set to HttpOnly and Secure in production
- [ ] HTTPS is enforced in production
- [ ] Token expiration is handled gracefully
- [ ] Sensitive routes are protected with auth middleware
- [ ] returnTo URLs are validated to prevent open redirects

## Environment Variables Summary

**Required for all environments:**
```bash
JWT_SECRET=your-jwt-secret-min-32-characters
SUBDOMAIN_NAME=passport  # or your subdomain name
```

**Development:**
```bash
AUTH_URL=http://oceanheart.lvh.me:3000
COOKIE_DOMAIN=.lvh.me
```

**Production:**
```bash
AUTH_URL=https://www.oceanheart.ai
COOKIE_DOMAIN=.oceanheart.ai
```

## Getting Help

1. **Check JWT payload** - Decode token to verify structure
2. **Verify environment variables** - Ensure all required vars are set
3. **Test cookie sharing** - Check browser DevTools for cookie presence
4. **Review logs** - Check both your app and main auth system logs

---

**This guide should provide everything needed to integrate any subdomain with the Oceanheart authentication system. The examples are framework-agnostic but provide enough detail for implementation in any stack.**
</file>

<file path="docs/specs/blueprint.md">
# Product Requirements Document (PRD)

## Project Overview
**Project Name:** [Project Name]
**Version:** 1.0
**Date:** [Current Date]

## Problem Statement
[Describe the problem this project aims to solve]

## Solution Overview
[High-level description of the proposed solution]

## Requirements
### Functional Requirements
- [ ] Requirement 1
- [ ] Requirement 2
- [ ] Requirement 3

### Non-Functional Requirements
- [ ] Performance requirements
- [ ] Security requirements
- [ ] Scalability requirements

## Success Metrics
- Metric 1: [Description]
- Metric 2: [Description]

## Timeline
- Phase 1: [Description and timeline]
- Phase 2: [Description and timeline]

## Resources Required
- Technical resources
- Human resources
- External dependencies

## Risks and Mitigation
| Risk | Impact | Likelihood | Mitigation |
|------|---------|------------|------------|
| Risk 1 | High | Medium | Mitigation strategy |
</file>

<file path="frontend/src/components/ReviewEditor.test.tsx">
import { test, expect, describe } from "bun:test";

// Mock component logic for testing without React DOM rendering
const createMockReviewEditor = (onChange?: (content: string) => void) => {
  return {
    type: 'ReviewEditor',
    props: {
      onChange,
      children: [
        {
          type: 'textarea',
          props: {
            'data-testid': 'editor-textarea',
            placeholder: 'Enter review content...',
            onChange: (e: { target: { value: string } }) => onChange?.(e.target.value)
          }
        },
        {
          type: 'button',
          props: {
            'data-testid': 'save-button',
            children: 'Save Review'
          }
        }
      ]
    }
  };
};

describe("ReviewEditor Component Logic", () => {
  test("creates editor with correct structure", () => {
    const editor = createMockReviewEditor();
    
    expect(editor.type).toBe('ReviewEditor');
    expect(editor.props.children).toHaveLength(2);
    expect(editor.props.children?.[0]?.props?.['data-testid']).toBe('editor-textarea');
    expect(editor.props.children?.[1]?.props?.['data-testid']).toBe('save-button');
  });

  test("handles content changes via callback", () => {
    let capturedContent = "";
    const handleChange = (content: string) => {
      capturedContent = content;
    };

    const editor = createMockReviewEditor(handleChange);
    const textarea = editor.props.children[0];
    
    // Simulate change event
    textarea?.props?.onChange?.({ target: { value: "Test review content" } });
    
    expect(capturedContent).toBe("Test review content");
  });

  test("has accessible textarea configuration", () => {
    const editor = createMockReviewEditor();
    const textarea = editor.props.children?.[0];
    
    expect(textarea?.props?.placeholder).toBe("Enter review content...");
    expect(textarea?.props?.['data-testid']).toBe('editor-textarea');
  });
});
</file>

<file path="frontend/src/components/TipTapEditor.tsx">
import React from 'react';
import { useEditor, EditorContent } from '@tiptap/react';
import StarterKit from '@tiptap/starter-kit';
import Placeholder from '@tiptap/extension-placeholder';

const TipTapEditor: React.FC = () => {
  const editor = useEditor({
    extensions: [
      StarterKit,
      Placeholder.configure({
        placeholder: 'Start editing your clinical review...',
      }),
    ],
    content: `
      <h2>Clinical Review Template</h2>
      <p>Use this editor to review and edit LLM-generated clinical summaries.</p>
      <p>Key features:</p>
      <ul>
        <li>Rich text editing with formatting</li>
        <li>Real-time diff computation</li>
        <li>Label classification system</li>
        <li>Export functionality</li>
      </ul>
    `,
    editorProps: {
      attributes: {
        class: 'prose prose-sm sm:prose lg:prose-lg xl:prose-2xl mx-auto focus:outline-none min-h-[400px] p-4 border border-gray-300 rounded-lg',
      },
    },
  });

  return (
    <div className="tiptap-editor">
      <div className="editor-toolbar">
        <button
          onClick={() => editor?.chain().focus().toggleBold().run()}
          className={editor?.isActive('bold') ? 'is-active' : ''}
          disabled={!editor?.can().chain().focus().toggleBold().run()}
        >
          Bold
        </button>
        <button
          onClick={() => editor?.chain().focus().toggleItalic().run()}
          className={editor?.isActive('italic') ? 'is-active' : ''}
          disabled={!editor?.can().chain().focus().toggleItalic().run()}
        >
          Italic
        </button>
        <button
          onClick={() => editor?.chain().focus().toggleStrike().run()}
          className={editor?.isActive('strike') ? 'is-active' : ''}
          disabled={!editor?.can().chain().focus().toggleStrike().run()}
        >
          Strike
        </button>
        <button
          onClick={() => editor?.chain().focus().toggleHeading({ level: 2 }).run()}
          className={editor?.isActive('heading', { level: 2 }) ? 'is-active' : ''}
        >
          H2
        </button>
        <button
          onClick={() => editor?.chain().focus().toggleBulletList().run()}
          className={editor?.isActive('bulletList') ? 'is-active' : ''}
        >
          Bullet List
        </button>
      </div>
      <EditorContent editor={editor} />
    </div>
  );
};

export default TipTapEditor;
</file>

<file path="frontend/src/utils/validation.test.ts">
import { test, expect, describe } from "bun:test";

// Mock utility functions for testing
const validateReviewData = (data: { title: string; content: string }) => {
  const errors: string[] = [];
  
  if (!data.title || data.title.trim().length === 0) {
    errors.push("Title is required");
  }
  
  if (!data.content || data.content.trim().length === 0) {
    errors.push("Content is required");
  }
  
  if (data.title && data.title.length > 200) {
    errors.push("Title must be under 200 characters");
  }
  
  return {
    isValid: errors.length === 0,
    errors
  };
};

const sanitizeHtml = (html: string): string => {
  // Basic HTML sanitization mock
  return html
    .replace(/<script[^>]*>.*?<\/script>/gi, '')
    .replace(/<iframe[^>]*>.*?<\/iframe>/gi, '')
    .replace(/javascript:/gi, '');
};

describe("Review Validation Utils", () => {
  test("validates complete review data", () => {
    const validData = {
      title: "Medical Review #001",
      content: "Patient shows good progress with current treatment plan."
    };
    
    const result = validateReviewData(validData);
    
    expect(result.isValid).toBe(true);
    expect(result.errors).toHaveLength(0);
  });

  test("rejects empty title", () => {
    const invalidData = {
      title: "",
      content: "Some content here"
    };
    
    const result = validateReviewData(invalidData);
    
    expect(result.isValid).toBe(false);
    expect(result.errors).toContain("Title is required");
  });

  test("rejects empty content", () => {
    const invalidData = {
      title: "Valid Title",
      content: ""
    };
    
    const result = validateReviewData(invalidData);
    
    expect(result.isValid).toBe(false);
    expect(result.errors).toContain("Content is required");
  });

  test("rejects overly long titles", () => {
    const longTitle = "A".repeat(201);
    const invalidData = {
      title: longTitle,
      content: "Valid content"
    };
    
    const result = validateReviewData(invalidData);
    
    expect(result.isValid).toBe(false);
    expect(result.errors).toContain("Title must be under 200 characters");
  });
});

describe("HTML Sanitization Utils", () => {
  test("removes script tags", () => {
    const dirtyHtml = '<p>Safe content</p><script>alert("xss")</script>';
    const cleanHtml = sanitizeHtml(dirtyHtml);
    
    expect(cleanHtml).toBe('<p>Safe content</p>');
    expect(cleanHtml).not.toContain('<script>');
  });

  test("removes iframe tags", () => {
    const dirtyHtml = '<p>Content</p><iframe src="evil.com"></iframe>';
    const cleanHtml = sanitizeHtml(dirtyHtml);
    
    expect(cleanHtml).toBe('<p>Content</p>');
    expect(cleanHtml).not.toContain('<iframe>');
  });

  test("removes javascript: URLs", () => {
    const dirtyHtml = '<a href="javascript:alert(1)">Link</a>';
    const cleanHtml = sanitizeHtml(dirtyHtml);
    
    expect(cleanHtml).toBe('<a href="alert(1)">Link</a>');
    expect(cleanHtml).not.toContain('javascript:');
  });
});
</file>

<file path="frontend/src/App.tsx">
import React from 'react';
import TipTapEditor from './components/TipTapEditor';

function App() {
  return (
    <div className="app">
      <header className="app-header">
        <h1>Watson - Clinical LLM Review Tool</h1>
        <p>Review and curate LLM outputs for clinical applications</p>
      </header>
      
      <main className="app-main">
        <div className="editor-container">
          <h2>Rich Text Editor</h2>
          <TipTapEditor />
        </div>
      </main>
    </div>
  );
}

export default App;
</file>

<file path="frontend/src/index.css">
/* Watson Frontend Styles */

* {
  margin: 0;
  padding: 0;
  box-sizing: border-box;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', 'Roboto', sans-serif;
  line-height: 1.6;
  color: #333;
  background-color: #f5f5f5;
}

.app {
  min-height: 100vh;
  display: flex;
  flex-direction: column;
}

.app-header {
  background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
  color: white;
  padding: 2rem;
  text-align: center;
}

.app-header h1 {
  font-size: 2.5rem;
  margin-bottom: 0.5rem;
}

.app-header p {
  font-size: 1.2rem;
  opacity: 0.9;
}

.app-main {
  flex: 1;
  padding: 2rem;
  max-width: 1200px;
  margin: 0 auto;
  width: 100%;
}

.editor-container {
  background: white;
  border-radius: 8px;
  padding: 2rem;
  box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
}

.editor-container h2 {
  margin-bottom: 1rem;
  color: #444;
}

/* TipTap Editor Styles */
.tiptap-editor {
  border: 1px solid #e1e5e9;
  border-radius: 8px;
  overflow: hidden;
}

.editor-toolbar {
  border-bottom: 1px solid #e1e5e9;
  padding: 0.5rem;
  display: flex;
  gap: 0.5rem;
  background: #f8f9fa;
}

.editor-toolbar button {
  padding: 0.5rem 1rem;
  border: 1px solid #ddd;
  background: white;
  border-radius: 4px;
  cursor: pointer;
  font-size: 0.9rem;
  transition: all 0.2s;
}

.editor-toolbar button:hover {
  background: #e9ecef;
}

.editor-toolbar button.is-active {
  background: #667eea;
  color: white;
  border-color: #667eea;
}

.editor-toolbar button:disabled {
  opacity: 0.5;
  cursor: not-allowed;
}

/* TipTap ProseMirror content styles */
.ProseMirror {
  padding: 1rem;
  min-height: 400px;
  outline: none;
}

.ProseMirror h1,
.ProseMirror h2,
.ProseMirror h3 {
  margin-top: 1rem;
  margin-bottom: 0.5rem;
  color: #333;
}

.ProseMirror p {
  margin-bottom: 1rem;
}

.ProseMirror ul,
.ProseMirror ol {
  padding-left: 1.5rem;
  margin-bottom: 1rem;
}

.ProseMirror li {
  margin-bottom: 0.25rem;
}

.ProseMirror p.is-editor-empty:first-child::before {
  content: attr(data-placeholder);
  float: left;
  color: #adb5bd;
  pointer-events: none;
  height: 0;
}

/* Responsive design */
@media (max-width: 768px) {
  .app-header {
    padding: 1rem;
  }
  
  .app-header h1 {
    font-size: 2rem;
  }
  
  .app-main {
    padding: 1rem;
  }
  
  .editor-container {
    padding: 1rem;
  }
  
  .editor-toolbar {
    flex-wrap: wrap;
  }
}
</file>

<file path="frontend/src/main.tsx">
import React from 'react';
import { createRoot } from 'react-dom/client';
import App from './App';
import './index.css';

const container = document.getElementById('root');
if (!container) {
  throw new Error('Root element not found');
}

const root = createRoot(container);
root.render(
  <React.StrictMode>
    <App />
  </React.StrictMode>
);
</file>

<file path="frontend/index.html">
<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Watson - Clinical LLM Review Tool</title>
    <link rel="icon" type="image/x-icon" href="/favicon.ico">
</head>
<body>
    <div id="root"></div>
    <script type="module" src="./src/main.tsx"></script>
</body>
</html>
</file>

<file path="frontend/types.d.ts">
// Type definitions for Watson frontend

declare module "*.html" {
  const content: string;
  export default content;
}

declare module "*.css" {
  const content: string;
  export default content;
}

declare module "*.svg" {
  const content: string;
  export default content;
}

declare module "*.png" {
  const content: string;
  export default content;
}

declare module "*.jpg" {
  const content: string;
  export default content;
}
</file>

<file path="scripts/build-env.sh">
#!/bin/bash

# Watson Environment-Specific Build Script
# Builds for different deployment environments

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Default to staging if no environment specified
ENVIRONMENT=${1:-staging}

echo "🏗️  Watson Environment Build: $ENVIRONMENT"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Validate environment
case $ENVIRONMENT in
  development|dev)
    ENV_FILE=".env.dev"
    OPTIMIZE_LEVEL="basic"
    INCLUDE_SOURCEMAPS=true
    ;;
  staging|stage)
    ENV_FILE=".env.staging"
    OPTIMIZE_LEVEL="full"
    INCLUDE_SOURCEMAPS=true
    ;;
  production|prod)
    ENV_FILE=".env.production"
    OPTIMIZE_LEVEL="aggressive"
    INCLUDE_SOURCEMAPS=false
    ;;
  *)
    echo -e "${RED}❌ Invalid environment: $ENVIRONMENT${NC}"
    echo "Usage: $0 [development|staging|production]"
    exit 1
    ;;
esac

echo -e "${BLUE}📋 Build Configuration:${NC}"
echo "  • Environment: $ENVIRONMENT"
echo "  • Config file: $ENV_FILE"
echo "  • Optimization: $OPTIMIZE_LEVEL"
echo "  • Source maps: $INCLUDE_SOURCEMAPS"
echo ""

# Check if environment file exists
if [ ! -f "$ENV_FILE" ]; then
    echo -e "${RED}❌ Environment file $ENV_FILE not found${NC}"
    exit 1
fi

# Load environment variables
echo -e "${BLUE}📥 Loading environment configuration...${NC}"
export $(cat $ENV_FILE | grep -v '^#' | xargs)
export NODE_ENV=$ENVIRONMENT

# Set build-specific variables
export OPTIMIZE_LEVEL
export INCLUDE_SOURCEMAPS

# Clean previous builds
echo -e "${BLUE}🧹 Cleaning previous build artifacts...${NC}"
rm -rf dist build backend/staticfiles

# Create build directories
mkdir -p dist/static dist/assets backend/static/dist

# Build frontend with environment-specific optimizations
echo -e "${BLUE}⚡ Building frontend for $ENVIRONMENT...${NC}"

BUN_BUILD_CMD="bun build ./frontend/src/main.tsx --outdir ./dist/static --minify --splitting --format esm --target browser --public-path /static/"

# Add source maps conditionally
if [ "$INCLUDE_SOURCEMAPS" = true ]; then
    BUN_BUILD_CMD="$BUN_BUILD_CMD --sourcemap=linked"
    echo -e "${YELLOW}  📍 Including source maps${NC}"
else
    echo -e "${GREEN}  🔒 Source maps excluded for security${NC}"
fi

# Environment-specific optimizations
case $OPTIMIZE_LEVEL in
  aggressive)
    BUN_BUILD_CMD="$BUN_BUILD_CMD --define process.env.NODE_ENV='\"production\"' --define process.env.DEBUG='\"false\"'"
    echo -e "${GREEN}  🚀 Aggressive optimization enabled${NC}"
    ;;
  full)
    BUN_BUILD_CMD="$BUN_BUILD_CMD --define process.env.NODE_ENV='\"staging\"'"
    echo -e "${BLUE}  ⚡ Full optimization enabled${NC}"
    ;;
  basic)
    echo -e "${YELLOW}  ⚙️  Basic optimization${NC}"
    ;;
esac

# Execute build
eval $BUN_BUILD_CMD

if [ $? -eq 0 ]; then
    echo -e "${GREEN}✅ Frontend build completed${NC}"
else
    echo -e "${RED}❌ Frontend build failed${NC}"
    exit 1
fi

# Copy HTML template
echo -e "${BLUE}📄 Processing HTML template...${NC}"
cp frontend/index.html dist/
echo -e "${GREEN}✅ HTML template copied${NC}"

# Django static collection
echo -e "${BLUE}🐍 Collecting Django static files...${NC}"
cd backend
source ../.venv/bin/activate

# Use environment-specific Django settings
export DJANGO_SETTINGS_MODULE=watson.settings
../.venv/bin/python manage.py collectstatic --noinput --clear

if [ $? -eq 0 ]; then
    echo -e "${GREEN}✅ Django static collection completed${NC}"
else
    echo -e "${RED}❌ Django static collection failed${NC}"
    exit 1
fi

# Copy frontend assets to Django
cp -r ../dist/static/* staticfiles/
cd ..

# Generate environment-specific build manifest
echo -e "${BLUE}📄 Generating build manifest...${NC}"
cat > dist/build-manifest.json << EOF
{
  "buildTime": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "version": "$(git rev-parse HEAD 2>/dev/null || echo 'development')",
  "environment": "$ENVIRONMENT",
  "optimizationLevel": "$OPTIMIZE_LEVEL",
  "sourceMaps": $INCLUDE_SOURCEMAPS,
  "assets": {
    "frontend": "$(find dist/static -name "*.js" | head -1 | xargs basename 2>/dev/null || echo 'main.js')",
    "css": "$(find dist/static -name "*.css" | head -1 | xargs basename 2>/dev/null || echo 'main.css')"
  },
  "buildConfig": {
    "nodeEnv": "$NODE_ENV",
    "minified": true,
    "codeSplitting": true,
    "envFile": "$ENV_FILE"
  }
}
EOF

# Run build validation
echo -e "${BLUE}🔍 Validating build artifacts...${NC}"
node scripts/validate-build.js

VALIDATION_RESULT=$?

# Final summary
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

if [ $VALIDATION_RESULT -eq 0 ]; then
    echo -e "${GREEN}🎉 Build completed successfully for $ENVIRONMENT!${NC}"
    echo ""
    echo -e "${BLUE}📊 Build Summary:${NC}"
    echo "  • Environment: $ENVIRONMENT"
    echo "  • Frontend bundle: $(find dist/static -name "*.js" -exec du -h {} \; | cut -f1)"
    echo "  • CSS bundle: $(find dist/static -name "*.css" -exec du -h {} \; | cut -f1)"
    echo "  • Total static files: $(find backend/staticfiles -type f | wc -l)"
    echo ""
    echo -e "${GREEN}🚀 Ready for deployment to $ENVIRONMENT!${NC}"
    exit 0
else
    echo -e "${RED}❌ Build validation failed for $ENVIRONMENT${NC}"
    echo "Please review validation warnings before deployment."
    exit 1
fi
</file>

<file path="scripts/build-production.sh">
#!/bin/bash

# Watson Production Build Script
# Creates optimized build artifacts for deployment

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "🏗️  Watson Production Build"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Set production environment
export NODE_ENV=production

# Function to check command success
check_success() {
    if [ $? -eq 0 ]; then
        echo -e "${GREEN}✅ $1${NC}"
    else
        echo -e "${RED}❌ $1 failed${NC}"
        exit 1
    fi
}

# Clean previous builds
echo -e "${BLUE}🧹 Cleaning previous build artifacts...${NC}"
rm -rf dist build backend/static/dist backend/staticfiles
check_success "Clean completed"

# Create output directories
echo -e "${BLUE}📁 Creating build directories...${NC}"
mkdir -p dist/static dist/assets backend/static/dist
check_success "Directories created"

# TypeScript type checking (frontend only)
echo -e "${BLUE}🔍 Running TypeScript type checking...${NC}"
cd frontend && bun tsc --noEmit src/**/*.tsx src/**/*.ts || echo -e "${YELLOW}⚠️  TypeScript warnings (non-blocking)${NC}"
cd ..

# Build frontend with Bun
echo -e "${BLUE}⚡ Building frontend with Bun optimization...${NC}"
bun build ./frontend/src/main.tsx \
    --outdir ./dist/static \
    --minify \
    --splitting \
    --format esm \
    --target browser \
    --public-path /static/ \
    --sourcemap=linked \
    --define process.env.NODE_ENV='"production"'
check_success "Frontend build"

# Build additional assets
echo -e "${BLUE}🖼️  Processing static assets...${NC}"
# Copy HTML template with hashed asset names
cp frontend/index.html dist/
# Copy any additional static assets
if [ -d "frontend/public" ]; then
    cp -r frontend/public/* dist/static/ 2>/dev/null || true
fi
check_success "Static assets processed"

# Django static file collection
echo -e "${BLUE}🐍 Collecting Django static files...${NC}"
cd backend
source ../.venv/bin/activate

# Ensure Django can find static files
export DJANGO_SETTINGS_MODULE=watson.settings
../.venv/bin/python manage.py collectstatic --noinput --clear
check_success "Django static collection"

# Copy built frontend assets to Django static
echo -e "${BLUE}🔄 Copying frontend assets to Django static...${NC}"
cp -r ../dist/static/* staticfiles/
check_success "Asset copying"

cd ..

# Generate build manifest
echo -e "${BLUE}📄 Generating build manifest...${NC}"
cat > dist/build-manifest.json << EOF
{
  "buildTime": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "version": "$(git rev-parse HEAD 2>/dev/null || echo 'development')",
  "environment": "production",
  "assets": {
    "frontend": "$(find dist/static -name "*.js" | head -1 | xargs basename 2>/dev/null || echo 'main.js')",
    "css": "$(find dist/static -name "*.css" | head -1 | xargs basename 2>/dev/null || echo 'none')"
  },
  "buildConfig": {
    "nodeEnv": "$NODE_ENV",
    "minified": true,
    "sourceMaps": true,
    "codeSplitting": true
  }
}
EOF
check_success "Build manifest generated"

# Validate build artifacts
echo -e "${BLUE}🔎 Validating build artifacts...${NC}"

# Check if main files exist
if [ ! -f "dist/index.html" ]; then
    echo -e "${RED}❌ Missing index.html${NC}"
    exit 1
fi

JS_FILES=$(find dist/static -name "*.js" | wc -l)
if [ "$JS_FILES" -eq 0 ]; then
    echo -e "${RED}❌ No JavaScript files generated${NC}"
    exit 1
fi

DJANGO_STATIC=$(find backend/staticfiles -type f | wc -l)
if [ "$DJANGO_STATIC" -eq 0 ]; then
    echo -e "${RED}❌ Django static files not collected${NC}"
    exit 1
fi

check_success "Build validation"

# Generate build summary
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo -e "${GREEN}🎉 Production Build Complete!${NC}"
echo ""
echo -e "${BLUE}📊 Build Summary:${NC}"
echo "  • Frontend JS files: $JS_FILES"
echo "  • Django static files: $DJANGO_STATIC"
echo "  • Build artifacts: dist/"
echo "  • Django static: backend/staticfiles/"
echo ""
echo -e "${BLUE}🚀 Ready for deployment!${NC}"
echo "  • Frontend assets: dist/static/"
echo "  • Backend static: backend/staticfiles/"
echo "  • Build manifest: dist/build-manifest.json"
echo ""
</file>

<file path="scripts/ci-local.sh">
#!/bin/bash

# Watson Testing Infrastructure - Local CI Simulation
# Simulates GitHub Actions workflow locally for development

set -e

echo "🚀 Watson Local CI Pipeline Simulation"
echo "======================================"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to print status
print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

# Change to project root
cd "$(dirname "$0")/.."

echo ""
echo "🔍 Step 1: Environment Check"
echo "----------------------------"

# Check required tools
if command -v bun &> /dev/null; then
    print_status "Bun is available"
else
    print_error "Bun is not installed"
    exit 1
fi

if command -v python &> /dev/null; then
    print_status "Python is available"
else
    print_error "Python is not installed"
    exit 1
fi

if command -v ruby &> /dev/null; then
    print_status "Ruby is available"
else
    print_error "Ruby is not installed"
    exit 1
fi

if command -v bundle &> /dev/null; then
    print_status "Bundler is available"
else
    print_error "Bundler is not installed"
    exit 1
fi

echo ""
echo "🧪 Step 2: Type Checking"
echo "------------------------"
if bun run typecheck; then
    print_status "TypeScript compilation successful"
else
    print_error "TypeScript compilation failed"
    exit 1
fi

echo ""
echo "🧪 Step 3: Running Test Suites"
echo "------------------------------"

# Frontend tests
echo "Frontend Tests (Bun):"
if bun test frontend/ --preload ./bun.test.config.ts; then
    print_status "Frontend tests passed"
else
    print_error "Frontend tests failed"
    exit 1
fi

echo ""
echo "Backend Tests (Django):"
if (cd backend && DJANGO_ENVIRONMENT=test ../.venv/bin/python manage.py test --verbosity=2); then
    print_status "Backend tests passed"
else
    print_error "Backend tests failed"
    exit 1
fi

echo ""
echo "Ruby Tests (RSpec):"
if bundle exec rspec --format progress; then
    print_status "Ruby tests passed"
else
    print_error "Ruby tests failed"
    exit 1
fi

echo ""
echo "📊 Step 4: Coverage Analysis"
echo "----------------------------"
if npm run coverage > /dev/null 2>&1; then
    print_status "Coverage reports generated"
else
    print_warning "Coverage generation had issues (non-fatal)"
fi

echo ""
echo "🔨 Step 5: Build Verification"
echo "-----------------------------"
if NODE_ENV=production npm run build; then
    print_status "Production build successful"
else
    print_error "Production build failed"
    exit 1
fi

if npm run validate:build; then
    print_status "Build validation passed"
else
    print_error "Build validation failed"
    exit 1
fi

echo ""
echo "🎉 Local CI Pipeline Completed Successfully!"
echo "==========================================="
print_status "All checks passed ✅"
echo ""
echo "📈 Summary:"
echo "  • Type checking: ✅"
echo "  • Frontend tests: ✅"
echo "  • Backend tests: ✅"
echo "  • Ruby tests: ✅"
echo "  • Coverage reports: ✅"
echo "  • Production build: ✅"
echo "  • Build validation: ✅"
echo ""
echo "🚀 Ready for deployment!"
</file>

<file path="scripts/coverage-report.sh">
#!/bin/bash

# Watson Testing Infrastructure - Coverage Report
# Generates comprehensive coverage reports for all components

set -e

echo "🔍 Generating Coverage Reports for Watson Testing Infrastructure"
echo "=================================================================="

# Frontend Coverage (TypeScript/JavaScript)
echo ""
echo "📊 Frontend Coverage (Bun):"
echo "----------------------------"
cd "$(dirname "$0")/.."
if bun test frontend/ --coverage 2>/dev/null; then
  echo "✅ Frontend coverage generated"
else
  echo "⚠️  Frontend coverage not available with current Bun version"
fi

# Backend Coverage (Django/Python)
echo ""
echo "📊 Backend Coverage (Django):"
echo "------------------------------"
cd backend
DJANGO_ENVIRONMENT=test ../.venv/bin/python -m coverage run --source='.' manage.py test --verbosity=1
../.venv/bin/python -m coverage report
../.venv/bin/python -m coverage html
echo "✅ Backend HTML coverage report: backend/htmlcov/index.html"
cd ..

# Ruby Coverage (RSpec/SimpleCov)
echo ""
echo "📊 Ruby Coverage (RSpec):"
echo "--------------------------"
if bundle exec rspec --format progress; then
  echo "✅ Ruby HTML coverage report: coverage/index.html"
else
  echo "❌ Ruby coverage failed"
  exit 1
fi

echo ""
echo "🎉 Coverage Report Generation Complete"
echo "======================================"
echo ""
echo "📈 Coverage Reports Available:"
echo "  • Backend (Django): backend/htmlcov/index.html"
echo "  • Ruby (RSpec): coverage/index.html"
echo "  • Frontend: Console output above"
echo ""
echo "📊 Summary:"
echo "  • Django Coverage: Check backend/htmlcov/index.html"
echo "  • Ruby Coverage: Check coverage/index.html" 
echo "  • All tests passing: ✅"
</file>

<file path="scripts/migrate.sh">
#!/bin/bash

# Watson Database Migration Automation
# Safe migration execution with backup and rollback capabilities

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
BACKUP_DIR="/tmp/watson_backups"
TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
BACKUP_FILE="$BACKUP_DIR/watson_backup_$TIMESTAMP.sql"
DRY_RUN=false
ENVIRONMENT="development"

print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_info() {
    echo -e "${BLUE}ℹ️  $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

print_usage() {
    echo "Usage: $0 [-e environment] [-d] [-b] [-r backup_file]"
    echo ""
    echo "Options:"
    echo "  -e, --environment Environment (development|staging|production) [default: development]"
    echo "  -d, --dry-run     Show migrations without executing"
    echo "  -b, --backup      Create backup before migration"
    echo "  -r, --rollback    Rollback to backup file"
    echo "  -h, --help        Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 -e production -b          # Migrate production with backup"
    echo "  $0 -d                        # Dry run migration"
    echo "  $0 -r /path/to/backup.sql    # Rollback to backup"
}

create_backup() {
    if [[ $ENVIRONMENT == "development" ]]; then
        print_info "Skipping backup for development environment"
        return
    fi
    
    print_info "Creating database backup..."
    mkdir -p "$BACKUP_DIR"
    
    # Get database URL based on environment
    if [[ -n $DATABASE_URL ]]; then
        pg_dump "$DATABASE_URL" > "$BACKUP_FILE"
        print_status "Backup created: $BACKUP_FILE"
    else
        print_warning "DATABASE_URL not set, using default connection"
        pg_dump -h localhost -U postgres watson_dev > "$BACKUP_FILE"
        print_status "Backup created: $BACKUP_FILE"
    fi
}

check_migrations() {
    print_info "Checking for pending migrations..."
    
    if [[ $DRY_RUN == true ]]; then
        python manage.py showmigrations --plan
        return $?
    fi
    
    # Check if there are unapplied migrations
    unapplied=$(python manage.py showmigrations --plan | grep "\[ \]" | wc -l)
    if [[ $unapplied -eq 0 ]]; then
        print_status "No pending migrations found"
        return 1
    else
        print_info "Found $unapplied pending migrations"
        python manage.py showmigrations --plan
        return 0
    fi
}

run_migrations() {
    if [[ $DRY_RUN == true ]]; then
        print_info "DRY RUN: Would execute migrations"
        return
    fi
    
    print_info "Running database migrations..."
    
    # Set appropriate Django settings based on environment
    case $ENVIRONMENT in
        production)
            export DJANGO_SETTINGS_MODULE=watson.settings.production
            ;;
        staging)
            export DJANGO_SETTINGS_MODULE=watson.settings.production
            export DEBUG=true
            ;;
        development)
            export DJANGO_SETTINGS_MODULE=watson.settings.base
            ;;
    esac
    
    # Run migrations with verbosity
    python manage.py migrate --verbosity=2
    
    print_status "Migrations completed successfully"
}

validate_migration() {
    print_info "Validating migration result..."
    
    # Check database integrity
    python manage.py check --database default
    
    # Run a simple query to ensure database is accessible
    python manage.py shell -c "
from django.db import connection
with connection.cursor() as cursor:
    cursor.execute('SELECT COUNT(*) FROM django_migrations')
    count = cursor.fetchone()[0]
    print(f'Total migrations applied: {count}')
"
    
    print_status "Migration validation passed"
}

rollback_migration() {
    local backup_file="$1"
    
    if [[ ! -f "$backup_file" ]]; then
        print_error "Backup file not found: $backup_file"
        exit 1
    fi
    
    print_warning "Rolling back database to backup: $backup_file"
    print_warning "This will DESTROY current data. Continue? (y/N)"
    
    read -r response
    if [[ $response != "y" && $response != "Y" ]]; then
        print_info "Rollback cancelled"
        exit 0
    fi
    
    print_info "Restoring database from backup..."
    
    # Drop current database and restore from backup
    if [[ -n $DATABASE_URL ]]; then
        psql "$DATABASE_URL" < "$backup_file"
    else
        psql -h localhost -U postgres watson_dev < "$backup_file"
    fi
    
    print_status "Database rollback completed"
}

# Parse command line arguments
BACKUP=false
ROLLBACK_FILE=""

while [[ $# -gt 0 ]]; do
    case $1 in
        -e|--environment)
            ENVIRONMENT="$2"
            shift 2
            ;;
        -d|--dry-run)
            DRY_RUN=true
            shift
            ;;
        -b|--backup)
            BACKUP=true
            shift
            ;;
        -r|--rollback)
            ROLLBACK_FILE="$2"
            shift 2
            ;;
        -h|--help)
            print_usage
            exit 0
            ;;
        *)
            print_error "Unknown option: $1"
            print_usage
            exit 1
            ;;
    esac
done

# Main execution
echo ""
echo "🔄 Watson Database Migration"
echo "============================"
echo ""
print_info "Environment: $ENVIRONMENT"
print_info "Dry Run: $DRY_RUN"
print_info "Backup: $BACKUP"
echo ""

# Change to backend directory
cd "$(dirname "$0")/../backend"

# Handle rollback case
if [[ -n $ROLLBACK_FILE ]]; then
    rollback_migration "$ROLLBACK_FILE"
    exit 0
fi

# Check for migrations first
if ! check_migrations; then
    print_status "Database is up to date"
    exit 0
fi

# Create backup if requested and not development
if [[ $BACKUP == true ]]; then
    create_backup
fi

# Run migrations
run_migrations

# Validate results
validate_migration

echo ""
print_status "Migration process completed successfully!"

if [[ $BACKUP == true && $ENVIRONMENT != "development" ]]; then
    echo ""
    print_info "Backup file available for rollback: $BACKUP_FILE"
fi
echo ""
</file>

<file path="scripts/monitor.sh">
#!/bin/bash

# Watson Application Monitoring and Health Check Script
# Comprehensive monitoring for all services

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
BASE_URL="${BASE_URL:-http://localhost:8888}"
TIMEOUT=10
ALERT_EMAIL="${ALERT_EMAIL:-admin@watson.local}"
LOG_FILE="/var/log/watson/monitoring.log"

print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_info() {
    echo -e "${BLUE}ℹ️  $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

log_message() {
    local level="$1"
    local message="$2"
    local timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] [$level] $message" >> "$LOG_FILE" 2>/dev/null || true
    echo "$message"
}

check_http_endpoint() {
    local endpoint="$1"
    local expected_status="${2:-200}"
    local description="$3"
    
    log_message "INFO" "Checking $description ($endpoint)..."
    
    if command -v curl >/dev/null 2>&1; then
        local response
        response=$(curl -s -o /dev/null -w "%{http_code}" --connect-timeout $TIMEOUT "$endpoint" 2>/dev/null)
        
        if [[ $response -eq $expected_status ]]; then
            print_status "$description: OK ($response)"
            return 0
        else
            print_error "$description: FAILED ($response, expected $expected_status)"
            log_message "ERROR" "$description failed with status $response"
            return 1
        fi
    else
        print_warning "$description: Cannot check - curl not available"
        return 1
    fi
}

check_service_health() {
    print_info "=== Watson Service Health Check ==="
    
    local failures=0
    
    # Main application health
    if ! check_http_endpoint "$BASE_URL/health/" 200 "Application Health"; then
        ((failures++))
    fi
    
    # Readiness check
    if ! check_http_endpoint "$BASE_URL/ready/" 200 "Application Readiness"; then
        ((failures++))
    fi
    
    # Admin interface (if enabled)
    if ! check_http_endpoint "$BASE_URL/admin/" 200 "Admin Interface"; then
        print_warning "Admin interface may be disabled or require authentication"
    fi
    
    return $failures
}

check_database_connection() {
    print_info "=== Database Connection Check ==="
    
    # Try to connect to database through Django
    if python manage.py check --database default >/dev/null 2>&1; then
        print_status "Database connection: OK"
        log_message "INFO" "Database connection successful"
        return 0
    else
        print_error "Database connection: FAILED"
        log_message "ERROR" "Database connection failed"
        return 1
    fi
}

check_static_files() {
    print_info "=== Static Files Check ==="
    
    local static_root=$(python -c "
import os
import django
from django.conf import settings
django.setup()
print(settings.STATIC_ROOT)
" 2>/dev/null)
    
    if [[ -d "$static_root" ]] && [[ -n "$(ls -A "$static_root" 2>/dev/null)" ]]; then
        print_status "Static files: OK"
        log_message "INFO" "Static files found in $static_root"
        return 0
    else
        print_error "Static files: MISSING or EMPTY"
        log_message "ERROR" "Static files missing in $static_root"
        return 1
    fi
}

check_disk_space() {
    print_info "=== Disk Space Check ==="
    
    local usage
    usage=$(df / | tail -1 | awk '{print $5}' | sed 's/%//')
    
    if [[ $usage -lt 80 ]]; then
        print_status "Disk space: OK (${usage}% used)"
        return 0
    elif [[ $usage -lt 90 ]]; then
        print_warning "Disk space: WARNING (${usage}% used)"
        log_message "WARNING" "Disk space at ${usage}%"
        return 0
    else
        print_error "Disk space: CRITICAL (${usage}% used)"
        log_message "ERROR" "Disk space critically low at ${usage}%"
        return 1
    fi
}

check_memory_usage() {
    print_info "=== Memory Usage Check ==="
    
    if command -v free >/dev/null 2>&1; then
        local memory_usage
        memory_usage=$(free | grep Mem | awk '{printf "%.1f", ($3/$2) * 100.0}')
        
        if (( $(echo "$memory_usage < 80" | bc -l) )); then
            print_status "Memory usage: OK (${memory_usage}%)"
            return 0
        elif (( $(echo "$memory_usage < 90" | bc -l) )); then
            print_warning "Memory usage: WARNING (${memory_usage}%)"
            log_message "WARNING" "Memory usage at ${memory_usage}%"
            return 0
        else
            print_error "Memory usage: CRITICAL (${memory_usage}%)"
            log_message "ERROR" "Memory usage critically high at ${memory_usage}%"
            return 1
        fi
    else
        print_warning "Memory usage: Cannot check - free command not available"
        return 0
    fi
}

check_process_status() {
    print_info "=== Process Status Check ==="
    
    # Check if Django process is running (adjust based on your deployment)
    if pgrep -f "gunicorn.*watson" >/dev/null || pgrep -f "python.*manage.py.*runserver" >/dev/null; then
        print_status "Django process: Running"
        return 0
    else
        print_error "Django process: Not found"
        log_message "ERROR" "Django process not running"
        return 1
    fi
}

send_alert() {
    local subject="$1"
    local message="$2"
    
    if [[ -n $ALERT_EMAIL ]] && command -v mail >/dev/null 2>&1; then
        echo "$message" | mail -s "$subject" "$ALERT_EMAIL"
        log_message "INFO" "Alert sent to $ALERT_EMAIL: $subject"
    else
        log_message "WARNING" "Cannot send alert - mail command not available or ALERT_EMAIL not set"
    fi
}

run_comprehensive_check() {
    echo ""
    echo "🏥 Watson Comprehensive Health Check"
    echo "===================================="
    echo ""
    
    local total_failures=0
    local start_time=$(date +%s)
    
    # Create log directory if needed
    mkdir -p "$(dirname "$LOG_FILE")" 2>/dev/null || true
    
    log_message "INFO" "Starting comprehensive health check"
    
    # Run all checks
    check_service_health || ((total_failures += $?))
    echo ""
    
    check_database_connection || ((total_failures++))
    echo ""
    
    check_static_files || ((total_failures++))
    echo ""
    
    check_disk_space || ((total_failures++))
    echo ""
    
    check_memory_usage || ((total_failures++))
    echo ""
    
    check_process_status || ((total_failures++))
    echo ""
    
    # Summary
    local end_time=$(date +%s)
    local duration=$((end_time - start_time))
    
    echo "📊 Health Check Summary"
    echo "======================"
    echo "Duration: ${duration}s"
    echo "Failures: $total_failures"
    echo ""
    
    if [[ $total_failures -eq 0 ]]; then
        print_status "All health checks passed!"
        log_message "INFO" "Health check completed successfully - all systems operational"
        return 0
    else
        print_error "Health check failed with $total_failures issue(s)"
        log_message "ERROR" "Health check failed with $total_failures issues"
        
        # Send alert for failures
        if [[ $total_failures -gt 0 ]]; then
            send_alert "Watson Health Check Failed" "Health check failed with $total_failures issues. Check logs at $LOG_FILE"
        fi
        
        return $total_failures
    fi
}

# Parse command line arguments
case "${1:-}" in
    "http")
        check_service_health
        ;;
    "database")
        check_database_connection
        ;;
    "static")
        check_static_files
        ;;
    "system")
        check_disk_space && check_memory_usage && check_process_status
        ;;
    *)
        run_comprehensive_check
        ;;
esac
</file>

<file path="scripts/optimize-assets.sh">
#!/bin/bash

# Watson Asset Optimization Script
# Additional compression and optimization for production assets

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "🔧 Watson Asset Optimization"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Function to check if command exists
command_exists() {
    command -v "$1" >/dev/null 2>&1
}

# Function to get file size
get_size() {
    if [ -f "$1" ]; then
        if command_exists gstat; then
            gstat -c%s "$1" 2>/dev/null || stat -f%z "$1" 2>/dev/null || echo "0"
        else
            stat -f%z "$1" 2>/dev/null || stat -c%s "$1" 2>/dev/null || echo "0"
        fi
    else
        echo "0"
    fi
}

# Function to format bytes
format_bytes() {
    local bytes=$1
    if [ $bytes -lt 1024 ]; then
        echo "${bytes}B"
    elif [ $bytes -lt 1048576 ]; then
        echo "$(($bytes / 1024))KB"
    else
        echo "$(($bytes / 1048576))MB"
    fi
}

# Check if build artifacts exist
if [ ! -d "dist/static" ]; then
    echo -e "${RED}❌ No build artifacts found. Run production build first.${NC}"
    exit 1
fi

echo -e "${BLUE}📊 Analyzing current assets...${NC}"

# Analyze main assets
JS_SIZE=$(get_size "dist/static/main.js")
CSS_SIZE=$(get_size "dist/static/main.css")

echo "  • JavaScript: $(format_bytes $JS_SIZE)"
echo "  • CSS: $(format_bytes $CSS_SIZE)"
echo ""

# Gzip compression simulation (checking compression ratios)
echo -e "${BLUE}🗜️  Testing compression ratios...${NC}"

if command_exists gzip; then
    # Create temporary compressed versions to check ratios
    cp dist/static/main.js /tmp/main.js.orig
    cp dist/static/main.css /tmp/main.css.orig
    
    gzip -9 -c /tmp/main.js.orig > /tmp/main.js.gz
    gzip -9 -c /tmp/main.css.orig > /tmp/main.css.gz
    
    JS_GZIP_SIZE=$(get_size "/tmp/main.js.gz")
    CSS_GZIP_SIZE=$(get_size "/tmp/main.css.gz")
    
    JS_RATIO=$(echo "scale=1; $JS_GZIP_SIZE * 100 / $JS_SIZE" | bc -l 2>/dev/null || echo "0")
    CSS_RATIO=$(echo "scale=1; $CSS_GZIP_SIZE * 100 / $CSS_SIZE" | bc -l 2>/dev/null || echo "0")
    
    echo "  • JavaScript (gzipped): $(format_bytes $JS_GZIP_SIZE) (${JS_RATIO}% of original)"
    echo "  • CSS (gzipped): $(format_bytes $CSS_GZIP_SIZE) (${CSS_RATIO}% of original)"
    
    # Cleanup temp files
    rm -f /tmp/main.js.orig /tmp/main.css.orig /tmp/main.js.gz /tmp/main.css.gz
else
    echo "  • gzip not available for compression testing"
fi

echo ""

# Asset optimization recommendations
echo -e "${BLUE}💡 Optimization Analysis:${NC}"

# Check for potential optimizations
TOTAL_SIZE=$((JS_SIZE + CSS_SIZE))
if [ $JS_SIZE -gt 500000 ]; then
    echo -e "${YELLOW}  ⚠️  JavaScript bundle is large ($(format_bytes $JS_SIZE)) - consider code splitting${NC}"
fi

if [ $CSS_SIZE -gt 50000 ]; then
    echo -e "${YELLOW}  ⚠️  CSS bundle is getting large ($(format_bytes $CSS_SIZE)) - consider critical CSS${NC}"
else
    echo -e "${GREEN}  ✅ CSS bundle size is optimal${NC}"
fi

# Check for source map size
SOURCEMAP_SIZE=$(get_size "dist/static/main.js.map")
if [ $SOURCEMAP_SIZE -gt 1000000 ]; then
    echo -e "${YELLOW}  ⚠️  Source map is large ($(format_bytes $SOURCEMAP_SIZE)) - ensure it's excluded from production${NC}"
fi

# Asset hashing check
echo -e "${BLUE}🔗 Asset Cache Optimization:${NC}"

# Check if assets have hash in filename
if [[ "dist/static/main.js" =~ -[a-f0-9]{8,}\. ]]; then
    echo -e "${GREEN}  ✅ Assets have cache-busting hashes${NC}"
else
    echo -e "${YELLOW}  ⚠️  Consider adding cache-busting hashes to asset names${NC}"
fi

# Generate optimization report
cat > dist/optimization-report.json << EOF
{
  "timestamp": "$(date -u +"%Y-%m-%dT%H:%M:%SZ")",
  "assets": {
    "javascript": {
      "file": "main.js",
      "originalSize": $JS_SIZE,
      "gzippedSize": ${JS_GZIP_SIZE:-0},
      "compressionRatio": "${JS_RATIO:-0}%"
    },
    "css": {
      "file": "main.css", 
      "originalSize": $CSS_SIZE,
      "gzippedSize": ${CSS_GZIP_SIZE:-0},
      "compressionRatio": "${CSS_RATIO:-0}%"
    },
    "sourcemap": {
      "size": $SOURCEMAP_SIZE
    }
  },
  "totalSize": $TOTAL_SIZE,
  "recommendations": [
    $([ $JS_SIZE -gt 500000 ] && echo '"Consider code splitting for large JavaScript bundle",')
    $([ $CSS_SIZE -gt 50000 ] && echo '"Consider critical CSS extraction",')
    "Enable gzip/brotli compression on server",
    "Implement proper cache headers",
    "Consider service worker for caching strategy"
  ]
}
EOF

echo -e "${GREEN}✅ Optimization analysis complete${NC}"
echo ""
echo -e "${BLUE}📄 Reports generated:${NC}"
echo "  • dist/build-manifest.json - Build metadata"
echo "  • dist/optimization-report.json - Performance analysis"
echo ""
echo -e "${GREEN}🎯 Production assets are optimized and ready for deployment!${NC}"
</file>

<file path="scripts/pre-commit-hook.sh">
#!/bin/bash

# Watson Testing Infrastructure - Pre-commit Hook
# Runs essential checks before allowing commits

set -e

echo "🔍 Pre-commit checks for Watson"
echo "==============================="

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
NC='\033[0m'

print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

# Change to project root
cd "$(dirname "$0")/.."

echo ""
echo "1. TypeScript Type Checking"
echo "---------------------------"
if bun run typecheck; then
    print_status "TypeScript types are valid"
else
    print_error "TypeScript type checking failed"
    echo "Please fix type errors before committing"
    exit 1
fi

echo ""
echo "2. Quick Test Suite"
echo "------------------"
# Run a subset of tests for speed
if bun test frontend/src/utils/validation.test.ts; then
    print_status "Frontend unit tests passed"
else
    print_error "Frontend tests failed"
    exit 1
fi

echo ""
echo "3. Django Model Tests"
echo "--------------------"
if (cd backend && DJANGO_ENVIRONMENT=test ../.venv/bin/python manage.py test core.test_models --verbosity=1); then
    print_status "Django core tests passed"
else
    print_error "Django tests failed"
    exit 1
fi

echo ""
echo "4. Ruby Validation Tests"
echo "-----------------------"
if bundle exec rspec spec/review_validator_spec.rb --format progress; then
    print_status "Ruby validation tests passed"
else
    print_error "Ruby tests failed"
    exit 1
fi

echo ""
print_status "Pre-commit checks completed successfully!"
echo ""
echo "✨ Ready to commit! All essential checks passed."
</file>

<file path="scripts/rollback.sh">
#!/bin/bash

# Watson Application Rollback Script
# Comprehensive rollback procedures for deployment failures

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Configuration
BACKUP_DIR="/tmp/watson_backups"
DOCKER_IMAGE_PREFIX="watson-oceanheart-ai"
ROLLBACK_STRATEGY="auto"

print_status() {
    echo -e "${GREEN}✅ $1${NC}"
}

print_info() {
    echo -e "${BLUE}ℹ️  $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}⚠️  $1${NC}"
}

print_error() {
    echo -e "${RED}❌ $1${NC}"
}

print_usage() {
    echo "Usage: $0 [options]"
    echo ""
    echo "Options:"
    echo "  -t, --type        Rollback type (database|application|full) [default: auto-detect]"
    echo "  -b, --backup      Specific backup file to rollback to"
    echo "  -v, --version     Application version/tag to rollback to"
    echo "  -s, --strategy    Rollback strategy (auto|manual|force) [default: auto]"
    echo "  -d, --dry-run     Show what would be rolled back without executing"
    echo "  -h, --help        Show this help message"
    echo ""
    echo "Examples:"
    echo "  $0 -t database -b /path/to/backup.sql"
    echo "  $0 -t application -v v1.2.3"
    echo "  $0 -t full -s manual"
}

detect_deployment_platform() {
    if [[ -f "deploy/fly.toml" ]] && command -v flyctl >/dev/null 2>&1; then
        echo "fly"
    elif [[ -f "deploy/railway.json" ]] && command -v railway >/dev/null 2>&1; then
        echo "railway"
    elif [[ -f "deploy/render.yaml" ]]; then
        echo "render"
    elif [[ -f "docker-compose.yml" ]] && command -v docker-compose >/dev/null 2>&1; then
        echo "docker"
    else
        echo "unknown"
    fi
}

get_current_version() {
    # Try to get version from various sources
    if [[ -f "package.json" ]]; then
        python -c "import json; print(json.load(open('package.json'))['version'])" 2>/dev/null || echo "unknown"
    elif command -v git >/dev/null 2>&1; then
        git describe --tags --abbrev=0 2>/dev/null || git rev-parse --short HEAD 2>/dev/null || echo "unknown"
    else
        echo "unknown"
    fi
}

list_available_backups() {
    print_info "Available database backups:"
    if [[ -d "$BACKUP_DIR" ]]; then
        ls -la "$BACKUP_DIR"/*.sql 2>/dev/null | awk '{print $9, $5, $6, $7, $8}' | column -t || print_info "No backups found"
    else
        print_info "No backup directory found"
    fi
}

list_available_versions() {
    local platform=$(detect_deployment_platform)
    
    print_info "Available versions for rollback:"
    
    case $platform in
        "docker")
            docker images | grep "$DOCKER_IMAGE_PREFIX" | head -5
            ;;
        "fly")
            flyctl releases list --app watson-oceanheart-ai || print_info "Cannot list Fly.io releases"
            ;;
        "railway")
            print_info "Railway: Check dashboard for previous deployments"
            ;;
        "render")
            print_info "Render: Check dashboard for previous deployments"
            ;;
        *)
            if command -v git >/dev/null 2>&1; then
                git tag -l | tail -5 || git log --oneline -5
            fi
            ;;
    esac
}

rollback_database() {
    local backup_file="$1"
    
    if [[ -z "$backup_file" ]]; then
        print_error "Backup file is required for database rollback"
        list_available_backups
        exit 1
    fi
    
    if [[ ! -f "$backup_file" ]]; then
        print_error "Backup file not found: $backup_file"
        exit 1
    fi
    
    print_warning "Database rollback will DESTROY current data!"
    print_warning "Backup file: $backup_file"
    print_warning "Continue? (y/N)"
    
    if [[ $ROLLBACK_STRATEGY != "force" ]]; then
        read -r response
        if [[ $response != "y" && $response != "Y" ]]; then
            print_info "Database rollback cancelled"
            exit 0
        fi
    fi
    
    print_info "Rolling back database..."
    
    # Create a backup of current state before rollback
    current_backup="$BACKUP_DIR/pre_rollback_$(date +%Y%m%d_%H%M%S).sql"
    mkdir -p "$BACKUP_DIR"
    
    print_info "Creating backup of current database state..."
    if [[ -n $DATABASE_URL ]]; then
        pg_dump "$DATABASE_URL" > "$current_backup" || print_warning "Failed to create pre-rollback backup"
    fi
    
    # Restore from backup
    print_info "Restoring database from backup..."
    if [[ -n $DATABASE_URL ]]; then
        psql "$DATABASE_URL" < "$backup_file"
    else
        psql -h localhost -U postgres watson_dev < "$backup_file"
    fi
    
    print_status "Database rollback completed"
    print_info "Current state backed up to: $current_backup"
}

rollback_application() {
    local version="$1"
    local platform=$(detect_deployment_platform)
    
    if [[ -z "$version" ]]; then
        print_error "Version/tag is required for application rollback"
        list_available_versions
        exit 1
    fi
    
    print_info "Rolling back application to version: $version"
    print_info "Platform: $platform"
    
    case $platform in
        "docker")
            print_info "Rolling back Docker deployment..."
            docker-compose down
            docker tag "$DOCKER_IMAGE_PREFIX:$version" "$DOCKER_IMAGE_PREFIX:latest"
            docker-compose up -d
            ;;
        "fly")
            print_info "Rolling back Fly.io deployment..."
            flyctl releases rollback "$version" --app watson-oceanheart-ai
            ;;
        "railway")
            print_error "Railway rollback must be done through dashboard"
            print_info "Go to: https://railway.app/dashboard"
            exit 1
            ;;
        "render")
            print_error "Render rollback must be done through dashboard"
            print_info "Go to: https://dashboard.render.com"
            exit 1
            ;;
        "git")
            print_info "Rolling back to git tag/commit: $version"
            git checkout "$version"
            # Redeploy using current deployment method
            print_info "Please redeploy using your normal deployment process"
            ;;
        *)
            print_error "Unknown deployment platform - cannot perform automatic rollback"
            exit 1
            ;;
    esac
    
    print_status "Application rollback completed"
}

rollback_full() {
    local backup_file="$1"
    local version="$2"
    
    print_info "Performing full system rollback..."
    
    if [[ -n "$backup_file" ]]; then
        rollback_database "$backup_file"
    else
        print_warning "No database backup specified - skipping database rollback"
    fi
    
    if [[ -n "$version" ]]; then
        rollback_application "$version"
    else
        print_warning "No application version specified - skipping application rollback"
    fi
    
    print_status "Full rollback completed"
}

test_rollback_procedures() {
    print_info "Testing rollback procedures (dry run)..."
    
    local platform=$(detect_deployment_platform)
    local current_version=$(get_current_version)
    
    echo ""
    echo "📋 Rollback Test Summary"
    echo "======================="
    echo "Platform: $platform"
    echo "Current Version: $current_version"
    echo ""
    
    print_info "Database rollback test:"
    list_available_backups
    echo ""
    
    print_info "Application rollback test:"
    list_available_versions
    echo ""
    
    # Test health check endpoint
    if curl -s http://localhost:8888/health/ >/dev/null 2>&1; then
        print_status "Health check endpoint: Accessible"
    else
        print_warning "Health check endpoint: Not accessible"
    fi
    
    print_status "Rollback procedure test completed"
}

# Parse command line arguments
ROLLBACK_TYPE=""
BACKUP_FILE=""
VERSION=""
DRY_RUN=false

while [[ $# -gt 0 ]]; do
    case $1 in
        -t|--type)
            ROLLBACK_TYPE="$2"
            shift 2
            ;;
        -b|--backup)
            BACKUP_FILE="$2"
            shift 2
            ;;
        -v|--version)
            VERSION="$2"
            shift 2
            ;;
        -s|--strategy)
            ROLLBACK_STRATEGY="$2"
            shift 2
            ;;
        -d|--dry-run)
            DRY_RUN=true
            shift
            ;;
        -h|--help)
            print_usage
            exit 0
            ;;
        *)
            print_error "Unknown option: $1"
            print_usage
            exit 1
            ;;
    esac
done

# Main execution
echo ""
echo "🔙 Watson Rollback System"
echo "========================="
echo ""

if [[ $DRY_RUN == true ]]; then
    test_rollback_procedures
    exit 0
fi

# Auto-detect rollback type if not specified
if [[ -z "$ROLLBACK_TYPE" ]]; then
    if [[ -n "$BACKUP_FILE" && -n "$VERSION" ]]; then
        ROLLBACK_TYPE="full"
    elif [[ -n "$BACKUP_FILE" ]]; then
        ROLLBACK_TYPE="database"
    elif [[ -n "$VERSION" ]]; then
        ROLLBACK_TYPE="application"
    else
        print_error "No rollback parameters specified"
        print_usage
        exit 1
    fi
fi

case $ROLLBACK_TYPE in
    "database")
        rollback_database "$BACKUP_FILE"
        ;;
    "application")
        rollback_application "$VERSION"
        ;;
    "full")
        rollback_full "$BACKUP_FILE" "$VERSION"
        ;;
    *)
        print_error "Invalid rollback type: $ROLLBACK_TYPE"
        print_usage
        exit 1
        ;;
esac

# Run health check after rollback
print_info "Running post-rollback health check..."
if [[ -f "scripts/monitor.sh" ]]; then
    bash scripts/monitor.sh http
else
    print_warning "Health check script not found - please verify manually"
fi

echo ""
print_status "Rollback procedure completed!"
echo ""
</file>

<file path="scripts/validate-build.js">
#!/usr/bin/env node

// Watson Build Validation Script
// Validates build artifacts for deployment readiness

import fs from 'fs';
import path from 'path';

// Colors for console output
const colors = {
  red: '\x1b[31m',
  green: '\x1b[32m',
  blue: '\x1b[34m',
  yellow: '\x1b[33m',
  reset: '\x1b[0m',
  bright: '\x1b[1m'
};

const log = {
  error: (msg) => console.log(`${colors.red}❌ ${msg}${colors.reset}`),
  success: (msg) => console.log(`${colors.green}✅ ${msg}${colors.reset}`),
  warning: (msg) => console.log(`${colors.yellow}⚠️  ${msg}${colors.reset}`),
  info: (msg) => console.log(`${colors.blue}ℹ️  ${msg}${colors.reset}`),
  header: (msg) => console.log(`${colors.bright}${colors.blue}${msg}${colors.reset}`)
};

console.log(`${colors.bright}🔍 Watson Build Validation${colors.reset}`);
console.log('━'.repeat(60));

let validationErrors = 0;
let validationWarnings = 0;
const validationResults = [];

// Helper function to check if file exists and get stats
function checkFile(filePath, description) {
  try {
    const stats = fs.statSync(filePath);
    const size = stats.size;
    validationResults.push({
      type: 'file',
      path: filePath,
      description,
      size,
      exists: true
    });
    return { exists: true, size, stats };
  } catch (err) {
    validationResults.push({
      type: 'file',
      path: filePath,
      description,
      exists: false,
      error: err.message
    });
    return { exists: false, error: err.message };
  }
}

// Helper function to format bytes
function formatBytes(bytes) {
  if (bytes === 0) return '0B';
  const k = 1024;
  const sizes = ['B', 'KB', 'MB', 'GB'];
  const i = Math.floor(Math.log(bytes) / Math.log(k));
  return parseFloat((bytes / Math.pow(k, i)).toFixed(1)) + sizes[i];
}

// Validation tests
log.header('\n📁 Build Directory Structure');

// Check main build directories
const requiredDirs = [
  { path: 'dist', desc: 'Main build output directory' },
  { path: 'dist/static', desc: 'Frontend static assets' },
  { path: 'backend/staticfiles', desc: 'Django static files' }
];

requiredDirs.forEach(({ path: dirPath, desc }) => {
  try {
    const stats = fs.statSync(dirPath);
    if (stats.isDirectory()) {
      const files = fs.readdirSync(dirPath).length;
      log.success(`${desc}: ${dirPath} (${files} items)`);
    } else {
      log.error(`${desc}: ${dirPath} is not a directory`);
      validationErrors++;
    }
  } catch (err) {
    log.error(`${desc}: ${dirPath} - ${err.message}`);
    validationErrors++;
  }
});

log.header('\n📄 Critical Build Files');

// Check critical files
const criticalFiles = [
  { path: 'dist/index.html', desc: 'Main HTML template', maxSize: 10 * 1024 },
  { path: 'dist/static/main.js', desc: 'Main JavaScript bundle', maxSize: 2 * 1024 * 1024 },
  { path: 'dist/static/main.css', desc: 'Main CSS bundle', maxSize: 100 * 1024 },
  { path: 'dist/build-manifest.json', desc: 'Build manifest', maxSize: 10 * 1024 }
];

criticalFiles.forEach(({ path: filePath, desc, maxSize }) => {
  const result = checkFile(filePath, desc);
  if (result.exists) {
    const sizeFormatted = formatBytes(result.size);
    if (result.size > maxSize) {
      log.warning(`${desc}: ${sizeFormatted} (larger than expected ${formatBytes(maxSize)})`);
      validationWarnings++;
    } else if (result.size === 0) {
      log.error(`${desc}: File is empty`);
      validationErrors++;
    } else {
      log.success(`${desc}: ${sizeFormatted}`);
    }
  } else {
    log.error(`${desc}: Missing - ${result.error}`);
    validationErrors++;
  }
});

log.header('\n📋 Build Manifest Validation');

// Validate build manifest
try {
  const manifest = JSON.parse(fs.readFileSync('dist/build-manifest.json', 'utf8'));
  
  const requiredFields = ['buildTime', 'version', 'environment', 'assets', 'buildConfig'];
  requiredFields.forEach(field => {
    if (manifest[field]) {
      log.success(`Build manifest has ${field}`);
    } else {
      log.error(`Build manifest missing ${field}`);
      validationErrors++;
    }
  });
  
  // Validate build time is recent (within last hour)
  const buildTime = new Date(manifest.buildTime);
  const now = new Date();
  const timeDiff = Math.abs(now - buildTime) / (1000 * 60); // minutes
  
  if (timeDiff > 60) {
    log.warning(`Build is ${Math.round(timeDiff)} minutes old`);
    validationWarnings++;
  } else {
    log.success(`Build is recent (${Math.round(timeDiff)} minutes ago)`);
  }
  
} catch (err) {
  log.error(`Build manifest validation failed: ${err.message}`);
  validationErrors++;
}

log.header('\n🎯 JavaScript Bundle Analysis');

// Analyze JavaScript bundle
try {
  const jsContent = fs.readFileSync('dist/static/main.js', 'utf8');
  
  // Check for development artifacts
  const devChecks = [
    { pattern: /console\.log/, desc: 'console.log statements' },
    { pattern: /debugger/, desc: 'debugger statements' },
    { pattern: /development/i, desc: 'development references' }
  ];
  
  devChecks.forEach(({ pattern, desc }) => {
    if (pattern.test(jsContent)) {
      log.warning(`JavaScript bundle contains ${desc}`);
      validationWarnings++;
    } else {
      log.success(`No ${desc} found`);
    }
  });
  
  // Check for minification indicators
  const minificationChecks = [
    { test: jsContent.includes('\n\n'), desc: 'Code appears to be minified', shouldBeFalse: true },
    { test: jsContent.length < 500000, desc: 'Bundle size is reasonable', shouldBeFalse: false }
  ];
  
  minificationChecks.forEach(({ test, desc, shouldBeFalse }) => {
    if (shouldBeFalse ? !test : test) {
      log.success(desc);
    } else {
      log.warning(`${desc} - check failed`);
      validationWarnings++;
    }
  });
  
} catch (err) {
  log.error(`JavaScript analysis failed: ${err.message}`);
  validationErrors++;
}

log.header('\n🗂️  Django Static Files');

// Check Django static files
try {
  const staticFiles = fs.readdirSync('backend/staticfiles');
  const jsFiles = staticFiles.filter(f => f.endsWith('.js'));
  const cssFiles = staticFiles.filter(f => f.endsWith('.css'));
  
  log.success(`Django static files: ${staticFiles.length} total`);
  log.info(`JavaScript files: ${jsFiles.length}`);
  log.info(`CSS files: ${cssFiles.length}`);
  
  if (jsFiles.length === 0) {
    log.error('No JavaScript files found in Django static files');
    validationErrors++;
  }
  
} catch (err) {
  log.error(`Django static files check failed: ${err.message}`);
  validationErrors++;
}

log.header('\n🔒 Security Validation');

// Security checks
const securityChecks = [
  {
    name: 'Source maps in production',
    check: () => {
      try {
        fs.statSync('dist/static/main.js.map');
        return { pass: false, message: 'Source maps should not be deployed to production' };
      } catch {
        return { pass: true, message: 'No source maps found in production build' };
      }
    }
  },
  {
    name: 'Environment variables',
    check: () => {
      try {
        const jsContent = fs.readFileSync('dist/static/main.js', 'utf8');
        const hasSecrets = /(?:password|secret|key|token)[\s]*[:=][\s]*["'][^"']+["']/i.test(jsContent);
        return { 
          pass: !hasSecrets, 
          message: hasSecrets ? 'Potential secrets found in bundle' : 'No obvious secrets in bundle'
        };
      } catch {
        return { pass: false, message: 'Could not analyze bundle for secrets' };
      }
    }
  }
];

securityChecks.forEach(({ name, check }) => {
  try {
    const result = check();
    if (result.pass) {
      log.success(`${name}: ${result.message}`);
    } else {
      log.warning(`${name}: ${result.message}`);
      validationWarnings++;
    }
  } catch (err) {
    log.error(`${name}: Check failed - ${err.message}`);
    validationErrors++;
  }
});

// Final validation summary
log.header('\n📊 Validation Summary');

console.log(`Total files validated: ${validationResults.length}`);
console.log(`Validation errors: ${validationErrors}`);
console.log(`Validation warnings: ${validationWarnings}`);

if (validationErrors === 0 && validationWarnings === 0) {
  log.success('🎉 All validations passed! Build is ready for deployment.');
  process.exit(0);
} else if (validationErrors === 0) {
  log.warning(`⚠️  Build passed with ${validationWarnings} warnings. Review before deployment.`);
  process.exit(0);
} else {
  log.error(`❌ Build validation failed with ${validationErrors} errors and ${validationWarnings} warnings.`);
  process.exit(1);
}
</file>

<file path="spec/review_validator_spec.rb">
require 'spec_helper'
require_relative '../lib/review_validator'

RSpec.describe ReviewValidator do
  describe '.validate_content' do
    it 'validates valid content' do
      content = "This is a valid medical review with sufficient length for testing."
      result = ReviewValidator.validate_content(content)
      
      expect(result[:valid]).to be true
      expect(result[:errors]).to be_empty
    end

    it 'rejects empty content' do
      result = ReviewValidator.validate_content("")
      
      expect(result[:valid]).to be false
      expect(result[:errors]).to include("Content cannot be empty")
    end

    it 'rejects nil content' do
      result = ReviewValidator.validate_content(nil)
      
      expect(result[:valid]).to be false
      expect(result[:errors]).to include("Content cannot be empty")
    end

    it 'rejects content that is too short' do
      result = ReviewValidator.validate_content("Too short")
      
      expect(result[:valid]).to be false
      expect(result[:errors]).to include("Content is too short")
    end

    it 'rejects content that is too long' do
      long_content = "a" * 5001
      result = ReviewValidator.validate_content(long_content)
      
      expect(result[:valid]).to be false
      expect(result[:errors]).to include("Content is too long")
    end
  end

  describe '.sanitize_html' do
    it 'removes script tags' do
      dirty_html = '<p>Safe content</p><script>alert("xss")</script>'
      clean_html = ReviewValidator.sanitize_html(dirty_html)
      
      expect(clean_html).to eq('<p>Safe content</p>')
      expect(clean_html).not_to include('<script>')
    end

    it 'removes iframe tags' do
      dirty_html = '<p>Content</p><iframe src="evil.com"></iframe>'
      clean_html = ReviewValidator.sanitize_html(dirty_html)
      
      expect(clean_html).to eq('<p>Content</p>')
      expect(clean_html).not_to include('<iframe>')
    end

    it 'removes javascript: URLs' do
      dirty_html = '<a href="javascript:alert(1)">Link</a>'
      clean_html = ReviewValidator.sanitize_html(dirty_html)
      
      expect(clean_html).to eq('<a href="">Link</a>')
      expect(clean_html).not_to include('javascript:')
    end

    it 'removes event handlers' do
      dirty_html = '<div onclick="alert(1)">Content</div>'
      clean_html = ReviewValidator.sanitize_html(dirty_html)
      
      expect(clean_html).to eq('<div>Content</div>')
      expect(clean_html).not_to include('onclick=')
    end

    it 'handles nil input' do
      result = ReviewValidator.sanitize_html(nil)
      expect(result).to eq("")
    end
  end

  describe '.extract_medical_terms' do
    it 'extracts common medical terms' do
      content = "Patient shows improvement with current medication and therapy regimen."
      terms = ReviewValidator.extract_medical_terms(content)
      
      expect(terms).to include('patient', 'medication', 'therapy')
      expect(terms).to be_an(Array)
    end

    it 'extracts symptoms and conditions' do
      content = "The patient's symptoms include fever and the condition is improving."
      terms = ReviewValidator.extract_medical_terms(content)
      
      expect(terms).to include('symptoms', 'condition')
    end

    it 'extracts dosage units' do
      content = "Prescribed 50mg tablets, 2ml injection, 3 units daily."
      terms = ReviewValidator.extract_medical_terms(content)
      
      expect(terms).to include('mg', 'ml', 'units')
    end

    it 'returns unique terms only' do
      content = "Patient patient Patient shows symptoms symptoms"
      terms = ReviewValidator.extract_medical_terms(content)
      
      expect(terms.count('patient')).to eq(1)
      expect(terms.count('symptoms')).to eq(1)
    end

    it 'handles empty content' do
      expect(ReviewValidator.extract_medical_terms("")).to eq([])
      expect(ReviewValidator.extract_medical_terms(nil)).to eq([])
    end

    it 'is case insensitive' do
      content = "PATIENT shows SYMPTOMS with MEDICATION"
      terms = ReviewValidator.extract_medical_terms(content)
      
      expect(terms).to include('patient', 'symptoms', 'medication')
    end
  end
end
</file>

<file path="spec/spec_helper.rb">
# Coverage reporting setup
require 'simplecov'
SimpleCov.start do
  add_filter '/spec/'
  add_filter '/vendor/'
  
  add_group 'Libraries', 'lib'
  
  minimum_coverage 80
end

# This file was generated by the `rspec --init` command. Conventionally, all
# specs live under a `spec` directory, which RSpec adds to the `$LOAD_PATH`.
# The generated `.rspec` file contains `--require spec_helper` which will cause
# this file to always be loaded, without a need to explicitly require it in any
# files.
#
# Given that it is always loaded, you are encouraged to keep this file as
# light-weight as possible. Requiring heavyweight dependencies from this file
# will add to the boot time of your test suite on EVERY test run, even for an
# individual file that may not need all of that loaded. Instead, consider making
# a separate helper file that requires the additional dependencies and performs
# the additional setup, and require it from the spec files that actually need
# it.
#
# See https://rubydoc.info/gems/rspec-core/RSpec/Core/Configuration
RSpec.configure do |config|
  # rspec-expectations config goes here. You can use an alternate
  # assertion/expectation library such as wrong or the stdlib/minitest
  # assertions if you prefer.
  config.expect_with :rspec do |expectations|
    # This option will default to `true` in RSpec 4. It makes the `description`
    # and `failure_message` of custom matchers include text for helper methods
    # defined using `chain`, e.g.:
    #     be_bigger_than(2).and_smaller_than(4).description
    #     # => "be bigger than 2 and smaller than 4"
    # ...rather than:
    #     # => "be bigger than 2"
    expectations.include_chain_clauses_in_custom_matcher_descriptions = true
  end

  # rspec-mocks config goes here. You can use an alternate test double
  # library (such as bogus or mocha) by changing the `mock_with` option here.
  config.mock_with :rspec do |mocks|
    # Prevents you from mocking or stubbing a method that does not exist on
    # a real object. This is generally recommended, and will default to
    # `true` in RSpec 4.
    mocks.verify_partial_doubles = true
  end

  # This option will default to `:apply_to_host_groups` in RSpec 4 (and will
  # have no way to turn it off -- the option exists only for backwards
  # compatibility in RSpec 3). It causes shared context metadata to be
  # inherited by the metadata hash of host groups and examples, rather than
  # triggering implicit auto-inclusion in groups with matching metadata.
  config.shared_context_metadata_behavior = :apply_to_host_groups

# The settings below are suggested to provide a good initial experience
# with RSpec, but feel free to customize to your heart's content.
=begin
  # This allows you to limit a spec run to individual examples or groups
  # you care about by tagging them with `:focus` metadata. When nothing
  # is tagged with `:focus`, all examples get run. RSpec also provides
  # aliases for `it`, `describe`, and `context` that include `:focus`
  # metadata: `fit`, `fdescribe` and `fcontext`, respectively.
  config.filter_run_when_matching :focus

  # Allows RSpec to persist some state between runs in order to support
  # the `--only-failures` and `--next-failure` CLI options. We recommend
  # you configure your source control system to ignore this file.
  config.example_status_persistence_file_path = "spec/examples.txt"

  # Limits the available syntax to the non-monkey patched syntax that is
  # recommended. For more details, see:
  # https://rspec.info/features/3-12/rspec-core/configuration/zero-monkey-patching-mode/
  config.disable_monkey_patching!

  # This setting enables warnings. It's recommended, but in some cases may
  # be too noisy due to issues in dependencies.
  config.warnings = true

  # Many RSpec users commonly either run the entire suite or an individual
  # file, and it's useful to allow more verbose output when running an
  # individual spec file.
  if config.files_to_run.one?
    # Use the documentation formatter for detailed output,
    # unless a formatter has already been configured
    # (e.g. via a command-line flag).
    config.default_formatter = "doc"
  end

  # Print the 10 slowest examples and example groups at the
  # end of the spec run, to help surface which specs are running
  # particularly slow.
  config.profile_examples = 10

  # Run specs in random order to surface order dependencies. If you find an
  # order dependency and want to debug it, you can fix the order by providing
  # the seed, which is printed after each run.
  #     --seed 1234
  config.order = :random

  # Seed global randomization in this process using the `--seed` CLI option.
  # Setting this allows you to use `--seed` to deterministically reproduce
  # test failures related to randomization by passing the same `--seed` value
  # as the one that triggered the failure.
  Kernel.srand config.seed
=end
end
</file>

<file path=".env.production">
# Watson Production Environment Variables

# Django settings
DEBUG=false
SECRET_KEY=${SECRET_KEY}
ALLOWED_HOSTS=${ALLOWED_HOSTS}

# Database
DATABASE_URL=${DATABASE_URL}

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Frontend/API
NODE_ENV=production
API_URL=${API_URL}

# Static files and CDN
STATIC_URL=/static/
MEDIA_URL=/media/

# Security settings
SECURE_SSL_REDIRECT=true
SESSION_COOKIE_SECURE=true
CSRF_COOKIE_SECURE=true
SECURE_BROWSER_XSS_FILTER=true
SECURE_CONTENT_TYPE_NOSNIFF=true

# Logging
LOG_LEVEL=INFO
SENTRY_DSN=${SENTRY_DSN}

# Performance
CACHE_TTL=3600
</file>

<file path=".env.production.template">
# Watson Production Environment Configuration
# IMPORTANT: Never commit actual production values

# Database - Use your production database URL
DATABASE_URL=postgresql://username:password@host:port/database
REDIS_URL=redis://host:port/database

# Django Configuration - CRITICAL SECURITY SETTINGS
DEBUG=false
SECRET_KEY=your-very-secure-secret-key-here
ALLOWED_HOSTS=yourdomain.com,www.yourdomain.com
DJANGO_SETTINGS_MODULE=watson.settings.production

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Frontend Configuration
NODE_ENV=production
VITE_API_URL=https://yourdomain.com

# Logging
LOG_LEVEL=WARNING

# Feature Flags - Disable debug features in production
ENABLE_DEBUG_TOOLBAR=false
ENABLE_ADMIN_INTERFACE=false

# External Services
SENTRY_DSN=your-production-sentry-dsn
ANALYTICS_TRACKING_ID=your-production-analytics-id

# Storage - Production asset storage
AWS_ACCESS_KEY_ID=your-production-aws-key
AWS_SECRET_ACCESS_KEY=your-production-aws-secret
AWS_STORAGE_BUCKET_NAME=watson-production-assets
AWS_S3_REGION_NAME=us-west-2
AWS_DEFAULT_ACL=public-read

# Email Configuration
EMAIL_BACKEND=django.core.mail.backends.smtp.EmailBackend
EMAIL_HOST=smtp.yourdomain.com
EMAIL_PORT=587
EMAIL_USE_TLS=true
EMAIL_HOST_USER=noreply@yourdomain.com
EMAIL_HOST_PASSWORD=your-email-password

# Security Headers
SECURE_SSL_REDIRECT=true
SESSION_COOKIE_SECURE=true
CSRF_COOKIE_SECURE=true
SECURE_BROWSER_XSS_FILTER=true
SECURE_CONTENT_TYPE_NOSNIFF=true

# Performance
GUNICORN_WORKERS=3
GUNICORN_WORKER_CONNECTIONS=1000

# Monitoring
HEALTH_CHECK_ACCESS_TOKEN=your-monitoring-token
</file>

<file path=".env.staging">
# Watson Staging Environment Variables

# Django settings
DEBUG=false
SECRET_KEY=${STAGING_SECRET_KEY}
ALLOWED_HOSTS=${STAGING_ALLOWED_HOSTS}

# Database
DATABASE_URL=${STAGING_DATABASE_URL}

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Frontend/API
NODE_ENV=staging
API_URL=${STAGING_API_URL}

# Static files
STATIC_URL=/static/
MEDIA_URL=/media/

# Security settings (less restrictive than production)
SECURE_SSL_REDIRECT=false
SESSION_COOKIE_SECURE=false
CSRF_COOKIE_SECURE=false
SECURE_BROWSER_XSS_FILTER=true
SECURE_CONTENT_TYPE_NOSNIFF=true

# Logging
LOG_LEVEL=DEBUG
SENTRY_DSN=${STAGING_SENTRY_DSN}

# Performance
CACHE_TTL=300
</file>

<file path=".env.staging.template">
# Watson Staging Environment Configuration
# Copy to .env for local staging environment

# Database
DATABASE_URL=postgresql://watson:staging_password@staging-db:5432/watson_staging
REDIS_URL=redis://staging-redis:6379/0

# Django Configuration
DEBUG=true
SECRET_KEY=staging-secret-key-change-this
ALLOWED_HOSTS=watson-staging.example.com,localhost,127.0.0.1
DJANGO_SETTINGS_MODULE=watson.settings.production

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Frontend Configuration
NODE_ENV=staging
VITE_API_URL=https://watson-staging.example.com

# Logging
LOG_LEVEL=INFO

# Feature Flags
ENABLE_DEBUG_TOOLBAR=true
ENABLE_ADMIN_INTERFACE=true

# External Services
SENTRY_DSN=your-sentry-dsn-here
ANALYTICS_TRACKING_ID=your-analytics-id-here

# Storage (if using cloud storage)
# AWS_ACCESS_KEY_ID=your-aws-key
# AWS_SECRET_ACCESS_KEY=your-aws-secret
# AWS_STORAGE_BUCKET_NAME=watson-staging-assets

# Email Configuration (if needed)
EMAIL_BACKEND=django.core.mail.backends.console.EmailBackend
# EMAIL_HOST=smtp.example.com
# EMAIL_PORT=587
# EMAIL_USE_TLS=true
# EMAIL_HOST_USER=your-email
# EMAIL_HOST_PASSWORD=your-password
</file>

<file path=".gitignore">
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
dist/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/
.pytest_cache/
.coverage
htmlcov/

# TypeScript/JavaScript
node_modules/
npm-debug.log*
yarn-debug.log*
yarn-error.log*
.npm
.yarn/cache
.yarn/unplugged
.yarn/build-state.yml
.yarn/install-state.gz
.pnp.*
dist/
build/
*.tsbuildinfo
.next/
out/
.nuxt/
.vuepress/dist/
.serverless/
.fusebox/
.dynamodb/
.tern-port

# Ruby
*.gem
*.rbc
/.config
/coverage/
/InstalledFiles
/pkg/
/spec/reports/
/spec/examples.txt
/test/tmp/
/test/version_tmp/
/tmp/
.bundle
/vendor/bundle
lib/bundler/man/
.rvmrc
/.ruby-version
/.ruby-gemset
.rbenv-version
Gemfile.lock

# IDE
.vscode/
.idea/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Logs
logs/
*.log

# Temporary files
*.tmp
*.temp

# Environment variables
.env
.env.local
.env.development.local
.env.test.local
.env.production.local

# Database
*.db
*.sqlite
*.sqlite3

# Compiled files
*.com
*.class
*.dll
*.exe
*.o
*.so
</file>

<file path=".rspec">
--require spec_helper
</file>

<file path="AGENTS.md">
# Repository Guidelines

## Project Structure & Modules
- `frontend/` — React + TypeScript app built with Bun. Entry: `src/main.tsx`; tests: `*.test.ts[x]`.
- `backend/` — Django API (`watson/`, `reviews/`, `core/`). Uses `manage.py`; static assets in `static/` and `staticfiles/`.
- `spec/` — Ruby/RSpec unit tests for shared validators/utilities.
- `scripts/` — Dev/CI helpers (`dev.sh`, `ci-local.sh`, `pre-commit-hook.sh`, `migrate.sh`).
- `deploy/` — Release scripts. `docker/`, `Dockerfile`, `docker-compose.yml` for container workflows.
- Build output goes to `dist/` and coverage to `coverage/`, `backend/htmlcov/`.

## Build, Test, and Dev Commands
- Local dev (full): `npm run dev` (hot-serve via Bun).
- Build (prod): `npm run build` or `npm run build:prod`.
- Frontend tests: `npm test` or `bun test frontend/ --preload ./bun.test.config.ts`.
- Backend tests: `npm run test:backend` (Django).
- Ruby tests: `npm run test:ruby` (RSpec).
- All tests + coverage: `npm run test:all` and `npm run test:coverage`.
- Docker: `npm run docker:build`, `npm run docker:up`, `npm run docker:down`.
- Local CI simulation: `npm run ci:local`. Pre-commit checks: `npm run pre-commit`.

## Coding Style & Naming
- TypeScript/React: strict types; run `npm run typecheck`. Components `PascalCase.tsx`, utilities `camelCase.ts`.
- Python/Django: follow Django app structure; module names `snake_case.py`; settings under `backend/watson/settings/`.
- Ruby: follow RuboCop defaults; specs under `spec/*_spec.rb`.
- Keep files small and cohesive; prefer pure functions and typed interfaces at boundaries.

## Testing Guidelines
- Frontend: Testing Library + Happy DOM. Name tests `*.test.ts[x]` adjacent to source.
- Backend: Django `TestCase` in app `tests.py` modules. Run with `DJANGO_ENVIRONMENT=test` when needed.
- Ruby: RSpec with SimpleCov; unit specs in `spec/` mirroring library names.
- Coverage reports: `npm run coverage` (HTML at `backend/htmlcov/index.html`, `coverage/index.html`).

## Commits & Pull Requests
- Commits: short imperative subject (<= 72 chars), scoped paths (e.g., `frontend: …`, `backend: …`). Group related changes.
- PRs: include purpose, screenshots for UI, reproduction/verification steps, and linked issues. Ensure `ci-local.sh` passes and production build validates (`npm run validate:build`).

## Security & Configuration
- Never commit secrets. Use `.env.*` files; copy from `*.template` and load per environment. Validate via `scripts/health-check.sh`.
</file>

<file path="main.py">
def main():
    print("Hello from watson-oceanheart-ai!")


if __name__ == "__main__":
    main()
</file>

<file path="backend/core/views.py">
from django.shortcuts import render
from django.http import JsonResponse
from django.db import connection
from django.conf import settings
import time


def health_check(request):
    """Health check endpoint for monitoring and load balancers"""
    
    health_data = {
        "status": "healthy",
        "timestamp": int(time.time()),
        "service": "watson-api",
        "version": "1.0.0"
    }
    
    try:
        # Check database connection
        with connection.cursor() as cursor:
            cursor.execute("SELECT 1")
            health_data["database"] = "connected"
    except Exception as e:
        health_data["status"] = "unhealthy"
        health_data["database"] = f"error: {str(e)}"
        return JsonResponse(health_data, status=503)
    
    # Check if in debug mode (should be False in production)
    health_data["debug_mode"] = settings.DEBUG
    
    # Add any additional health checks here
    return JsonResponse(health_data)


def readiness_check(request):
    """Readiness check for Kubernetes/container orchestration"""
    
    readiness_data = {
        "ready": True,
        "timestamp": int(time.time()),
        "checks": {}
    }
    
    try:
        # Database readiness
        with connection.cursor() as cursor:
            cursor.execute("SELECT COUNT(*) FROM django_migrations")
            migration_count = cursor.fetchone()[0]
            readiness_data["checks"]["migrations"] = f"{migration_count} applied"
            
        # Check if static files are collected
        import os
        static_root = getattr(settings, 'STATIC_ROOT', None)
        if static_root and os.path.exists(static_root):
            readiness_data["checks"]["static_files"] = "available"
        else:
            readiness_data["checks"]["static_files"] = "missing"
            readiness_data["ready"] = False
            
    except Exception as e:
        readiness_data["ready"] = False
        readiness_data["error"] = str(e)
        return JsonResponse(readiness_data, status=503)
    
    status_code = 200 if readiness_data["ready"] else 503
    return JsonResponse(readiness_data, status=status_code)


# Create your views here.
</file>

<file path="backend/watson/settings/base.py">
"""
Django settings for watson project.

Generated by 'django-admin startproject' using Django 5.2.6.

For more information on this file, see
https://docs.djangoproject.com/en/5.2/topics/settings/

For the full list of settings and their values, see
https://docs.djangoproject.com/en/5.2/ref/settings/
"""

import os
from pathlib import Path

# Build paths inside the project like this: BASE_DIR / 'subdir'.
BASE_DIR = Path(__file__).resolve().parent.parent


# Quick-start development settings - unsuitable for production
# See https://docs.djangoproject.com/en/5.2/howto/deployment/checklist/

# SECURITY WARNING: keep the secret key used in production secret!
SECRET_KEY = os.environ.get('SECRET_KEY', 'django-insecure-jvb2pf6e&e54kfq7h=v!)$8osg0w3s_-=e#clij39xkzn59@_4')

# SECURITY WARNING: don't run with debug turned on in production!
DEBUG = os.environ.get('DEBUG', 'true').lower() == 'true'

ALLOWED_HOSTS = os.environ.get('ALLOWED_HOSTS', 'localhost,127.0.0.1').split(',')


# Application definition

INSTALLED_APPS = [
    'django.contrib.admin',
    'django.contrib.auth',
    'django.contrib.contenttypes',
    'django.contrib.sessions',
    'django.contrib.messages',
    'django.contrib.staticfiles',
    # Third party apps
    'rest_framework',
    'corsheaders',
    # Watson apps
    'core',
    'reviews',
]

MIDDLEWARE = [
    'django.middleware.security.SecurityMiddleware',
    'corsheaders.middleware.CorsMiddleware',
    'django.contrib.sessions.middleware.SessionMiddleware',
    'django.middleware.common.CommonMiddleware',
    'django.middleware.csrf.CsrfViewMiddleware',
    'django.contrib.auth.middleware.AuthenticationMiddleware',
    'django.contrib.messages.middleware.MessageMiddleware',
    'django.middleware.clickjacking.XFrameOptionsMiddleware',
]

ROOT_URLCONF = 'watson.urls'

TEMPLATES = [
    {
        'BACKEND': 'django.template.backends.django.DjangoTemplates',
        'DIRS': [],
        'APP_DIRS': True,
        'OPTIONS': {
            'context_processors': [
                'django.template.context_processors.request',
                'django.contrib.auth.context_processors.auth',
                'django.contrib.messages.context_processors.messages',
            ],
        },
    },
]

WSGI_APPLICATION = 'watson.wsgi.application'


# Database
# https://docs.djangoproject.com/en/5.2/ref/settings/#databases

DATABASES = {
    'default': {
        'ENGINE': 'django.db.backends.postgresql',
        'NAME': os.environ.get('DB_NAME', 'watson_dev'),
        'USER': os.environ.get('DB_USER', 'postgres'),
        'PASSWORD': os.environ.get('DB_PASSWORD', ''),
        'HOST': os.environ.get('DB_HOST', 'localhost'),
        'PORT': os.environ.get('DB_PORT', '5432'),
    }
} if os.environ.get('DATABASE_URL') else {
    'default': {
        'ENGINE': 'django.db.backends.sqlite3',
        'NAME': BASE_DIR / 'db.sqlite3',
    }
}


# Password validation
# https://docs.djangoproject.com/en/5.2/ref/settings/#auth-password-validators

AUTH_PASSWORD_VALIDATORS = [
    {
        'NAME': 'django.contrib.auth.password_validation.UserAttributeSimilarityValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.MinimumLengthValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.CommonPasswordValidator',
    },
    {
        'NAME': 'django.contrib.auth.password_validation.NumericPasswordValidator',
    },
]


# Internationalization
# https://docs.djangoproject.com/en/5.2/topics/i18n/

LANGUAGE_CODE = 'en-us'

TIME_ZONE = 'UTC'

USE_I18N = True

USE_TZ = True


# Static files (CSS, JavaScript, Images)
# https://docs.djangoproject.com/en/5.2/howto/static-files/

STATIC_URL = '/static/'
STATIC_ROOT = BASE_DIR / 'staticfiles'

# Additional static files directories
STATICFILES_DIRS = [
    BASE_DIR / 'static',
]

# Static file storage and optimization
STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.StaticFilesStorage'

# Production static file settings
if not DEBUG:
    STATICFILES_STORAGE = 'django.contrib.staticfiles.storage.ManifestStaticFilesStorage'

# Default primary key field type
# https://docs.djangoproject.com/en/5.2/ref/settings/#default-auto-field

DEFAULT_AUTO_FIELD = 'django.db.models.BigAutoField'

# Django REST Framework configuration
REST_FRAMEWORK = {
    'DEFAULT_PERMISSION_CLASSES': [
        'rest_framework.permissions.IsAuthenticated',
    ],
    'DEFAULT_AUTHENTICATION_CLASSES': [
        'rest_framework.authentication.SessionAuthentication',
    ],
    'DEFAULT_RENDERER_CLASSES': [
        'rest_framework.renderers.JSONRenderer',
    ],
    'DEFAULT_PARSER_CLASSES': [
        'rest_framework.parsers.JSONParser',
    ],
}

# CORS configuration for development
CORS_ALLOWED_ORIGINS = [
    "http://localhost:8881",  # Bun frontend dev port
    "http://127.0.0.1:8881",
]

CORS_ALLOW_CREDENTIALS = True

# Development-specific settings
if DEBUG:
    CORS_ALLOW_ALL_ORIGINS = True
</file>

<file path="backend/watson/urls.py">
"""
URL configuration for watson project.

The `urlpatterns` list routes URLs to views. For more information please see:
    https://docs.djangoproject.com/en/5.2/topics/http/urls/
Examples:
Function views
    1. Add an import:  from my_app import views
    2. Add a URL to urlpatterns:  path('', views.home, name='home')
Class-based views
    1. Add an import:  from other_app.views import Home
    2. Add a URL to urlpatterns:  path('', Home.as_view(), name='home')
Including another URLconf
    1. Import the include() function: from django.urls import include, path
    2. Add a URL to urlpatterns:  path('blog/', include('blog.urls'))
"""
from django.contrib import admin
from django.urls import path
from core.views import health_check, readiness_check

urlpatterns = [
    path('admin/', admin.site.urls),
    path('health/', health_check, name='health_check'),
    path('ready/', readiness_check, name='readiness_check'),
]
</file>

<file path="docker/caddy/Caddyfile.local">
# Local reverse proxy for developer workflow
# Domain: http://watson.lvh.me:3321 (HTTP only; no TLS for local)
# Routes:
#   - /            -> Bun dev server (frontend) on :8881
#   - /api/*       -> Django API on :8888
#   - /admin/*     -> Django admin on :8888

{
  auto_https off
}

http://watson.lvh.me:3321 {
  encode gzip

  # API/Admin to Django
  handle_path /api/* {
    reverse_proxy localhost:8888
  }
  handle_path /admin/* {
    reverse_proxy localhost:8888
  }

  # Everything else to the frontend dev server
  handle {
    reverse_proxy localhost:8881
  }
}
</file>

<file path="docker/caddy/Caddyfile.prod">
# Production reverse proxy for watson.oceanheart.ai
#
# Assumptions:
# - Frontend static files are deployed to /srv/www/dist/static
# - Django app is reachable at host "django" on port 8000 (e.g., via Docker network)
# - Optional: Django staticfiles mounted at /srv/backend/staticfiles
#
# Notes:
# - Caddy will manage TLS via Let's Encrypt automatically for the domain.
# - Adjust origins and paths as needed for your deployment layout.

watson.oceanheart.ai {
  encode gzip zstd

  # Security headers (adjust CSP as your frontend requires)
  header {
    X-Content-Type-Options "nosniff"
    X-Frame-Options "DENY"
    Referrer-Policy "strict-origin-when-cross-origin"
    Strict-Transport-Security "max-age=31536000; includeSubDomains; preload"
  }

  # API and Admin routed to Django
  @api path /api/*
  handle @api {
    reverse_proxy django:8000
  }
  @admin path /admin/*
  handle @admin {
    reverse_proxy django:8000
  }

  # Optional: serve Django static files directly if mounted
  handle_path /static/* {
    root * /srv/backend/staticfiles
    file_server
  }

  # Frontend SPA static files
  root * /srv/www/dist/static
  try_files {path} /index.html
  file_server
}
</file>

<file path="docker/caddy/README.md">
# Caddy Reverse Proxy

This folder contains ready‑to‑use Caddyfiles for local development and production.

## Local
- File: `docker/caddy/Caddyfile.local`
- Domain: `http://watson.lvh.me:3321`
- Routes:
  - `/api/*`, `/admin/*` → `localhost:8888` (Django)
  - everything else → `localhost:8881` (Bun dev server)

Run locally (assuming Caddy is installed):

```
caddy run --config docker/caddy/Caddyfile.local --adapter caddyfile

Notes:
- The local Caddyfile disables automatic HTTPS and binds to HTTP on port 3321 to avoid ACME lookups.
- Proxies frontend to :8881 and API to :8888.
- Visit: http://watson.lvh.me:3321
```

## Production
- File: `docker/caddy/Caddyfile.prod`
- Domain: `https://watson.oceanheart.ai` (TLS via Let’s Encrypt)
- Expects:
  - Frontend static at `/srv/www/dist/static`
- Django reachable as host `django:8000` (e.g., Docker network)
  - Optional Django static at `/srv/backend/staticfiles`

Example Docker Compose service:

```yaml
services:
  caddy:
    image: caddy:2
    ports: ["80:80", "443:443"]
    volumes:
      - ./docker/caddy/Caddyfile.prod:/etc/caddy/Caddyfile:ro
      - ./dist/static:/srv/www/dist/static:ro
      - ./backend/staticfiles:/srv/backend/staticfiles:ro
      - caddy_data:/data
      - caddy_config:/config
    depends_on:
      - watson
volumes:
  caddy_data:
  caddy_config:
```

Adjust paths and service names to match your environment.
</file>

<file path="docs/specs/001-build.prd.spec">
# Watson Build System - Product Requirements Document

**Version**: 1.0  
**Date**: 2025-09-12  
**Author**: Senior Product Development Architect  
**Status**: Draft  

---

## 1. Executive Summary

Watson is a clinical LLM output review and curation tool requiring a sophisticated multi-language build system to support Python (UV), TypeScript/JavaScript (Bun), and Ruby environments. The build system must enable efficient development workflows, reliable testing, and seamless deployment across multiple environments while maintaining strict isolation between language ecosystems.

This PRD defines the requirements for a comprehensive build system that balances developer experience, deployment reliability, and operational simplicity for the Watson clinical review platform.

---

## 2. Project Context

### 2.1 Architecture Overview
- **Backend**: Django 5 + Django REST Framework + HTMX
- **Frontend**: TypeScript/React with TipTap rich text editor
- **Database**: PostgreSQL with JSONB support (Neon hosted)
- **Authentication**: JWT from passport.oceanheart.ai (RS256)
- **Deployment**: Cloud platforms (Render/Railway/Fly)

### 2.2 Multi-Language Requirements
- **Python**: UV package manager for Django backend and data processing
- **TypeScript/JavaScript**: Bun runtime for frontend and build tooling  
- **Ruby**: Bundle for auxiliary tooling and scripts

### 2.3 Core Workflow Dependencies
The build system must support the complete Watson workflow:
1. Document ingestion and LLM output generation
2. Rich text editing with TipTap/ProseMirror
3. Real-time diff computation (token + structural JSON)
4. Analytics dashboard with data visualization
5. Export generation (JSONL/CSV bundles)

---

## 3. Requirements Analysis

### 3.1 Functional Requirements

#### 3.1.1 Development Environment Setup
- **DEV-001**: Automated environment initialization for all three language stacks
- **DEV-002**: Dependency management isolation between Python, TypeScript, and Ruby
- **DEV-003**: Hot reloading support for both backend (Django) and frontend (React/TipTap)
- **DEV-004**: Environment variable management across all stacks
- **DEV-005**: Database migration and seed data management

#### 3.1.2 Build Pipeline
- **BUILD-001**: TypeScript transpilation and bundling using Bun
- **BUILD-002**: Python package building and dependency resolution via UV
- **BUILD-003**: Ruby gem management and script execution
- **BUILD-004**: Static asset processing (CSS, images, fonts)
- **BUILD-005**: Production-optimized builds with minification and tree-shaking

#### 3.1.3 Testing Infrastructure
- **TEST-001**: Python test execution using Django's test framework
- **TEST-002**: TypeScript/JavaScript testing with Bun's built-in test runner
- **TEST-003**: Ruby test execution with standard test frameworks
- **TEST-004**: Integration testing across language boundaries
- **TEST-005**: Database testing with isolated test environments

#### 3.1.4 Deployment Automation
- **DEPLOY-001**: Container image building for cloud deployment
- **DEPLOY-002**: Environment-specific configuration management
- **DEPLOY-003**: Database migration execution in deployment pipeline
- **DEPLOY-004**: Static asset deployment to CDN/storage
- **DEPLOY-005**: Health checks and rollback mechanisms

### 3.2 Non-Functional Requirements

#### 3.2.1 Performance
- **PERF-001**: Build times under 2 minutes for development builds
- **PERF-002**: Hot reload response times under 500ms
- **PERF-003**: Production build optimization for minimal bundle sizes
- **PERF-004**: Parallel execution of independent build tasks

#### 3.2.2 Reliability
- **REL-001**: Build process must be deterministic and reproducible
- **REL-002**: Dependency lock files for all package managers (UV, Bun, Bundle)
- **REL-003**: Build failure detection and clear error reporting
- **REL-004**: Rollback capability for failed deployments

#### 3.2.3 Developer Experience
- **DX-001**: Single command setup for new developers
- **DX-002**: Clear documentation for common build tasks
- **DX-003**: IDE integration with TypeScript, Python, and Ruby tooling
- **DX-004**: Consistent command interface across all languages

### 3.3 Technical Constraints

#### 3.3.1 Language Version Requirements
- **Python**: 3.11+ (for Django 5 compatibility)
- **Node.js**: Bun runtime (no Node.js dependency)
- **Ruby**: 3.0.0+ (current Gemfile specification)
- **TypeScript**: 5.0+ (peer dependency requirement)

#### 3.3.2 Package Manager Constraints
- **Python**: Must use UV (no pip, pipenv, or poetry)
- **JavaScript**: Must use Bun (no npm, yarn, or pnpm)
- **Ruby**: Must use Bundle (standard Ruby package manager)

#### 3.3.3 Platform Compatibility
- **Primary**: macOS (Darwin) development environment
- **Secondary**: Linux deployment environments
- **Tertiary**: Windows development environment (WSL)

---

## 4. Implementation Phases

### Phase 0: Foundation Setup (001-build-00.prd.spec)
**Scope**: Basic multi-language environment initialization and dependency management

**Key Features**:
- UV environment setup with Python 3.11+
- Bun installation and TypeScript configuration
- Ruby Bundle configuration
- Basic project structure validation
- Environment variable template creation

**Success Criteria**:
- All three language environments can be initialized from scratch
- Dependencies install without conflicts
- Basic "hello world" execution in each language
- Clear setup documentation

**Dependencies**: None
**Estimated Effort**: 1-2 days

### Phase 1: Development Workflow (001-build-01.prd.spec)
**Scope**: Hot reloading, development servers, and local testing infrastructure

**Key Features**:
- Django development server with hot reload
- Bun-based frontend development with HMR
- File watching for automatic rebuilds
- Local database setup and migrations
- Development environment health checks

**Success Criteria**:
- Changes to Python code trigger Django reload
- Frontend changes reflect immediately in browser
- Database migrations run automatically
- All services can start with single command

**Dependencies**: Phase 0 completion
**Estimated Effort**: 2-3 days

### Phase 2: Build Pipeline (001-build-02.prd.spec)
**Scope**: Production-ready build processes and asset optimization

**Key Features**:
- TypeScript transpilation and bundling with Bun
- Python package building and optimization
- Static asset processing and optimization
- Build artifact validation
- Environment-specific configuration

**Success Criteria**:
- Production builds complete without errors
- Static assets are properly optimized
- Build artifacts are deployment-ready
- Build process is deterministic

**Dependencies**: Phase 1 completion
**Estimated Effort**: 2-3 days

### Phase 3: Testing Infrastructure (001-build-03.prd.spec)
**Scope**: Comprehensive testing setup across all language stacks

**Key Features**:
- Django test suite execution
- Bun test runner for TypeScript/JavaScript
- Ruby test framework integration
- Test database isolation
- Coverage reporting

**Success Criteria**:
- All test suites run independently
- Test databases are properly isolated
- Coverage reports generated
- CI/CD integration ready

**Dependencies**: Phase 2 completion
**Estimated Effort**: 2-3 days

### Phase 4: Deployment Automation (001-build-04.prd.spec)
**Scope**: Production deployment pipeline and infrastructure

**Key Features**:
- Docker containerization
- Cloud platform deployment scripts
- Database migration automation
- Environment configuration management
- Health checks and monitoring

**Success Criteria**:
- Automated deployment to staging/production
- Database migrations execute safely
- Health checks validate deployment
- Rollback procedures tested

**Dependencies**: Phase 3 completion
**Estimated Effort**: 3-4 days

---

## 5. Technical Implementation Details

### 5.1 Build Tool Requirements

#### 5.1.1 Bun Configuration
```json
{
  "scripts": {
    "dev": "bun --hot ./src/index.ts",
    "build": "bun build ./src/index.ts --outdir ./dist --minify",
    "test": "bun test",
    "typecheck": "tsc --noEmit"
  },
  "build": {
    "target": "browser",
    "outdir": "./dist",
    "entryPoints": ["./src/index.ts"],
    "splitting": true,
    "format": "esm"
  }
}
```

#### 5.1.2 UV Configuration
```toml
[project]
name = "watson-oceanheart-ai"
version = "0.1.0"
requires-python = ">=3.11"
dependencies = [
    "django>=5.0",
    "djangorestframework",
    "django-cors-headers",
    "psycopg2-binary",
    "python-jose[cryptography]",
    "requests"
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"
```

#### 5.1.3 Bundle Configuration
```ruby
source 'https://rubygems.org'
ruby '3.0.0'

gem 'rake'
gem 'minitest'
gem 'rubocop'
```

### 5.2 File Structure Organization
```
watson.oceanheart.ai/
├── backend/                 # Django application
│   ├── watson/             # Main Django project
│   ├── apps/               # Django apps
│   ├── static/             # Static assets
│   └── requirements/       # Environment-specific deps
├── frontend/               # TypeScript/React frontend
│   ├── src/                # Source code
│   ├── public/             # Public assets
│   └── dist/               # Build output
├── scripts/                # Ruby and other scripts
├── docs/                   # Documentation
├── tests/                  # Cross-language tests
├── docker/                 # Container configurations
└── deploy/                 # Deployment scripts
```

### 5.3 Environment Management

#### 5.3.1 Development Environment Variables
```bash
# Database
DATABASE_URL=postgresql://localhost:5432/watson_dev
REDIS_URL=redis://localhost:6379/0

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Django
DEBUG=true
SECRET_KEY=dev-secret-key
ALLOWED_HOSTS=localhost,127.0.0.1

# Bun/Frontend
NODE_ENV=development
VITE_API_URL=http://localhost:8888
```

#### 5.3.2 Production Environment Variables
```bash
# Database
DATABASE_URL=${DATABASE_URL}
REDIS_URL=${REDIS_URL}

# Authentication
PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
JWT_ALGORITHM=RS256

# Django
DEBUG=false
SECRET_KEY=${SECRET_KEY}
ALLOWED_HOSTS=${ALLOWED_HOSTS}

# Frontend
NODE_ENV=production
VITE_API_URL=${API_URL}
```

---

## 6. Integration Points

### 6.1 Frontend-Backend Integration
- **API Endpoints**: RESTful API with Django REST Framework
- **Authentication**: JWT validation middleware
- **Static Assets**: Django serves development assets, CDN in production
- **WebSocket**: HTMX for real-time interactions

### 6.2 Database Integration
- **Migrations**: Django migration system
- **Seed Data**: Management commands for test data
- **Backup/Restore**: Automated database backup procedures

### 6.3 External Service Integration
- **Passport Authentication**: JWT token validation
- **Database Hosting**: Neon PostgreSQL integration
- **File Storage**: Static asset storage (local/S3/CDN)

---

## 7. Quality Assurance

### 7.1 Code Quality Standards
- **Python**: Black formatting, isort imports, flake8 linting
- **TypeScript**: ESLint with TypeScript rules, Prettier formatting
- **Ruby**: RuboCop linting and formatting

### 7.2 Testing Strategy
- **Unit Tests**: Each language stack has comprehensive unit tests
- **Integration Tests**: Cross-language integration validation
- **End-to-End Tests**: Full workflow testing with real database
- **Performance Tests**: Build time and runtime performance validation

### 7.3 Security Requirements
- **Dependency Scanning**: Automated vulnerability scanning
- **Secret Management**: No hardcoded secrets in code
- **Container Security**: Minimal attack surface in containers

---

## 8. Monitoring and Observability

### 8.1 Build Monitoring
- **Build Success Rates**: Track successful vs failed builds
- **Build Performance**: Monitor build times and resource usage
- **Dependency Health**: Track outdated and vulnerable dependencies

### 8.2 Deployment Monitoring
- **Deployment Success**: Track successful deployments
- **Rollback Events**: Monitor and alert on rollbacks
- **Health Check Status**: Continuous application health monitoring

---

## 9. Documentation Requirements

### 9.1 Developer Documentation
- **Setup Guide**: Comprehensive environment setup instructions
- **Build Commands**: Reference for all build system commands
- **Troubleshooting**: Common issues and solutions
- **Architecture Guide**: Build system architecture overview

### 9.2 Operations Documentation
- **Deployment Guide**: Production deployment procedures
- **Monitoring Guide**: Monitoring and alerting setup
- **Incident Response**: Build and deployment incident procedures

---

## 10. Success Metrics

### 10.1 Developer Experience Metrics
- **Setup Time**: New developer can start contributing in <30 minutes
- **Build Time**: Development builds complete in <2 minutes
- **Hot Reload Time**: Changes reflect in <500ms
- **Test Execution Time**: Full test suite completes in <5 minutes

### 10.2 Reliability Metrics
- **Build Success Rate**: >95% successful builds
- **Deployment Success Rate**: >98% successful deployments
- **Mean Time to Recovery**: <15 minutes for build/deployment issues
- **Zero Downtime Deployments**: 100% of deployments are zero-downtime

### 10.3 Maintenance Metrics
- **Dependency Freshness**: <30 days average age for non-major updates
- **Security Vulnerability Resolution**: <24 hours for critical vulnerabilities
- **Build System Updates**: Minimal disruption to developer workflow

---

## 11. Risk Assessment

### 11.1 Technical Risks
- **Multi-Language Complexity**: Managing three different language ecosystems
- **Build Tool Maturity**: Bun is relatively new compared to established tools
- **Dependency Conflicts**: Potential conflicts between language-specific dependencies

### 11.2 Mitigation Strategies
- **Containerization**: Use containers to isolate language environments
- **Fallback Plans**: Alternative build tools ready if Bun issues arise
- **Comprehensive Testing**: Extensive testing to catch dependency conflicts early

---

## 12. Conclusion

This PRD establishes the foundation for a robust, multi-language build system supporting Watson's clinical LLM review platform. The phased approach ensures systematic implementation while maintaining focus on developer experience and deployment reliability.

The build system must balance the complexity of supporting Python (UV), TypeScript (Bun), and Ruby environments while providing a unified, simple interface for developers and operations teams.

Success depends on careful attention to integration points, comprehensive testing, and maintaining flexibility for the evolving needs of the Watson platform.
</file>

<file path="docs/specs/deployment.prd.md">
# Watson Deployment Strategy PRD

Date: 2025-09-12

## Executive Summary
Define a pragmatic deployment for watson.oceanheart.ai with clean separation of dev/prod databases, simple reverse proxying, and smooth local development at watson.lvh.me:3321. Prefer managed Postgres and a developer‑friendly proxy (Caddy) for TLS and routing.

## Problem Statement
We need a cohesive, low‑friction path from local dev to production: consistent URLs, secure env config, separate DBs, and repeatable deployment using existing scripts (deploy/, docker/).

## Requirements
### User requirements
- Access production at https://watson.oceanheart.ai with HTTPS.
- Local dev at http://watson.lvh.me:3321 with frontend hot‑reload and API routing.

### Technical requirements
- Separate Postgres instances for dev and prod; migrations tracked and automated.
- Reverse proxy terminates TLS, serves static assets, and routes /api to Django.
- CI gates deploys with tests (use `npm run test:all`) and build validation.
- Single command deploy via `deploy/deploy.sh` (Render/Fly) or Docker on a VM.

### Design requirements
- Use `.env.*` files from provided templates; never commit secrets.
- Health checks in place and a rollback path.

## Implementation Phases
### Phase 1: Local development
- Run DB/Redis/Django via `docker-compose up -d` (ports 5432, 6379, 8888).
- Start frontend: `npm run dev` (bun dev). Use Caddy to expose http://watson.lvh.me:3321 and route:
  - `/` → `localhost:8881` (Bun dev server)
  - `/api/*` → `localhost:8888` (Django)

Example Caddyfile (local):
```
watson.lvh.me:3321 {
  reverse_proxy /api/* localhost:8888
  reverse_proxy localhost:8881
}
```

### Phase 2: Production (managed platform)
- Preferred: Render or Fly.io using `deploy/deploy.sh -p render` or `-p fly`.
- DNS: `A/AAAA` for `watson.oceanheart.ai` per platform instructions.
- Configure env from `.env.production` (use `.env.production.template`).
- DB: Managed Postgres (two databases: `watson_prod`, `watson_staging`), expose `DATABASE_URL` only.
- Static assets: build with `npm run build:prod`; platform serves static or proxy to Django `collectstatic` output.

### Phase 3: Production (self‑hosted VM, optional)
- Services with Docker Compose (reuse `docker-compose.yml` pattern): Caddy (TLS via Let’s Encrypt), Django (gunicorn), Redis, Postgres (or managed).
- Example Caddyfile (prod):
```
watson.oceanheart.ai {
  encode gzip
  handle_path /api/* {
    reverse_proxy django:8000
  }
  root * /srv/www/dist/static
  file_server
}
```
- Publish built frontend to `/srv/www/dist/static` during deploy.

## Implementation Notes
- Migrations: `npm run migrate` or `./scripts/migrate.sh` post‑deploy.
- CI: `npm run ci:local` locally; platform CI must run `npm run test:all` and `npm run validate:build`.
- Env: derive from `.env.staging.template` and `.env.production.template`. Ensure `ALLOWED_HOSTS` includes target domains.

## Security Considerations
- Enforce HTTPS in production; HSTS via Caddy/Nginx.
- Strong `SECRET_KEY`, secure `DATABASE_URL`; rotate credentials.
- Limit admin access; configure CORS narrowly.

## Success Metrics
- Green CI before deploy; < 5 min zero‑downtime rollout; health check returns 200; error rates stable; page load and API latency within baseline.

## Future Enhancements
- Blue/green deploys with traffic switching.
- Automated DB backups and PITR; read replicas for analytics.
- Observability: logs, metrics, tracing (e.g., OpenTelemetry) with alerts.
</file>

<file path="scripts/dev-backend.sh">
#!/bin/bash

# Watson Backend Development Server
# Starts Django development server with hot reload

set -e

echo "🚀 Starting Watson Backend Development Server..."

# Load development environment variables
if [ -f .env.dev ]; then
    export $(cat .env.dev | grep -v '^#' | xargs)
    echo "✅ Loaded development environment variables"
else
    echo "⚠️  No .env.dev file found, using default settings"
fi

# Navigate to backend directory
cd backend

# Activate virtual environment
source ../.venv/bin/activate

# Run migrations if needed
echo "🔄 Checking for pending migrations..."
python manage.py migrate --check || {
    echo "📝 Running migrations..."
    python manage.py migrate
}

# Start development server with hot reload
echo "🔥 Starting Django development server with hot reload..."
echo "📍 Server will be available at: http://localhost:8888"
echo "🛑 Press Ctrl+C to stop the server"
echo ""

python manage.py runserver 0.0.0.0:8888
</file>

<file path="scripts/dev-frontend.sh">
#!/bin/bash

# Watson Frontend Development Server
# Starts Bun development server with HMR

set -e

echo "🚀 Starting Watson Frontend Development Server..."

# Load development environment variables
if [ -f .env.dev ]; then
    export $(cat .env.dev | grep -v '^#' | xargs)
    echo "✅ Loaded development environment variables"
else
    echo "⚠️  No .env.dev file found, using default settings"
fi

# Navigate to frontend directory
cd frontend

# Start Bun development server with HMR
echo "🔥 Starting Bun development server with Hot Module Reloading..."
echo "📍 Frontend will be available at: http://localhost:8881"
echo "🔗 API proxy to Django backend at: http://localhost:8888"
echo "🛑 Press Ctrl+C to stop the server"
echo ""

bun --hot ./index.ts
</file>

<file path="scripts/dev.sh">
#!/bin/bash

# Watson Unified Development Server
# Starts both Django backend and Bun frontend concurrently

set -e

echo "🚀 Starting Watson Development Environment..."
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# Function to cleanup processes on exit
cleanup() {
    echo -e "\n${YELLOW}🛑 Shutting down development servers...${NC}"
    kill $(jobs -p) 2>/dev/null || true
    exit 0
}

# Trap Ctrl+C and other termination signals
trap cleanup INT TERM

# Load development environment variables
if [ -f .env.dev ]; then
    export $(cat .env.dev | grep -v '^#' | xargs)
    echo -e "${GREEN}✅ Loaded development environment variables${NC}"
else
    echo -e "${YELLOW}⚠️  No .env.dev file found, using default settings${NC}"
fi

echo ""
echo -e "${BLUE}📋 Services to start:${NC}"
echo -e "  • Django Backend (port 8888)"
echo -e "  • React Frontend (port 8881)"
echo ""

# Start Django backend in background
echo -e "${BLUE}🐍 Starting Django backend...${NC}"
cd backend
source ../.venv/bin/activate

# Check and run migrations
echo -e "${BLUE}🔄 Checking for pending migrations...${NC}"
uv run python manage.py migrate --check || {
    echo -e "${YELLOW}📝 Running migrations...${NC}"
    uv run python manage.py migrate
}

# Start Django development server
uv run python manage.py runserver 0.0.0.0:8888 &
BACKEND_PID=$!
cd ..

# Wait a moment for backend to start
sleep 2

# Start Bun frontend in background
echo -e "${BLUE}⚡ Starting Bun frontend...${NC}"
cd frontend
bun --hot ./index.ts &
FRONTEND_PID=$!
cd ..

# Wait for both services to start
sleep 3

echo ""
echo -e "${GREEN}🎉 Watson Development Environment Ready!${NC}"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
echo -e "${BLUE}📍 Frontend:${NC} http://localhost:8881"
echo -e "${BLUE}📍 Backend API:${NC} http://localhost:8888"
echo -e "${BLUE}📍 Django Admin:${NC} http://localhost:8888/admin"
echo ""
echo -e "${YELLOW}🛑 Press Ctrl+C to stop all servers${NC}"
echo ""

# Keep script running and wait for background processes
wait $BACKEND_PID $FRONTEND_PID
</file>

<file path="scripts/health-check.sh">
#!/bin/bash

# Watson Development Environment Health Check
# Verifies that all development dependencies and services are ready

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

echo "🏥 Watson Development Environment Health Check"
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"

SUCCESS_COUNT=0
TOTAL_CHECKS=0

# Function to check and report status
check_status() {
    local name=$1
    local command=$2
    TOTAL_CHECKS=$((TOTAL_CHECKS + 1))
    
    printf "%-30s " "$name:"
    
    if eval "$command" &>/dev/null; then
        echo -e "${GREEN}✅ OK${NC}"
        SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
    else
        echo -e "${RED}❌ FAIL${NC}"
    fi
}

# Check Python and virtual environment
echo -e "\n${BLUE}🐍 Python Environment${NC}"
check_status "Virtual environment" "[ -d .venv ]"
check_status "Python executable" ".venv/bin/python --version"
check_status "Django installation" ".venv/bin/python -c 'import django'"
check_status "Django REST Framework" ".venv/bin/python -c 'import rest_framework'"

# Check Bun and Node dependencies
echo -e "\n${BLUE}⚡ Bun Environment${NC}"
check_status "Bun installation" "bun --version"
check_status "Node modules" "[ -d node_modules ]"
check_status "React installation" "[ -f node_modules/react/package.json ]"
check_status "TipTap installation" "[ -f node_modules/@tiptap/core/package.json ]"

# Check project structure
echo -e "\n${BLUE}📁 Project Structure${NC}"
check_status "Backend directory" "[ -d backend ]"
check_status "Frontend directory" "[ -d frontend ]"
check_status "Django project" "[ -f backend/manage.py ]"
check_status "Frontend entry point" "[ -f frontend/index.ts ]"

# Check configuration files
echo -e "\n${BLUE}⚙️  Configuration${NC}"
check_status "Django settings" "[ -f backend/watson/settings.py ]"
check_status "Package.json" "[ -f package.json ]"
check_status "Pyproject.toml" "[ -f pyproject.toml ]"
check_status "TypeScript config" "[ -f tsconfig.json ]"

# Check development scripts
echo -e "\n${BLUE}🛠️  Development Scripts${NC}"
check_status "Backend dev script" "[ -x scripts/dev-backend.sh ]"
check_status "Frontend dev script" "[ -x scripts/dev-frontend.sh ]"
check_status "Unified dev script" "[ -x scripts/dev.sh ]"
check_status "Environment file" "[ -f .env.dev ]"

# Database connectivity check
echo -e "\n${BLUE}💾 Database${NC}"
cd backend
if ./../.venv/bin/python manage.py migrate --check &>/dev/null; then
    echo -e "Database migrations     : ${GREEN}✅ OK${NC}"
    SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
else
    echo -e "Database migrations     : ${YELLOW}⚠️  Pending migrations detected${NC}"
fi
cd ..
TOTAL_CHECKS=$((TOTAL_CHECKS + 1))

# Port availability check
echo -e "\n${BLUE}🔌 Port Availability${NC}"
if ! lsof -i :8888 &>/dev/null; then
    echo -e "Port 8888 (Django)      : ${GREEN}✅ Available${NC}"
    SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
else
    echo -e "Port 8888 (Django)      : ${YELLOW}⚠️  In use${NC}"
fi

if ! lsof -i :8881 &>/dev/null; then
    echo -e "Port 8881 (Frontend)    : ${GREEN}✅ Available${NC}"
    SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
else
    echo -e "Port 8881 (Frontend)    : ${YELLOW}⚠️  In use${NC}"
fi
TOTAL_CHECKS=$((TOTAL_CHECKS + 2))

# Summary
echo ""
echo "━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━"
if [ $SUCCESS_COUNT -eq $TOTAL_CHECKS ]; then
    echo -e "${GREEN}🎉 All checks passed! ($SUCCESS_COUNT/$TOTAL_CHECKS)${NC}"
    echo -e "${GREEN}Ready to start development with: ./scripts/dev.sh${NC}"
    exit 0
else
    echo -e "${YELLOW}⚠️  Some checks failed: ($SUCCESS_COUNT/$TOTAL_CHECKS passed)${NC}"
    echo -e "${YELLOW}Please resolve the issues above before starting development${NC}"
    exit 1
fi
</file>

<file path=".env.dev">
# Watson Development Environment Variables

# Database (SQLite for development)
# DATABASE_URL=postgresql://localhost:5432/watson_dev

# Django settings
DEBUG=true
SECRET_KEY=dev-secret-key-change-in-production
ALLOWED_HOSTS=localhost,127.0.0.1

# Authentication (for future JWT integration)
# PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json
# JWT_ALGORITHM=RS256

# Frontend/API
NODE_ENV=development
API_URL=http://localhost:8888
</file>

<file path="build.config.ts">
// Watson Build Configuration for Production
// Optimized Bun build settings for clinical review application

export default {
  // Build targets and entry points
  entryPoints: ['./frontend/src/main.tsx'],
  outdir: './dist/static',
  
  // Optimization settings
  minify: true,
  splitting: true,
  format: 'esm' as const,
  target: 'browser',
  
  // Static asset configuration
  publicPath: '/static/',
  
  // Advanced optimization
  define: {
    'process.env.NODE_ENV': '"production"',
    'process.env.API_URL': 'process.env.API_URL || "http://localhost:8888"',
  },
  
  // Bundle splitting for better caching
  external: [],
  
  // Source maps for production debugging
  sourcemap: 'linked',
  
  // Asset handling
  loader: {
    '.png': 'file',
    '.jpg': 'file',
    '.jpeg': 'file',
    '.svg': 'file',
    '.woff': 'file',
    '.woff2': 'file',
    '.ttf': 'file',
    '.eot': 'file',
  },
  
  // Build metadata
  metafile: true,
  
  // Production-specific settings
  treeshaking: true,
  mangling: true,
  
  // Output naming for caching
  naming: {
    entry: '[name]-[hash].js',
    chunk: 'chunks/[name]-[hash].js',
    asset: 'assets/[name]-[hash].[ext]',
  },
} as const;
</file>

<file path="bun.test.config.ts">
import { GlobalWindow } from "happy-dom";

// Setup DOM environment for React component tests
const window = new GlobalWindow({
  url: 'http://localhost:8881',
  width: 1024,
  height: 768,
});

global.window = window as any;
global.document = window.document as any;
global.navigator = window.navigator as any;
global.HTMLElement = window.HTMLElement as any;
global.Element = window.Element as any;
global.Node = window.Node as any;
global.DocumentFragment = window.DocumentFragment as any;
global.Text = window.Text as any;
</file>

<file path="CLAUDE.md">
# CLAUDE.md

This file provides guidance to Claude Code (claude.ai/code) when working with code in this repository.

---

## Project Overview

**Watson** is a clinical LLM output review and curation tool for psychotherapy and well-being applications. It provides an environment for clinicians to review, edit, classify, and refine model-generated clinical summaries through a structured workflow: review → edit/classify → submit → diff → analytics → export.

This is a multi-language project supporting:
- **Backend**: Django 5 + DRF + HTMX (planned)
- **Frontend**: TypeScript/React with TipTap editor (using Bun)
- **Scripting**: Python with UV package manager
- **Additional**: Ruby support

---

## Development Environment Setup

### Python (UV)
```bash
# Activate the existing virtual environment
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
# Install dependencies
uv pip install -r requirements.txt  # when requirements.txt is created
```

### TypeScript/JavaScript (Bun)
```bash
# Install dependencies
bun install
# Development server (when TypeScript/frontend code is added)
bun --hot ./index.ts
```

### Ruby
```bash
# Install gems
bundle install
```

---

## Commands

### Bun (Primary JavaScript/TypeScript Runtime)

**Always use Bun instead of Node.js, npm, pnpm, or vite.**

- Use `bun <file>` instead of `node <file>` or `ts-node <file>`
- Use `bun test` to run tests
- Use `bun build <file.html|file.ts|file.css>` instead of `webpack` or `esbuild`
- Use `bun install` instead of `npm install` or `yarn install` or `pnpm install`
- Use `bun run <script>` instead of `npm run <script>` or `yarn run <script>` or `pnpm run <script>`
- Bun automatically loads .env, so don't use dotenv

### Python
- Use `python main.py` to run the main Python script
- UV is the preferred package manager for Python dependencies

### Ruby
- Use `bundle exec` to run Ruby commands with proper gem dependencies

---

## Architecture

### Core Workflow
1. **Seed**: Document + LLMOutput loaded
2. **Edit**: Clinician edits in TipTap rich editor, applies classification labels
3. **Submit**: Backend computes diffs (token + structural), stores immutable record
4. **Review/Diff**: Diff viewer shows before/after changes  
5. **Analytics**: Dashboard of change rates + label frequencies
6. **Export**: Generate research datasets (JSONL/CSV bundles)

### Data Model (Planned)
- **Document** – source clinical note (raw JSON)
- **LLMOutput** – model-generated summary tied to a Document
- **Edit** – clinician revision with diffs, edited JSON, status
- **Label** – taxonomy of issue types (hallucination, missing_risk, etc.)
- **EditLabel** – join table for applied labels

### Key Endpoints (Planned)
- `GET /outputs/:id` → view output snapshot
- `POST /edits` → create draft edit
- `PUT /edits/:id` → save draft changes
- `POST /edits/:id/submit` → finalize, compute diffs
- `GET /edits/:id/diff` → return/render diff
- `GET /analytics/basic` → JSON for dashboard
- `POST /exports` → create export bundle

---

## Frontend Development (Bun + React)

Use HTML imports with `Bun.serve()`. HTML imports fully support React, CSS, and Tailwind.

### Bun APIs (Preferred)
- `Bun.serve()` for HTTP server with WebSocket support (instead of Express)
- `bun:sqlite` for SQLite (instead of better-sqlite3)
- `Bun.redis` for Redis (instead of ioredis)  
- `Bun.sql` for Postgres (instead of pg or postgres.js)
- Built-in `WebSocket` (instead of ws library)
- `Bun.file` over `node:fs` readFile/writeFile
- `Bun.$` for shell commands (instead of execa)

### Testing
```ts
import { test, expect } from "bun:test";

test("example test", () => {
  expect(1).toBe(1);
});
```

### Frontend Structure
HTML files can directly import .tsx, .jsx, .js files and Bun will handle transpilation and bundling automatically.

---

## TypeScript Configuration

The project uses modern TypeScript with:
- ESNext target and lib
- React JSX transform
- Strict type checking enabled
- Bundler module resolution
- No emit (bundler handles compilation)

---

## Authentication

**Centralized Auth** via `passport.oceanheart.ai` JWTs with RS256 verification middleware.

---

## Documentation

Project specifications and PRDs are located in `docs/specs/`. Current documentation includes:
- Integration specifications for visual design systems
- Oceanheart Passport integration
- Style guide specifications
</file>

<file path="docker-compose.yml">
# Watson Docker Compose Configuration
# For local development and testing

services:
  database:
    image: postgres:15-alpine
    environment:
      POSTGRES_DB: watson_dev
      POSTGRES_USER: watson
      POSTGRES_PASSWORD: watson_dev_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./docker/init-db.sql:/docker-entrypoint-initdb.d/init-db.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U watson -d watson_dev"]
      interval: 10s
      timeout: 5s
      retries: 5

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5

  watson:
    build:
      context: .
      dockerfile: Dockerfile
    ports:
      - "8888:8000"
    environment:
      # Database
      DATABASE_URL: postgresql://watson:watson_dev_password@database:5432/watson_dev
      DB_NAME: watson_dev
      DB_USER: watson
      DB_PASSWORD: watson_dev_password
      DB_HOST: database
      DB_PORT: 5432
      REDIS_URL: redis://redis:6379/0
      
      # Django
      DEBUG: "false"
      SECRET_KEY: "docker-dev-secret-key-change-in-production"
      ALLOWED_HOSTS: "localhost,127.0.0.1,watson"
      DJANGO_SETTINGS_MODULE: "watson.settings.production"
      SECURE_SSL_REDIRECT: "false"  # disable HTTPS redirect in local compose
      
      # Authentication
      PASSPORT_JWKS_URL: "https://passport.oceanheart.ai/.well-known/jwks.json"
      JWT_ALGORITHM: "RS256"
      
      # Superuser creation
      DJANGO_SUPERUSER_USERNAME: "admin"
      DJANGO_SUPERUSER_EMAIL: "admin@watson.local"
      DJANGO_SUPERUSER_PASSWORD: "admin123"
      
    depends_on:
      database:
        condition: service_healthy
      redis:
        condition: service_healthy
    volumes:
      # Mount specific backend subdirectories to avoid overriding venv
      - ./backend/core:/app/backend/core:ro
      - ./backend/reviews:/app/backend/reviews:ro
      - ./backend/scripts:/app/backend/scripts:ro
      - ./backend/manage.py:/app/backend/manage.py:ro
      # Mount the entire watson app directory as read-write for development
      - ./backend/watson:/app/backend/watson:rw
    healthcheck:
      test: ["CMD", "/healthcheck.sh"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s

  # Development services
  frontend-dev:
    image: node:18-slim
    working_dir: /app
    ports:
      - "8881:3000"
    environment:
      NODE_ENV: development
      VITE_API_URL: http://localhost:8888
    volumes:
      - .:/app:ro
      - frontend_node_modules:/app/node_modules
    command: >
      sh -c "curl -fsSL https://bun.sh/install | bash &&
             export PATH=\"/root/.bun/bin:$PATH\" &&
             bun install &&
             bun run dev"
    profiles:
      - dev
    depends_on:
      - watson

  caddy:
    image: caddy:2
    profiles:
      - dev
    ports:
      - "3321:3321"
    volumes:
      - ./docker/caddy/Caddyfile.compose.local:/etc/caddy/Caddyfile:ro
    depends_on:
      watson:
        condition: service_started
      frontend-dev:
        condition: service_started

volumes:
  postgres_data:
  redis_data:
  frontend_node_modules:

networks:
  default:
    driver: bridge
</file>

<file path="Gemfile">
source 'https://rubygems.org'

ruby '3.4.5'

# Testing framework
gem 'rspec', '~> 3.12'
gem 'factory_bot', '~> 6.4'
gem 'faker', '~> 3.2'

# Development and test gems
group :development, :test do
  gem 'pry', '~> 0.14'
  gem 'rubocop', '~> 1.57'
  gem 'simplecov', '~> 0.22', require: false
end

# Add your gems here
</file>

<file path="README.md">
Here’s a README tailored to the Watson project as you just scoped it — **review → edit/classify → submit → diff → basic analytics → export**.

---

# Watson

**Clinical LLM Output Review & Curation Tool**
*(part of Oceanheart.ai)*

---

## 1. Overview

**Watson** is a prototype application exploring how clinicians can effectively **review and refine LLM outputs** in psychotherapy and related well-being fields.
It provides an environment to:

* Review a model-generated **clinical summary** or note.
* **Edit** the text or per-section content with a rich editor.
* **Classify/label** issues (e.g., hallucination, missing risk content).
* **Submit** the review, generating a structured **diff**.
* View **basic analytics** (change rates, label frequencies).
* **Export** collected datasets for research and iteration.

The focus is on **process evaluation**, not clinical deployment.

---

## 2. Key Features

* **Rich text editing** (TipTap/ProseMirror) with support for strike-through, insertions, and sectioned content.
* **Labeling/classification panel** to tag issues in outputs.
* **Server-side diffing** (token + structural JSON) when edits are submitted.
* **Basic analytics dashboard**: change rates, label frequency, per-section heatmap.
* **Dataset export** (JSONL/CSV in a zip bundle with manifest).
* **Django Admin console** for operational review and curation.
* **Centralized Auth** via `passport.oceanheart.ai` JWTs.

---

## 3. Tech Stack

| Layer      | Technology                          | Notes                                             |
| ---------- | ----------------------------------- | ------------------------------------------------- |
| Backend    | **Django 5** + DRF + HTMX           | Batteries-included MVC; lightweight interactivity |
| Frontend   | **TipTap** editor                   | ProseMirror-based rich-text editing               |
| Database   | **Postgres (Neon)**                 | JSONB for flexible storage + relational joins     |
| Auth       | **JWT from passport.oceanheart.ai** | RS256 verification middleware                     |
| Deployment | Render / Railway / Fly              | App server + Neon DB                              |
| Diffing    | `difflib`, `jsondiff`               | Token-level + structural JSON                     |

---

## 4. Data Model

* **Document** – source clinical note (raw JSON).
* **LLMOutput** – model-generated summary tied to a Document.
* **Edit** – clinician revision of an LLMOutput (with `edited_json`, diffs, status).
* **Label** – taxonomy of issue types (e.g., hallucination, missing\_risk).
* **EditLabel** – join table: which labels were applied to an Edit.

---

## 5. Core Workflow

1. **Seed**: A Document + LLMOutput is loaded.
2. **Edit**: Clinician opens the LLMOutput in TipTap, edits text/sections, applies labels.
3. **Submit**: Backend computes diffs (token + structural), stores immutable record.
4. **Review/Diff**: Diff viewer shows before/after changes.
5. **Analytics**: Simple dashboard of change rates + label frequencies.
6. **Export**: Generate a zip containing JSONL files of documents, outputs, edits, labels, and diffs.

---

## 6. Endpoints

* `GET /outputs/:id` → view output snapshot.
* `POST /edits` → create draft edit.
* `PUT /edits/:id` → save draft changes.
* `POST /edits/:id/submit` → finalize, compute diffs.
* `GET /edits/:id/diff` → return/render diff.
* `GET /analytics/basic` → JSON for dashboard.
* `POST /exports` → create export bundle.
* `GET /exports/:id` → download export.

---

## 7. Diffing

* **Text diff**: tokenized diff with insert/delete/replace ops.
* **Structural diff**: JSON node add/remove/replace/move with JSON pointers.
* Both are stored in `Edit.diff_text_json` and `Edit.diff_struct_json`.

---

## 8. Analytics (MVP)

* Change rate per section.
* Net length delta.
* Most frequent labels.
* Submission counts per clinician.

---

## 9. Export Format

```
manifest.json           # version, filters, timestamp, app_commit
documents.jsonl         # {doc_id, source, raw_json}
outputs.jsonl           # {output_id, doc_id, model, output_json, created_at}
edits.jsonl             # {edit_id, output_id, clinician_hash, edited_json,
                        #  diff_text_json, diff_struct_json, status}
labels.jsonl            # {edit_id, label_key, value}
README.txt
```

* Clinician IDs are hashed/salted.
* PHI should be stripped from raw documents before ingestion.

---

## 10. Installation

### Prerequisites

* Python 3.11+
* Postgres DB (Neon recommended)
* Node/npm (for TipTap assets)
* Redis (optional, for background tasks)

### Setup

```bash
git clone https://github.com/oceanheart-ai/watson
cd watson
python -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# env vars
export DATABASE_URL=postgresql://user:pass@host/db
export PASSPORT_JWKS_URL=https://passport.oceanheart.ai/.well-known/jwks.json

python manage.py migrate
python manage.py runserver
```

Frontend assets (TipTap) load via npm in `static/`.

---

## 11. Django Admin

* Manage Labels taxonomy.
* Review Edits inline with LLMOutputs.
* Diff preview widget in `EditAdmin`.
* Bulk export selected edits.

---

## 12. Roadmap

* **v0**: Review → Edit/Label → Submit → Diff → Analytics → Export.
* **v1**: Per-section editing; richer analytics; taxonomy versioning.
* **v2**: Multi-reviewer workflows, assignments, collaborative editing.

---

## 13. License

MIT License © 2025 Oceanheart.ai / Rick “Kai” Hallett.
See LICENSE for details.

---

## 14. Contact

* Website: [www.oceanheart.ai](https://www.oceanheart.ai)
* Lead developer: **Rick “Kai” Hallett**
* Email: [hello@oceanheart.ai](mailto:hello@oceanheart.ai)

---

Would you like me to also generate a **matching portfolio carousel card** (like I did for Preflight) with title/description/tech for Watson?


## Setup

### Python (UV)
```bash
uv venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
```

### TypeScript/JavaScript (Bun)
```bash
bun install
bun run dev
```

### Ruby
```bash
bundle install
```

## Development

[Add development instructions here]

## Contributing

[Add contributing guidelines here]
</file>

<file path="tsconfig.json">
{
  "compilerOptions": {
    // Environment setup & latest features
    "lib": ["ESNext", "DOM", "DOM.Iterable"],
    "target": "ESNext",
    "module": "Preserve",
    "moduleDetection": "force",
    "jsx": "react-jsx",
    "allowJs": true,

    // Bundler mode
    "moduleResolution": "bundler",
    "allowImportingTsExtensions": true,
    "verbatimModuleSyntax": true,
    "noEmit": true,

    // Best practices
    "strict": true,
    "skipLibCheck": true,
    "noFallthroughCasesInSwitch": true,
    "noUncheckedIndexedAccess": true,
    "noImplicitOverride": true,

    // Some stricter flags (disabled by default)
    "noUnusedLocals": false,
    "noUnusedParameters": false,
    "noPropertyAccessFromIndexSignature": false
  },
  "include": [
    "frontend/**/*",
    "scripts/**/*"
  ],
  "exclude": [
    "node_modules",
    "dist",
    "build",
    "backend"
  ]
}
</file>

<file path="docker/entrypoint.sh">
#!/bin/bash
# Watson Docker Entrypoint Script

set -e

echo "🚀 Starting Watson Application"
echo "================================"

# Ensure venv binaries are preferred
export PATH="/app/backend/.venv/bin:$PATH"
VENV_PY="/app/backend/.venv/bin/python"
if [ ! -x "$VENV_PY" ]; then
  echo "⚠️  Venv python not found at $VENV_PY, using system python"
  VENV_PY="python"
fi

# Wait for database to be ready
echo "📊 Waiting for database connection..."
cd /app/backend
"$VENV_PY" manage.py check --database default

# Run database migrations
echo "🔄 Running database migrations..."
"$VENV_PY" manage.py migrate --noinput

# Collect static files (skip if already done during build)
if [ ! -d "/app/backend/watson/staticfiles" ] || [ -z "$(ls -A /app/backend/watson/staticfiles)" ]; then
    echo "📁 Collecting static files..."
    "$VENV_PY" manage.py collectstatic --noinput --clear
else
    echo "📁 Static files already collected during build"
fi

# Create superuser if specified
if [[ $DJANGO_SUPERUSER_EMAIL ]]; then
    echo "👤 Creating superuser..."
    "$VENV_PY" manage.py createsuperuser \
        --noinput \
        --username $DJANGO_SUPERUSER_USERNAME \
        --email $DJANGO_SUPERUSER_EMAIL || true
fi

# Run any additional setup commands
if [[ -f /app/scripts/setup.sh ]]; then
    echo "⚙️ Running additional setup..."
    bash /app/scripts/setup.sh
fi

echo "✅ Watson application ready!"
echo ""

# Execute the main command
exec "$@"
</file>

<file path="frontend/index.ts">
import index from "./index.html";

// Type assertion for HTML imports
const indexContent = index as unknown as string;

const server = Bun.serve({
  port: 8881,
  fetch(request) {
    const url = new URL(request.url);
    
    // Serve the main HTML file
    if (url.pathname === "/" || url.pathname === "/index.html") {
      return new Response(indexContent, {
        headers: {
          "Content-Type": "text/html",
        },
      });
    }
    
    // Handle other routes (SPA routing)
    if (url.pathname.startsWith("/api/")) {
      // Proxy API requests to Django backend
      const backendUrl = `http://localhost:8888${url.pathname}${url.search}`;
      return fetch(backendUrl, {
        method: request.method,
        headers: request.headers,
        body: request.body,
      });
    }
    
    // For all other routes, serve the index.html (SPA)
    return new Response(indexContent, {
      headers: {
        "Content-Type": "text/html",
      },
    });
  },
  development: {
    hmr: true,
    console: true,
  },
});

console.log(`🚀 Watson Frontend Server running at http://localhost:${server.port}`);
console.log(`🔄 Hot Module Reloading enabled`);
console.log(`🔗 API proxy to Django backend at http://localhost:8888`);
console.log(`🛑 Press Ctrl+C to stop the server`);
</file>

<file path="docs/specs/001-build-change-log.md">
# Change Log: Watson Build System - Phase 1
## Date: 2025-09-12

## Overview

This change log tracks all modifications made during the implementation of Phase 1 (Development Workflow) of the Watson build system.

## Files Modified

### pyproject.toml
- **Change**: Added Django dependencies and hatchling build configuration
- **Rationale**: Enable Django 5.2+ with REST framework and PostgreSQL support
- **Impact**: Python package management and build system setup
- **Commit**: 8b8ba55

### package.json  
- **Change**: Added React, TipTap, and TypeScript dependencies with Bun scripts
- **Rationale**: Enable modern React frontend with rich text editing capabilities
- **Impact**: Frontend development workflow and dependency management
- **Commit**: dde6033

### backend/watson/settings.py
- **Change**: Added environment-based configuration, REST framework, and CORS setup  
- **Rationale**: Support development/production environments and frontend integration
- **Impact**: Django application configuration and API functionality
- **Commit**: 8b8ba55

### .env.dev
- **Change**: Created development environment variables template
- **Rationale**: Secure configuration management for development
- **Impact**: Environment setup and configuration consistency
- **Commit**: dde6033

### frontend/src/main.tsx
- **Change**: Created React 18 application entry point
- **Rationale**: Modern React application bootstrap
- **Impact**: Frontend application initialization
- **Commit**: dde6033

### frontend/src/App.tsx
- **Change**: Main React application component with TipTap editor integration
- **Rationale**: Clinical review interface with rich text editing
- **Impact**: Core application functionality
- **Commit**: dde6033

### frontend/src/components/TipTapEditor.tsx
- **Change**: Rich text editor component for clinical review workflow
- **Rationale**: Enable advanced text editing with formatting and review capabilities
- **Impact**: Primary user interface for clinical content editing
- **Commit**: dde6033

### frontend/src/index.css
- **Change**: Responsive CSS styling for Watson application
- **Rationale**: Professional UI/UX for clinical environment
- **Impact**: Visual design and user experience
- **Commit**: dde6033

### frontend/index.html
- **Change**: HTML template for React application
- **Rationale**: Single-page application entry point
- **Impact**: Application loading and structure
- **Commit**: dde6033

### frontend/index.ts
- **Change**: Bun server with HMR and API proxy functionality
- **Rationale**: Development server with hot reloading and backend integration
- **Impact**: Development workflow and frontend-backend communication
- **Commit**: dde6033

### scripts/dev-backend.sh
- **Change**: Django development server startup script
- **Rationale**: Automated backend development environment setup
- **Impact**: Developer experience and consistency
- **Commit**: dde6033

### scripts/dev-frontend.sh
- **Change**: Bun frontend development server script
- **Rationale**: Automated frontend development with HMR
- **Impact**: Frontend development workflow
- **Commit**: dde6033

### scripts/dev.sh
- **Change**: Unified development startup script for both services
- **Rationale**: Single command to start entire development environment
- **Impact**: Developer productivity and ease of use
- **Commit**: Final commit

### scripts/health-check.sh
- **Change**: Comprehensive development environment health verification
- **Rationale**: Ensure all dependencies and services are properly configured
- **Impact**: Development environment reliability and debugging
- **Commit**: Final commit

## Django Applications Created

### backend/core/
- **Change**: Core Django application for base functionality
- **Rationale**: Central location for shared models and utilities
- **Impact**: Application architecture and organization
- **Commit**: 8b8ba55

### backend/reviews/
- **Change**: Reviews Django application for clinical review workflow
- **Rationale**: Dedicated app for LLM output review functionality
- **Impact**: Feature separation and maintainability  
- **Commit**: 8b8ba55

## Dependencies Added/Removed

### Python Dependencies Added
- django>=5.0 - Web framework
- djangorestframework>=3.14.0 - REST API functionality
- django-cors-headers>=4.0.0 - CORS support for frontend integration
- psycopg2-binary>=2.9.0 - PostgreSQL database adapter
- python-jose[cryptography]>=3.3.0 - JWT authentication support
- requests>=2.28.0 - HTTP client for external API calls

### Frontend Dependencies Added
- react@^18.2.0 - UI framework
- react-dom@^18.2.0 - DOM rendering for React
- @tiptap/core@^2.1.0 - Rich text editor core
- @tiptap/react@^2.1.0 - React integration for TipTap
- @tiptap/starter-kit@^2.1.0 - Basic editing functionality
- @tiptap/extension-collaboration@^2.1.0 - Collaboration features
- @tiptap/extension-placeholder@^2.1.0 - Editor placeholder text
- @types/react@^18.2.0 - TypeScript definitions
- @types/react-dom@^18.2.0 - TypeScript definitions
- typescript@^5.0.0 - TypeScript compiler

## Breaking Changes

*No breaking changes - this is initial implementation*

## Implementation Notes

- **Phase**: 2 (Build Pipeline) - ✅ **COMPLETE**  
- **Started**: 2025-09-12
- **Completed**: 2025-09-12
- **Focus**: Production builds, asset optimization, environment configuration, validation
- **Target Languages**: Python (Django), TypeScript (Bun), Ruby (prepared)
- **Success Criteria**: All 4 success criteria achieved ✅

## Commit History

### 8b8ba55 - Backend Infrastructure
```
feat(backend): initialize Django project structure with core and reviews apps
- Add Django 5.2.6 project with REST framework and CORS support
- Configure environment-based settings for development/production  
- Create core and reviews Django applications
- Update pyproject.toml with Django dependencies and hatchling config
- Add PostgreSQL support with SQLite fallback for development
```

### dde6033 - Frontend & Development Workflow
```
feat(frontend): add React frontend with TipTap editor and Bun HMR server
- Create React 18 frontend with TypeScript support
- Implement TipTap rich text editor for clinical review workflow
- Add Bun development server with Hot Module Reloading
- Include frontend development script with environment loading
- Configure API proxy to Django backend on localhost:8888
- Add responsive CSS styling for clinical review interface
- Update package.json with TipTap and React dependencies
```

### 67feb90 - Development Scripts & Health Checks (Phase 1 Complete)
```
feat(build): add unified development workflow and health checks
- Create unified development startup script (scripts/dev.sh)
- Add comprehensive health check system (scripts/health-check.sh)  
- Enable single-command development environment startup
- Implement concurrent frontend/backend service management
- Add environment verification and port availability checks
- Complete Phase 1 development workflow implementation
```

### Phase 2 Commits - Production Build Pipeline

#### Updated Package.json & Build Configuration
```
feat(build): enhance TypeScript build pipeline with Bun optimization
- Add environment-specific build scripts (build, build:clean, build:frontend, build:backend)
- Configure production optimization with code splitting and minification
- Add build validation script integration (validate:build)
- Update dependencies for production build workflow
```

#### Build Configuration & Optimization Scripts
```
feat(build): add build configuration and asset optimization
- Create build.config.ts with production optimization settings
- Add build-production.sh for comprehensive production builds
- Implement optimize-assets.sh for compression analysis and recommendations
- Configure Django static file management with ManifestStaticFilesStorage
```

#### Build Validation & Security
```  
feat(build): implement comprehensive build validation system
- Create validate-build.js with security and integrity checks
- Add file validation, bundle analysis, and Django static verification
- Implement development artifact detection and security scanning
- Generate detailed validation reports with actionable recommendations
```

#### Environment-Specific Configuration
```
feat(build): add environment-specific build configurations
- Create .env.production and .env.staging environment files
- Implement build-env.sh for environment-aware build process
- Add conditional optimization levels (basic/full/aggressive)  
- Configure security settings per environment (SSL, cookies, etc.)
- Enable/disable source maps based on environment
```

#### TypeScript & Frontend Improvements
```
fix(frontend): resolve TypeScript compilation issues
- Update tsconfig.json with DOM libraries and proper includes
- Add frontend/types.d.ts for HTML module declarations
- Fix HTML import syntax for Bun compatibility
- Resolve build pipeline TypeScript errors
```
</file>

<file path="Dockerfile">
# Watson Multi-Stage Docker Build
# Supports Django backend, Bun frontend, and Ruby services

FROM oven/bun:1.1 as frontend-builder
WORKDIR /app

# Copy frontend source only
COPY package.json bun.lock ./
COPY tsconfig.json ./
COPY frontend/ ./frontend/

# Install dependencies and build frontend assets
RUN bun install
RUN bun run build:clean && bun run build:frontend

# Python/Django stage
FROM python:3.11-slim as backend-base

# Install system dependencies
RUN apt-get update && apt-get install -y \
    build-essential \
    libpq-dev \
    curl \
    && rm -rf /var/lib/apt/lists/*

# (Optional) Install tools; we'll use Python venv + pip for reliability

WORKDIR /app

# Copy Python requirements
COPY pyproject.toml ./
COPY backend/ ./backend/

# Create virtual environment and install dependencies from pyproject
RUN python -m venv /app/backend/.venv \
    && /app/backend/.venv/bin/pip install --upgrade pip \
    && /app/backend/.venv/bin/pip install -e /app \
    && /app/backend/.venv/bin/pip install \
        "django>=5.0" \
        "djangorestframework>=3.14.0" \
        "django-cors-headers>=4.0.0" \
        "psycopg2-binary>=2.9.0" \
        "python-jose[cryptography]>=3.3.0" \
        "requests>=2.28.0" \
        "factory-boy>=3.3.0" \
        "faker>=21.0.0" \
        "coverage>=7.3.0" \
        "django-coverage-plugin>=3.1.0" \
        "gunicorn>=21.2.0" \
        "whitenoise>=6.6.0"

# Ruby services stage
FROM ruby:3.4.5-slim as ruby-services

WORKDIR /app

# Install system dependencies for Ruby
RUN apt-get update && apt-get install -y \
    build-essential \
    && rm -rf /var/lib/apt/lists/*

# Copy Ruby configuration
COPY Gemfile Gemfile.lock ./
COPY lib/ ./lib/
COPY scripts/ ./scripts/

# Install Ruby dependencies
RUN bundle config set --local path 'vendor/bundle' && \
    bundle install --jobs 4 --retry 3

# Final production stage
FROM python:3.11-slim

# Install runtime and minimal build dependencies
RUN apt-get update && apt-get install -y \
    libpq5 \
    libpq-dev \
    build-essential \
    curl \
    && rm -rf /var/lib/apt/lists/*

# Create app user
RUN groupadd -g 999 app && \
    useradd -r -u 999 -g app app

WORKDIR /app

# Copy backend source, venv, and project metadata from backend-base
COPY --from=backend-base /app/backend /app/backend
COPY --from=backend-base /app/pyproject.toml /app/

# Copy built frontend assets
COPY --from=frontend-builder /app/dist /app/backend/staticfiles/

# Copy Ruby services
COPY --from=ruby-services /app/vendor /app/vendor
COPY --from=ruby-services /app/lib /app/lib
COPY --from=ruby-services /app/scripts /app/scripts
COPY --from=ruby-services /app/Gemfile* /app/

# Copy configuration files
COPY docker/entrypoint.sh /entrypoint.sh
COPY docker/healthcheck.sh /healthcheck.sh

# Set permissions and create log directory
RUN chmod +x /entrypoint.sh /healthcheck.sh && \
    mkdir -p /var/log/watson && \
    # Create static directory if it doesn't exist
    mkdir -p /app/backend/watson/static && \
    chown -R app:app /app /var/log/watson && \
    # Fix venv symlinks after chown (they point to system python)
    ln -sf /usr/local/bin/python /app/backend/.venv/bin/python && \
    ln -sf python /app/backend/.venv/bin/python3 && \
    ln -sf python /app/backend/.venv/bin/python3.11 && \
    chmod +x /app/backend/.venv/bin/*

# Set environment variables
ENV PATH="/app/backend/.venv/bin:$PATH"
ENV DJANGO_SETTINGS_MODULE=watson.settings.production
ENV PYTHONPATH=/app/backend

# Fix venv permissions and install globally as fallback
RUN chmod +x /app/backend/.venv/bin/* 2>/dev/null || true && \
    pip install -e /app && \
    pip install "django>=5.0" "djangorestframework>=3.14.0" "django-cors-headers>=4.0.0" "psycopg2-binary>=2.9.0" "python-jose[cryptography]>=3.3.0" "requests>=2.28.0" "factory-boy>=3.3.0" "faker>=21.0.0" "coverage>=7.3.0" "django-coverage-plugin>=3.1.0" "gunicorn>=21.2.0" "whitenoise>=6.6.0"

# Pre-collect static files during build for production
RUN cd /app/backend && \
    # Set minimal environment variables needed for collectstatic
    export SECRET_KEY="build-time-secret" && \
    export DEBUG="false" && \
    export ALLOWED_HOSTS="localhost" && \
    export DJANGO_SETTINGS_MODULE="watson.settings.base" && \
    # Run collectstatic without requiring database - use base settings to avoid production constraints
    /app/backend/.venv/bin/python manage.py collectstatic --noinput --clear || true

# Switch to non-root user
USER app

# Health check
HEALTHCHECK --interval=30s --timeout=10s --start-period=5s --retries=3 \
    CMD /healthcheck.sh

# Expose port
EXPOSE 8000

# Use entrypoint script
ENTRYPOINT ["/entrypoint.sh"]
CMD ["/app/backend/.venv/bin/gunicorn", "--bind", "0.0.0.0:8000", "--workers", "3", "watson.wsgi:application"]
</file>

<file path="pyproject.toml">
[project]
name = "watson-oceanheart-ai"
version = "0.1.0"
description = "Clinical LLM output review and curation tool"
requires-python = ">=3.11"
dependencies = [
    "django>=5.0",
    "djangorestframework>=3.14.0",
    "django-cors-headers>=4.0.0",
    "psycopg2-binary>=2.9.0",
    "python-jose[cryptography]>=3.3.0",
    "requests>=2.28.0",
    # Testing dependencies
    "factory-boy>=3.3.0",
    "faker>=21.0.0",
    "coverage>=7.3.0",
    "django-coverage-plugin>=3.1.0",
    # Production dependencies
    "gunicorn>=21.2.0",
    "whitenoise>=6.6.0",
]

[build-system]
requires = ["hatchling"]
build-backend = "hatchling.build"

[tool.hatch.build.targets.wheel]
packages = ["backend"]
</file>

<file path="docs/specs/001-build-implementation-report.md">
# Implementation Report: Watson Build System - Phase 1
## Date: 2025-09-12
## PRD: 001-build.prd.spec

## Overview

This report tracks the implementation of **Phase 1: Development Workflow** for the Watson build system. Phase 1 focuses on establishing hot reloading, development servers, and local testing infrastructure for the multi-language project.

## Phase 1 Scope

**Key Features to Implement**:
- Django development server with hot reload
- Bun-based frontend development with HMR  
- File watching for automatic rebuilds
- Local database setup and migrations
- Development environment health checks

**Success Criteria**:
- Changes to Python code trigger Django reload
- Frontend changes reflect immediately in browser
- Database migrations run automatically
- All services can start with single command

## Phases Completed

- [x] Phase 1: Development Workflow Setup
  - Tasks: Django project structure, React frontend with TipTap, HMR setup, unified dev script, health checks
  - Commits: 8b8ba55, dde6033, and final commit

## Task Details Completed

### 1. Django Project Structure ✅
- Created Django 5.2.6 project with REST framework integration
- Configured environment-based settings for development/production
- Added PostgreSQL support with SQLite fallback
- Created `core` and `reviews` Django applications
- Updated pyproject.toml with proper dependencies

### 2. React Frontend with TipTap Editor ✅
- Implemented React 18 frontend with TypeScript
- Integrated TipTap rich text editor for clinical review workflow
- Added responsive CSS styling
- Configured package.json with all necessary dependencies

### 3. Bun Development Server with HMR ✅
- Created Bun server with Hot Module Reloading
- Configured API proxy to Django backend
- Implemented file watching for automatic rebuilds

### 4. Development Scripts ✅
- `scripts/dev-backend.sh` - Django development server
- `scripts/dev-frontend.sh` - Bun frontend server  
- `scripts/dev.sh` - Unified development startup (single command)
- `scripts/health-check.sh` - Environment verification

### 5. Environment Configuration ✅
- Created `.env.dev` for development environment variables
- Configured CORS for frontend-backend communication
- Set up proper port assignments (8881 frontend, 8888 backend)

## Success Criteria Achievement

✅ **Django development server with hot reload** - Complete  
✅ **Bun-based frontend development with HMR** - Complete  
✅ **File watching for automatic rebuilds** - Complete  
✅ **All services can start with single command** - `./scripts/dev.sh`  
✅ **Development environment health checks** - `./scripts/health-check.sh`  

## Testing Summary

- Tests written: 0 (testing infrastructure planned for Phase 3)
- Tests passing: N/A
- Manual verification: ✅ Complete - Health check passes 23/23 checks
- Environment setup: ✅ All dependencies and scripts verified

## Challenges & Solutions

### Challenge 1: Hatchling Build Configuration
- **Issue**: UV installation failed due to missing package configuration
- **Solution**: Added `[tool.hatch.build.targets.wheel]` with `packages = ["backend"]` to pyproject.toml

### Challenge 2: Multi-language Development Workflow
- **Issue**: Managing Python (UV), TypeScript (Bun), and Ruby environments
- **Solution**: Created unified development script with proper environment activation and concurrent service startup

### Challenge 3: Frontend-Backend Integration
- **Issue**: CORS configuration for API communication during development  
- **Solution**: Added django-cors-headers with development-friendly settings and API proxy in Bun server

## Critical Security Notes

- **Authentication/Authorization changes**: Configured JWT preparation for passport.oceanheart.ai integration (future)
- **Data validation changes**: Django REST Framework configured with authentication requirements
- **Input sanitization**: TipTap editor configured with safe defaults, Django CSRF protection enabled
- **Environment variables**: Secure handling of sensitive configuration via .env files

## Next Steps

### Phase 2: Build Pipeline (Next)
- TypeScript transpilation and bundling optimization
- Python package building for production
- Static asset processing and CDN preparation
- Environment-specific configuration management

### Phase 3: Testing Infrastructure ✅ Complete
- Django test suite with in-memory SQLite database
- Bun test runner with TypeScript and component testing
- Ruby RSpec framework with SimpleCov coverage
- Comprehensive test database isolation
- Multi-platform coverage reporting
- CI/CD integration with GitHub Actions
- Pre-commit hooks for quality assurance

### Technical Debt Identified
- Add proper error boundaries in React components
- Implement proper logging configuration
- Add database connection pooling for production
- Create Docker configuration for deployment consistency

## Implementation Status

**Status**: ✅ **Phase 4 Complete**  
**Started**: 2025-09-12  
**Completed**: 2025-09-12  
**Phase**: 4 (Deployment Automation)  
**All Success Criteria**: ✅ Achieved

## Phase 2 Implementation Details

### Key Features Implemented ✅

#### 1. TypeScript Transpilation and Bundling with Bun ✅
- Enhanced package.json with optimized build scripts
- Created build.config.ts for production optimization settings
- Implemented code splitting, minification, and tree shaking
- Added source map generation for debugging (environment-specific)

#### 2. Python Package Building and Optimization ✅
- Updated Django settings for static file management
- Configured ManifestStaticFilesStorage for production
- Implemented proper STATIC_ROOT and STATICFILES_DIRS
- Added static file collection and optimization

#### 3. Static Asset Processing and Optimization ✅
- Built asset optimization analysis script (optimize-assets.sh)
- Implemented compression testing and size analysis
- Added cache-busting recommendations
- Generated optimization reports with performance metrics

#### 4. Build Artifact Validation ✅
- Created comprehensive build validation script (validate-build.js)
- Implemented security checks for production builds
- Added file integrity and size validation
- Generated detailed validation reports with error/warning summary

#### 5. Environment-Specific Configuration ✅
- Created .env files for development, staging, and production
- Implemented environment-aware build script (build-env.sh)
- Added conditional optimization levels per environment
- Configured security settings per environment

### Production Build Results

**Environment Builds:**
- **Development**: Basic optimization, source maps included, console.log allowed
- **Staging**: Full optimization, source maps included, reduced security
- **Production**: Aggressive optimization, no source maps, maximum security

**Bundle Sizes:**
- JavaScript (production): 443.7KB (gzipped: ~137KB)
- CSS: 1.7KB
- Total static files: 165

**Validation Results:**
- Production build: ✅ 0 errors, 2 warnings
- Staging build: ✅ 0 errors, 6 warnings  
- Development build: ✅ 0 errors, minimal warnings

### Phase 2 Success Criteria Achievement

✅ **Production builds complete without errors** - All environment builds successful  
✅ **Static assets are properly optimized** - 30.9% compression ratio achieved  
✅ **Build artifacts are deployment-ready** - Full validation passing  
✅ **Build process is deterministic** - Environment-specific configurations ensure consistency

## Phase 3 Implementation Details

### Key Features Implemented ✅

#### 1. Django Test Suite with Database Isolation ✅
- Reorganized Django settings into modular structure (base.py, test.py, production.py)
- Configured test-specific settings with in-memory SQLite database
- Implemented DisableMigrations class for faster test execution
- Added django-coverage-plugin for accurate coverage reporting
- Created comprehensive test examples in backend/core/test_models.py
- Set up automated test database creation and destruction

#### 2. Bun Test Runner for TypeScript/JavaScript ✅
- Configured Bun test runner with TypeScript support
- Created test configuration with DOM simulation using happy-dom
- Implemented component logic testing for React components
- Added validation utilities testing with security-focused test cases
- Set up frontend test structure with proper TypeScript types
- Created test scripts for different test scenarios

#### 3. Ruby Test Framework with RSpec ✅
- Updated Gemfile with RSpec, FactoryBot, and Faker dependencies
- Configured SimpleCov for comprehensive coverage reporting (100% achieved)
- Created ReviewValidator utility class with medical content processing
- Implemented security-focused HTML sanitization testing
- Added medical terminology extraction with pattern matching
- Set up Ruby test environment with coverage thresholds

#### 4. Test Database Isolation and Management ✅
- Django: In-memory SQLite with automatic creation/destruction per test run
- Bun: DOM simulation environment for component testing
- Ruby: Independent test execution with no shared state
- Implemented proper test data cleanup and isolation
- Added factory patterns for test data generation
- Configured test-specific environment variables

#### 5. Multi-Platform Coverage Reporting ✅
- Django: HTML coverage reports with 72% baseline coverage
- Ruby: SimpleCov with 100% coverage for utility classes
- Frontend: Bun test coverage integration
- Created unified coverage reporting script (scripts/coverage-report.sh)
- Added coverage thresholds and failure conditions
- Generated HTML reports for visual coverage analysis

#### 6. CI/CD Integration Scripts ✅
- Created GitHub Actions workflow (.github/workflows/test.yml)
- Implemented multi-platform testing (Python, Node.js/Bun, Ruby)
- Added database services for integration testing
- Created local CI simulation script (scripts/ci-local.sh)
- Implemented pre-commit hooks for quality assurance
- Added caching strategies for faster CI builds

### Testing Infrastructure Results

**Test Execution Summary:**
- **Frontend (Bun)**: 10 tests passing across 2 files
- **Backend (Django)**: 2 core model tests with database isolation
- **Ruby (RSpec)**: 16 tests with 100% coverage on utility classes

**Coverage Analysis:**
- **Django Coverage**: 72% overall (123 statements, 34 missed)
- **Ruby Coverage**: 100% (20/20 lines covered)
- **Frontend Coverage**: Bun test runner integrated

**CI/CD Pipeline Features:**
- **GitHub Actions**: Multi-platform testing with PostgreSQL service
- **Local CI Simulation**: Complete pipeline validation
- **Pre-commit Hooks**: Type checking + essential test subset
- **Coverage Integration**: Codecov upload for Django and Ruby

### Phase 3 Success Criteria Achievement

✅ **Comprehensive testing setup across all platforms** - Django, Bun, and Ruby test suites operational  
✅ **Database isolation for reliable testing** - In-memory SQLite with proper cleanup  
✅ **Coverage reporting with quality gates** - Multi-platform coverage analysis  
✅ **CI/CD integration ready for deployment** - GitHub Actions workflow with all services  
✅ **Development workflow optimization** - Pre-commit hooks and local CI simulation

## Phase 4 Implementation Details

### Key Features Implemented ✅

#### 1. Docker Containerization for Multi-Service Architecture ✅
- Created multi-stage Dockerfile supporting Django, Bun frontend, and Ruby services
- Implemented production-ready container with non-root user security
- Added comprehensive Docker Compose configuration for local development
- Created entrypoint script with automated migration and static file collection
- Implemented health check script with database and HTTP endpoint validation
- Configured Gunicorn for production WSGI serving with optimal worker configuration

#### 2. Cloud Platform Deployment Scripts ✅
- Railway deployment configuration with service definitions and environment management
- Render.com Blueprint specification with PostgreSQL and Redis integration
- Fly.io configuration with health checks and release commands
- Unified deployment automation script supporting multiple platforms (Railway, Render, Fly.io, Docker)
- Environment validation with branch checking and test execution requirements
- Automated deployment workflow with dry-run capabilities and platform auto-detection

#### 3. Database Migration Automation ✅
- Comprehensive migration script with backup and rollback capabilities
- Environment-specific migration execution (development, staging, production)
- Automated database backup creation before production migrations
- Migration validation with integrity checks and query testing
- Rollback procedures with backup file management
- Migration logging and error handling with detailed status reporting

#### 4. Environment Configuration Management ✅
- Production environment template with security-focused configurations
- Staging environment template with debug capabilities enabled
- Environment variable management for DATABASE_URL, Redis, and external services
- Security header configuration for production deployments
- AWS S3 integration templates for static asset storage
- Email configuration templates for SMTP and development backends

#### 5. Health Checks and Monitoring System ✅
- Django health check endpoints (/health/ and /ready/) with database validation
- Comprehensive monitoring script with system resource checking
- HTTP endpoint validation with configurable timeouts
- Database connection monitoring through Django ORM
- Static file availability verification
- Disk space and memory usage monitoring with alerting thresholds
- Process status checking for Django/Gunicorn workers

#### 6. Rollback Procedures and Testing ✅
- Multi-platform rollback automation (Docker, Fly.io, Railway, Render)
- Database rollback with backup file restoration
- Application version rollback with container/deployment management  
- Full system rollback combining database and application rollback
- Rollback testing with dry-run capabilities
- Platform auto-detection for appropriate rollback strategies
- Post-rollback health validation and verification

### Deployment Infrastructure Results

**Docker Configuration:**
- **Multi-stage build**: Frontend (Bun) → Backend (Python/UV) → Ruby → Production image
- **Security**: Non-root user execution, minimal attack surface
- **Health checks**: 30-second intervals with database and HTTP validation
- **Production ready**: Gunicorn WSGI server with 3 workers default

**Cloud Platform Support:**
- **Railway**: JSON configuration with PostgreSQL and Redis services
- **Render**: Blueprint YAML with managed database and Redis
- **Fly.io**: TOML configuration with release commands and health checks  
- **Docker**: Local development with compose orchestration

**Migration System:**
- **Backup automation**: Timestamped SQL dumps before migrations
- **Environment safety**: Production branch validation and test execution
- **Rollback capability**: Automated restore from backup files
- **Validation**: Database integrity and migration status verification

**Monitoring Coverage:**
- **HTTP endpoints**: Health and readiness checks with status codes
- **Database**: Connection validation and migration status
- **System resources**: Disk space (80%/90% thresholds) and memory usage
- **Process monitoring**: Django/Gunicorn worker status verification
- **Alerting**: Email notifications for critical failures

### Phase 4 Success Criteria Achievement

✅ **Automated deployment to staging/production** - Multi-platform deployment scripts with Railway, Render, Fly.io support  
✅ **Database migrations execute safely** - Automated migration system with backup and rollback capabilities  
✅ **Health checks validate deployment** - Comprehensive monitoring with HTTP, database, and system resource validation  
✅ **Rollback procedures tested** - Multi-platform rollback automation with dry-run testing and platform auto-detection
</file>

<file path="package.json">
{
  "name": "watson.oceanheart.ai",
  "version": "0.1.0",
  "type": "module",
  "private": true,
  "scripts": {
    "dev": "bun --hot ./frontend/index.ts",
    "build": "npm run build:clean && npm run build:frontend && npm run build:backend",
    "build:clean": "rm -rf dist build",
    "build:frontend": "bun build ./frontend/src/main.tsx --outdir ./dist/static --minify --splitting --format esm --target browser --public-path /static/",
    "build:backend": "cd backend && python manage.py collectstatic --noinput",
    "build:prod": "NODE_ENV=production npm run build",
    "test": "bun test frontend/ --preload ./bun.test.config.ts",
    "test:backend": "cd backend && DJANGO_ENVIRONMENT=test ../.venv/bin/python manage.py test --verbosity=2",
    "test:ruby": "bundle exec rspec --format documentation",
    "test:all": "npm run test && npm run test:backend && npm run test:ruby",
    "test:coverage": "npm run test:coverage:frontend && npm run test:coverage:backend && npm run test:coverage:ruby",
    "test:coverage:frontend": "bun test frontend/ --coverage",
    "test:coverage:backend": "cd backend && DJANGO_ENVIRONMENT=test ../.venv/bin/python -m coverage run --source='.' manage.py test && ../.venv/bin/python -m coverage report && ../.venv/bin/python -m coverage html",
    "test:coverage:ruby": "bundle exec rspec",
    "coverage": "./scripts/coverage-report.sh",
    "ci:local": "./scripts/ci-local.sh",
    "pre-commit": "./scripts/pre-commit-hook.sh",
    "deploy": "./deploy/deploy.sh",
    "migrate": "./scripts/migrate.sh",
    "monitor": "./scripts/monitor.sh",
    "rollback": "./scripts/rollback.sh",
    "docker:build": "docker build -t watson-oceanheart-ai .",
    "docker:up": "docker-compose up -d",
    "docker:down": "docker-compose down",
    "docker:logs": "docker-compose logs -f",
    "typecheck": "tsc --noEmit",
    "frontend:dev": "cd frontend && bun --hot ./index.ts",
    "validate:build": "node scripts/validate-build.js"
  },
  "dependencies": {
    "react": "^18.2.0",
    "react-dom": "^18.2.0",
    "@tiptap/core": "^2.1.0",
    "@tiptap/pm": "^2.1.0",
    "@tiptap/react": "^2.1.0",
    "@tiptap/starter-kit": "^2.1.0",
    "@tiptap/extension-collaboration": "^2.1.0",
    "@tiptap/extension-placeholder": "^2.1.0"
  },
  "devDependencies": {
    "@testing-library/jest-dom": "^6.8.0",
    "@testing-library/react": "^16.3.0",
    "@testing-library/user-event": "^14.6.1",
    "@types/bun": "latest",
    "@types/react": "^18.2.0",
    "@types/react-dom": "^18.2.0",
    "happy-dom": "^18.0.1",
    "typescript": "^5.0.0"
  },
  "build": {
    "target": "browser",
    "outdir": "./dist",
    "entryPoints": ["./frontend/src/main.tsx"],
    "splitting": true,
    "format": "esm"
  }
}
</file>

</files>
